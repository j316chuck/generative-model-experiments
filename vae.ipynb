{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchviz import make_dot\n",
    "from utils import one_hot_encode, one_hot_decode, get_all_amino_acids, get_wild_type_amino_acid_sequence\n",
    "from utils import load_gfp_data, count_substring_mismatch, get_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    # change architecture later to make it deeper if it's not good enough to capture all data\n",
    "    def __init__(self, input_size, hidden_size, latent_dim, num_characters):\n",
    "        super(VAE, self).__init__() \n",
    "        self.num_characters = num_characters\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc21 = nn.Linear(hidden_size, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_size, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
    "        self.fc5 = nn.Linear(self.num_characters, self.num_characters)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # input should be one hot encoded. shape - (batch_size, alphabet x sequence_length)\n",
    "        h1 = F.elu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z, softmax=False):\n",
    "        batch_size = z.shape[0]\n",
    "        h3 = F.elu(self.fc3(z))\n",
    "        h4 = F.elu(self.fc4(h3)).view(batch_size, -1, self.num_characters) ## may need to add RELU here. \n",
    "        #F.elu(self.fc4(h3)).view(batch_size, -1, self.num_characters)\n",
    "        h5 = self.fc5(h4)\n",
    "        if softmax:\n",
    "            return F.softmax(h5, dim=2)\n",
    "        else:\n",
    "            return h5\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.input_size))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, softmax=False), mu, logvar\n",
    "\n",
    "    def elbo_loss(self, recon_x, x, mu, logvar):\n",
    "        \"\"\"\n",
    "        Input: x is the one hot encoded batch_size x (seq_length * len(all_characters)) \n",
    "               recon_x is the unormalized outputs of the decoder in the same shape as x\n",
    "               mu and logvar are the hidden states of size self.hidden_size\n",
    "        Output: elbo_loss\n",
    "        \"\"\"\n",
    "        # get the argmax of each batch_size x seq_length * len(all_characters) matrix. Output is in batch_size x seq_length form\n",
    "        # print(labels)\n",
    "        # reshapes the recon_x vector to be of shape batch_size x len(all_characters) x seq_length so that it fits according to PyTorch's CrossEntropyLoss\n",
    "        # permute is transpose function so at each 1, 2 dimension we take the transpose\n",
    "        # print(recon_x.shape)\n",
    "        # print(reshape_x[0,:,0])\n",
    "        outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        CE = (-1 * outputs * x.view(x.shape[0], -1, len(self.all_characters))).sum()\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        #print(\"log var shape:\", logvar.shape, \"mu shape: \", mu.shape, \"logvar: \", logvar.sum(dim=1))\n",
    "        #print(\"mu: \", mu.sum(dim=1))\n",
    "        #print((1 + logvar - mu.pow(2) - logvar.exp()).shape)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        #print(\"CE Loss: \", CE, \"KLD Loss:\", KLD, file=logger)\n",
    "        return CE + KLD\n",
    "    \n",
    "    def NLLoss(self, recon_x, x):\n",
    "        #outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        #return  (-1 * outputs * x.view(x.shape[0], -1, self.num_characters)).sum()\n",
    "        loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "        input = recon_x.permute(0, 2, 1)\n",
    "        _, target = x.view(x.shape[0], -1, self.num_characters).max(dim=2)\n",
    "        target = target.long()\n",
    "        return loss(input, target)\n",
    "    \n",
    "    def KLD(self, mu, logvar): \n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 1. Average Train loss: 182.2484. Train Reconstruction loss: 148.3594. Train KLD loss: 33.8890. Time: 1.19\n",
      "<-- Epoch: 1. Average Test loss: 47.1824. Test Reconstruction loss: 33.4760. Test KLD loss: 13.7064. Time: 1.56\n",
      "<-- Epoch: 2. Average Train loss: 41.2713. Train Reconstruction loss: 31.4287. Train KLD loss: 9.8426. Time: 2.58\n",
      "<-- Epoch: 2. Average Test loss: 41.6451. Test Reconstruction loss: 35.5643. Test KLD loss: 6.0807. Time: 2.88\n",
      "<-- Epoch: 3. Average Train loss: 36.5658. Train Reconstruction loss: 29.1410. Train KLD loss: 7.4248. Time: 3.92\n",
      "<-- Epoch: 3. Average Test loss: 35.8055. Test Reconstruction loss: 30.0839. Test KLD loss: 5.7216. Time: 4.22\n",
      "<-- Epoch: 4. Average Train loss: 35.4068. Train Reconstruction loss: 28.3871. Train KLD loss: 7.0197. Time: 5.26\n",
      "<-- Epoch: 4. Average Test loss: 34.5089. Test Reconstruction loss: 28.3998. Test KLD loss: 6.1091. Time: 5.58\n",
      "<-- Epoch: 5. Average Train loss: 33.0888. Train Reconstruction loss: 26.9185. Train KLD loss: 6.1703. Time: 6.61\n",
      "<-- Epoch: 5. Average Test loss: 33.9375. Test Reconstruction loss: 27.3299. Test KLD loss: 6.6077. Time: 6.92\n",
      "<-- Epoch: 6. Average Train loss: 31.7762. Train Reconstruction loss: 26.3884. Train KLD loss: 5.3878. Time: 8.12\n",
      "<-- Epoch: 6. Average Test loss: 32.6484. Test Reconstruction loss: 27.9978. Test KLD loss: 4.6506. Time: 8.42\n",
      "<-- Epoch: 7. Average Train loss: 31.0992. Train Reconstruction loss: 26.1673. Train KLD loss: 4.9319. Time: 9.44\n",
      "<-- Epoch: 7. Average Test loss: 33.4721. Test Reconstruction loss: 27.3802. Test KLD loss: 6.0919. Time: 9.76\n",
      "<-- Epoch: 8. Average Train loss: 30.9617. Train Reconstruction loss: 25.8775. Train KLD loss: 5.0842. Time: 10.90\n",
      "<-- Epoch: 8. Average Test loss: 31.9111. Test Reconstruction loss: 27.1881. Test KLD loss: 4.7230. Time: 11.19\n",
      "<-- Epoch: 9. Average Train loss: 31.3017. Train Reconstruction loss: 25.8117. Train KLD loss: 5.4900. Time: 12.21\n",
      "<-- Epoch: 9. Average Test loss: 31.7463. Test Reconstruction loss: 27.1668. Test KLD loss: 4.5794. Time: 12.51\n",
      "<-- Epoch: 10. Average Train loss: 30.5199. Train Reconstruction loss: 25.6870. Train KLD loss: 4.8328. Time: 13.72\n",
      "<-- Epoch: 10. Average Test loss: 30.8655. Test Reconstruction loss: 26.4691. Test KLD loss: 4.3964. Time: 14.03\n",
      "<-- Epoch: 11. Average Train loss: 29.3804. Train Reconstruction loss: 25.1287. Train KLD loss: 4.2517. Time: 15.04\n",
      "<-- Epoch: 11. Average Test loss: 30.7303. Test Reconstruction loss: 26.5306. Test KLD loss: 4.1997. Time: 15.34\n",
      "<-- Epoch: 12. Average Train loss: 28.4030. Train Reconstruction loss: 24.8566. Train KLD loss: 3.5464. Time: 16.35\n",
      "<-- Epoch: 12. Average Test loss: 29.8938. Test Reconstruction loss: 27.1459. Test KLD loss: 2.7479. Time: 16.65\n",
      "<-- Epoch: 13. Average Train loss: 28.6702. Train Reconstruction loss: 24.9250. Train KLD loss: 3.7452. Time: 17.66\n",
      "<-- Epoch: 13. Average Test loss: 29.8238. Test Reconstruction loss: 25.9772. Test KLD loss: 3.8466. Time: 17.95\n",
      "<-- Epoch: 14. Average Train loss: 28.1736. Train Reconstruction loss: 24.7371. Train KLD loss: 3.4365. Time: 18.96\n",
      "<-- Epoch: 14. Average Test loss: 29.5577. Test Reconstruction loss: 26.2840. Test KLD loss: 3.2737. Time: 19.26\n",
      "<-- Epoch: 15. Average Train loss: 27.7866. Train Reconstruction loss: 24.5863. Train KLD loss: 3.2004. Time: 20.26\n",
      "<-- Epoch: 15. Average Test loss: 29.4670. Test Reconstruction loss: 25.9862. Test KLD loss: 3.4807. Time: 20.57\n",
      "<-- Epoch: 16. Average Train loss: 26.8685. Train Reconstruction loss: 24.2698. Train KLD loss: 2.5986. Time: 21.57\n",
      "<-- Epoch: 16. Average Test loss: 28.6568. Test Reconstruction loss: 26.5265. Test KLD loss: 2.1303. Time: 21.86\n",
      "<-- Epoch: 17. Average Train loss: 26.6489. Train Reconstruction loss: 24.2568. Train KLD loss: 2.3921. Time: 22.87\n",
      "<-- Epoch: 17. Average Test loss: 28.4123. Test Reconstruction loss: 26.2574. Test KLD loss: 2.1549. Time: 23.16\n",
      "<-- Epoch: 18. Average Train loss: 26.0849. Train Reconstruction loss: 24.0771. Train KLD loss: 2.0078. Time: 24.19\n",
      "<-- Epoch: 18. Average Test loss: 27.5570. Test Reconstruction loss: 25.6231. Test KLD loss: 1.9339. Time: 24.48\n",
      "<-- Epoch: 19. Average Train loss: 26.1785. Train Reconstruction loss: 24.1332. Train KLD loss: 2.0453. Time: 25.48\n",
      "<-- Epoch: 19. Average Test loss: 27.6782. Test Reconstruction loss: 25.3353. Test KLD loss: 2.3429. Time: 25.79\n",
      "<-- Epoch: 20. Average Train loss: 25.7302. Train Reconstruction loss: 23.8706. Train KLD loss: 1.8596. Time: 26.80\n",
      "<-- Epoch: 20. Average Test loss: 27.6498. Test Reconstruction loss: 25.5990. Test KLD loss: 2.0508. Time: 27.08\n",
      "<-- Epoch: 21. Average Train loss: 25.3093. Train Reconstruction loss: 23.7309. Train KLD loss: 1.5784. Time: 28.08\n",
      "<-- Epoch: 21. Average Test loss: 26.8694. Test Reconstruction loss: 25.6772. Test KLD loss: 1.1923. Time: 28.36\n",
      "<-- Epoch: 22. Average Train loss: 24.9748. Train Reconstruction loss: 23.6788. Train KLD loss: 1.2960. Time: 29.37\n",
      "<-- Epoch: 22. Average Test loss: 26.6112. Test Reconstruction loss: 25.3297. Test KLD loss: 1.2815. Time: 29.68\n",
      "<-- Epoch: 23. Average Train loss: 24.6990. Train Reconstruction loss: 23.5960. Train KLD loss: 1.1030. Time: 30.68\n",
      "<-- Epoch: 23. Average Test loss: 26.3235. Test Reconstruction loss: 25.1958. Test KLD loss: 1.1277. Time: 30.97\n",
      "<-- Epoch: 24. Average Train loss: 24.3975. Train Reconstruction loss: 23.4458. Train KLD loss: 0.9517. Time: 31.96\n",
      "<-- Epoch: 24. Average Test loss: 25.9637. Test Reconstruction loss: 25.1781. Test KLD loss: 0.7857. Time: 32.25\n",
      "<-- Epoch: 25. Average Train loss: 24.5446. Train Reconstruction loss: 23.4820. Train KLD loss: 1.0626. Time: 33.26\n",
      "<-- Epoch: 25. Average Test loss: 26.0052. Test Reconstruction loss: 24.9123. Test KLD loss: 1.0929. Time: 33.57\n",
      "<-- Epoch: 26. Average Train loss: 23.9874. Train Reconstruction loss: 23.2999. Train KLD loss: 0.6874. Time: 34.58\n",
      "<-- Epoch: 26. Average Test loss: 25.5110. Test Reconstruction loss: 24.9296. Test KLD loss: 0.5814. Time: 34.87\n",
      "<-- Epoch: 27. Average Train loss: 23.7810. Train Reconstruction loss: 23.2717. Train KLD loss: 0.5093. Time: 35.88\n",
      "<-- Epoch: 27. Average Test loss: 25.4281. Test Reconstruction loss: 25.0470. Test KLD loss: 0.3812. Time: 36.18\n",
      "<-- Epoch: 28. Average Train loss: 23.5326. Train Reconstruction loss: 23.1949. Train KLD loss: 0.3378. Time: 37.19\n",
      "<-- Epoch: 28. Average Test loss: 25.2975. Test Reconstruction loss: 25.0437. Test KLD loss: 0.2538. Time: 37.48\n",
      "<-- Epoch: 29. Average Train loss: 23.3990. Train Reconstruction loss: 23.1333. Train KLD loss: 0.2657. Time: 38.57\n",
      "<-- Epoch: 29. Average Test loss: 25.1743. Test Reconstruction loss: 24.9551. Test KLD loss: 0.2193. Time: 38.86\n",
      "<-- Epoch: 30. Average Train loss: 23.2835. Train Reconstruction loss: 23.0811. Train KLD loss: 0.2024. Time: 39.87\n",
      "<-- Epoch: 30. Average Test loss: 25.0962. Test Reconstruction loss: 24.8861. Test KLD loss: 0.2102. Time: 40.15\n",
      "<-- Epoch: 31. Average Train loss: 23.2141. Train Reconstruction loss: 23.0506. Train KLD loss: 0.1635. Time: 41.15\n",
      "<-- Epoch: 31. Average Test loss: 24.8728. Test Reconstruction loss: 24.7836. Test KLD loss: 0.0892. Time: 41.44\n",
      "<-- Epoch: 32. Average Train loss: 23.1737. Train Reconstruction loss: 23.0619. Train KLD loss: 0.1118. Time: 42.43\n",
      "<-- Epoch: 32. Average Test loss: 24.8911. Test Reconstruction loss: 24.8211. Test KLD loss: 0.0700. Time: 42.74\n",
      "<-- Epoch: 33. Average Train loss: 23.0540. Train Reconstruction loss: 22.9776. Train KLD loss: 0.0763. Time: 43.73\n",
      "<-- Epoch: 33. Average Test loss: 24.8243. Test Reconstruction loss: 24.7804. Test KLD loss: 0.0439. Time: 44.01\n",
      "<-- Epoch: 34. Average Train loss: 23.0336. Train Reconstruction loss: 22.9656. Train KLD loss: 0.0680. Time: 45.01\n",
      "<-- Epoch: 34. Average Test loss: 24.7867. Test Reconstruction loss: 24.7492. Test KLD loss: 0.0374. Time: 45.29\n",
      "<-- Epoch: 35. Average Train loss: 22.9729. Train Reconstruction loss: 22.9091. Train KLD loss: 0.0637. Time: 46.28\n",
      "<-- Epoch: 35. Average Test loss: 24.8274. Test Reconstruction loss: 24.7901. Test KLD loss: 0.0373. Time: 46.59\n",
      "<-- Epoch: 36. Average Train loss: 23.0000. Train Reconstruction loss: 22.9328. Train KLD loss: 0.0672. Time: 47.58\n",
      "<-- Epoch: 36. Average Test loss: 24.7403. Test Reconstruction loss: 24.7009. Test KLD loss: 0.0394. Time: 47.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 37. Average Train loss: 22.9600. Train Reconstruction loss: 22.8903. Train KLD loss: 0.0697. Time: 48.86\n",
      "<-- Epoch: 37. Average Test loss: 24.7802. Test Reconstruction loss: 24.7379. Test KLD loss: 0.0422. Time: 49.15\n",
      "<-- Epoch: 38. Average Train loss: 22.9704. Train Reconstruction loss: 22.8932. Train KLD loss: 0.0773. Time: 50.14\n",
      "<-- Epoch: 38. Average Test loss: 24.8063. Test Reconstruction loss: 24.7617. Test KLD loss: 0.0446. Time: 50.43\n",
      "<-- Epoch: 39. Average Train loss: 22.9552. Train Reconstruction loss: 22.8748. Train KLD loss: 0.0803. Time: 51.43\n",
      "<-- Epoch: 39. Average Test loss: 24.7728. Test Reconstruction loss: 24.7276. Test KLD loss: 0.0452. Time: 51.73\n",
      "<-- Epoch: 40. Average Train loss: 22.9403. Train Reconstruction loss: 22.8541. Train KLD loss: 0.0863. Time: 52.73\n",
      "<-- Epoch: 40. Average Test loss: 24.8162. Test Reconstruction loss: 24.7690. Test KLD loss: 0.0472. Time: 53.03\n",
      "<-- Epoch: 41. Average Train loss: 22.9135. Train Reconstruction loss: 22.8226. Train KLD loss: 0.0909. Time: 54.02\n",
      "<-- Epoch: 41. Average Test loss: 24.8074. Test Reconstruction loss: 24.7588. Test KLD loss: 0.0487. Time: 54.30\n",
      "<-- Epoch: 42. Average Train loss: 22.8984. Train Reconstruction loss: 22.8004. Train KLD loss: 0.0980. Time: 55.40\n",
      "<-- Epoch: 42. Average Test loss: 24.8603. Test Reconstruction loss: 24.8022. Test KLD loss: 0.0581. Time: 637.67\n",
      "<-- Epoch: 43. Average Train loss: 22.9055. Train Reconstruction loss: 22.7926. Train KLD loss: 0.1130. Time: 639.19\n",
      "<-- Epoch: 43. Average Test loss: 24.7905. Test Reconstruction loss: 24.7276. Test KLD loss: 0.0630. Time: 639.56\n",
      "<-- Epoch: 44. Average Train loss: 22.8718. Train Reconstruction loss: 22.7444. Train KLD loss: 0.1274. Time: 640.82\n",
      "<-- Epoch: 44. Average Test loss: 24.8393. Test Reconstruction loss: 24.7680. Test KLD loss: 0.0713. Time: 641.25\n",
      "<-- Epoch: 45. Average Train loss: 22.8895. Train Reconstruction loss: 22.7462. Train KLD loss: 0.1434. Time: 642.52\n",
      "<-- Epoch: 45. Average Test loss: 24.8238. Test Reconstruction loss: 24.7426. Test KLD loss: 0.0812. Time: 642.97\n",
      "<-- Epoch: 46. Average Train loss: 22.8662. Train Reconstruction loss: 22.7068. Train KLD loss: 0.1593. Time: 644.44\n",
      "<-- Epoch: 46. Average Test loss: 24.8409. Test Reconstruction loss: 24.7624. Test KLD loss: 0.0785. Time: 644.73\n",
      "<-- Epoch: 47. Average Train loss: 22.8520. Train Reconstruction loss: 22.6664. Train KLD loss: 0.1856. Time: 645.79\n",
      "<-- Epoch: 47. Average Test loss: 24.8569. Test Reconstruction loss: 24.7611. Test KLD loss: 0.0957. Time: 646.09\n",
      "<-- Epoch: 48. Average Train loss: 22.8099. Train Reconstruction loss: 22.6208. Train KLD loss: 0.1891. Time: 647.19\n",
      "<-- Epoch: 48. Average Test loss: 24.8557. Test Reconstruction loss: 24.7597. Test KLD loss: 0.0960. Time: 647.49\n",
      "<-- Epoch: 49. Average Train loss: 22.8385. Train Reconstruction loss: 22.6268. Train KLD loss: 0.2117. Time: 648.52\n",
      "<-- Epoch: 49. Average Test loss: 24.8635. Test Reconstruction loss: 24.7530. Test KLD loss: 0.1105. Time: 648.80\n",
      "<-- Epoch: 50. Average Train loss: 22.7702. Train Reconstruction loss: 22.5344. Train KLD loss: 0.2358. Time: 649.84\n",
      "<-- Epoch: 50. Average Test loss: 24.9228. Test Reconstruction loss: 24.7956. Test KLD loss: 0.1272. Time: 650.15\n",
      "<-- Epoch: 51. Average Train loss: 22.7642. Train Reconstruction loss: 22.5100. Train KLD loss: 0.2542. Time: 651.16\n",
      "<-- Epoch: 51. Average Test loss: 24.9413. Test Reconstruction loss: 24.7831. Test KLD loss: 0.1582. Time: 651.52\n",
      "<-- Epoch: 52. Average Train loss: 22.7517. Train Reconstruction loss: 22.4709. Train KLD loss: 0.2808. Time: 652.55\n",
      "<-- Epoch: 52. Average Test loss: 24.9642. Test Reconstruction loss: 24.8319. Test KLD loss: 0.1323. Time: 652.85\n",
      "<-- Epoch: 53. Average Train loss: 22.7178. Train Reconstruction loss: 22.4226. Train KLD loss: 0.2951. Time: 653.87\n",
      "<-- Epoch: 53. Average Test loss: 24.9292. Test Reconstruction loss: 24.7862. Test KLD loss: 0.1430. Time: 654.18\n",
      "<-- Epoch: 54. Average Train loss: 22.7967. Train Reconstruction loss: 22.4589. Train KLD loss: 0.3378. Time: 655.22\n",
      "<-- Epoch: 54. Average Test loss: 24.9476. Test Reconstruction loss: 24.7839. Test KLD loss: 0.1637. Time: 655.51\n",
      "<-- Epoch: 55. Average Train loss: 22.6773. Train Reconstruction loss: 22.3438. Train KLD loss: 0.3336. Time: 656.52\n",
      "<-- Epoch: 55. Average Test loss: 24.9841. Test Reconstruction loss: 24.7523. Test KLD loss: 0.2319. Time: 656.82\n",
      "<-- Epoch: 56. Average Train loss: 22.6765. Train Reconstruction loss: 22.3204. Train KLD loss: 0.3561. Time: 657.83\n",
      "<-- Epoch: 56. Average Test loss: 24.9645. Test Reconstruction loss: 24.7763. Test KLD loss: 0.1882. Time: 658.15\n",
      "<-- Epoch: 57. Average Train loss: 22.6494. Train Reconstruction loss: 22.2510. Train KLD loss: 0.3984. Time: 659.21\n",
      "<-- Epoch: 57. Average Test loss: 25.0350. Test Reconstruction loss: 24.8386. Test KLD loss: 0.1965. Time: 659.50\n",
      "<-- Epoch: 58. Average Train loss: 22.6356. Train Reconstruction loss: 22.1941. Train KLD loss: 0.4415. Time: 660.53\n",
      "<-- Epoch: 58. Average Test loss: 25.0607. Test Reconstruction loss: 24.8377. Test KLD loss: 0.2230. Time: 660.83\n",
      "<-- Epoch: 59. Average Train loss: 22.6267. Train Reconstruction loss: 22.1550. Train KLD loss: 0.4716. Time: 661.99\n",
      "<-- Epoch: 59. Average Test loss: 25.0516. Test Reconstruction loss: 24.8238. Test KLD loss: 0.2278. Time: 662.30\n",
      "<-- Epoch: 60. Average Train loss: 22.5004. Train Reconstruction loss: 21.9995. Train KLD loss: 0.5010. Time: 663.34\n",
      "<-- Epoch: 60. Average Test loss: 25.0704. Test Reconstruction loss: 24.8249. Test KLD loss: 0.2455. Time: 663.65\n",
      "<-- Epoch: 61. Average Train loss: 22.5356. Train Reconstruction loss: 21.9686. Train KLD loss: 0.5670. Time: 664.72\n",
      "<-- Epoch: 61. Average Test loss: 25.2089. Test Reconstruction loss: 24.7978. Test KLD loss: 0.4111. Time: 665.05\n",
      "<-- Epoch: 62. Average Train loss: 22.4679. Train Reconstruction loss: 21.8947. Train KLD loss: 0.5732. Time: 666.10\n",
      "<-- Epoch: 62. Average Test loss: 25.0542. Test Reconstruction loss: 24.8126. Test KLD loss: 0.2416. Time: 666.42\n",
      "<-- Epoch: 63. Average Train loss: 22.5584. Train Reconstruction loss: 21.9669. Train KLD loss: 0.5915. Time: 667.46\n",
      "<-- Epoch: 63. Average Test loss: 25.0768. Test Reconstruction loss: 24.7912. Test KLD loss: 0.2855. Time: 667.77\n",
      "<-- Epoch: 64. Average Train loss: 22.4930. Train Reconstruction loss: 21.8343. Train KLD loss: 0.6587. Time: 668.81\n",
      "<-- Epoch: 64. Average Test loss: 25.1569. Test Reconstruction loss: 24.8332. Test KLD loss: 0.3237. Time: 669.10\n",
      "<-- Epoch: 65. Average Train loss: 22.4407. Train Reconstruction loss: 21.7275. Train KLD loss: 0.7132. Time: 670.10\n",
      "<-- Epoch: 65. Average Test loss: 25.1097. Test Reconstruction loss: 24.7448. Test KLD loss: 0.3649. Time: 670.41\n",
      "<-- Epoch: 66. Average Train loss: 22.4379. Train Reconstruction loss: 21.6365. Train KLD loss: 0.8014. Time: 671.42\n",
      "<-- Epoch: 66. Average Test loss: 25.2563. Test Reconstruction loss: 24.8820. Test KLD loss: 0.3742. Time: 671.72\n",
      "<-- Epoch: 67. Average Train loss: 22.3881. Train Reconstruction loss: 21.5803. Train KLD loss: 0.8078. Time: 672.73\n",
      "<-- Epoch: 67. Average Test loss: 25.2740. Test Reconstruction loss: 24.8766. Test KLD loss: 0.3974. Time: 673.02\n",
      "<-- Epoch: 68. Average Train loss: 22.4509. Train Reconstruction loss: 21.6135. Train KLD loss: 0.8374. Time: 674.04\n",
      "<-- Epoch: 68. Average Test loss: 25.3480. Test Reconstruction loss: 24.9491. Test KLD loss: 0.3989. Time: 674.36\n",
      "<-- Epoch: 69. Average Train loss: 22.2964. Train Reconstruction loss: 21.4236. Train KLD loss: 0.8727. Time: 675.39\n",
      "<-- Epoch: 69. Average Test loss: 25.3659. Test Reconstruction loss: 24.9370. Test KLD loss: 0.4289. Time: 675.69\n",
      "<-- Epoch: 70. Average Train loss: 22.2619. Train Reconstruction loss: 21.3646. Train KLD loss: 0.8974. Time: 676.70\n",
      "<-- Epoch: 70. Average Test loss: 25.4693. Test Reconstruction loss: 25.0040. Test KLD loss: 0.4654. Time: 677.03\n",
      "<-- Epoch: 71. Average Train loss: 22.2776. Train Reconstruction loss: 21.3038. Train KLD loss: 0.9739. Time: 678.06\n",
      "<-- Epoch: 71. Average Test loss: 25.3229. Test Reconstruction loss: 24.8627. Test KLD loss: 0.4603. Time: 678.37\n",
      "<-- Epoch: 72. Average Train loss: 22.2184. Train Reconstruction loss: 21.1861. Train KLD loss: 1.0323. Time: 679.41\n",
      "<-- Epoch: 72. Average Test loss: 25.5152. Test Reconstruction loss: 25.0002. Test KLD loss: 0.5151. Time: 679.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 73. Average Train loss: 22.1701. Train Reconstruction loss: 21.1048. Train KLD loss: 1.0653. Time: 680.79\n",
      "<-- Epoch: 73. Average Test loss: 25.5064. Test Reconstruction loss: 24.9516. Test KLD loss: 0.5549. Time: 681.11\n",
      "<-- Epoch: 74. Average Train loss: 22.1066. Train Reconstruction loss: 20.9881. Train KLD loss: 1.1184. Time: 682.39\n",
      "<-- Epoch: 74. Average Test loss: 25.6021. Test Reconstruction loss: 25.0242. Test KLD loss: 0.5780. Time: 682.75\n",
      "<-- Epoch: 75. Average Train loss: 22.1219. Train Reconstruction loss: 20.9812. Train KLD loss: 1.1406. Time: 684.04\n",
      "<-- Epoch: 75. Average Test loss: 25.5107. Test Reconstruction loss: 24.9059. Test KLD loss: 0.6048. Time: 684.51\n",
      "<-- Epoch: 76. Average Train loss: 22.0370. Train Reconstruction loss: 20.8151. Train KLD loss: 1.2219. Time: 685.76\n",
      "<-- Epoch: 76. Average Test loss: 25.5343. Test Reconstruction loss: 24.9416. Test KLD loss: 0.5927. Time: 686.09\n",
      "<-- Epoch: 77. Average Train loss: 22.0167. Train Reconstruction loss: 20.7802. Train KLD loss: 1.2365. Time: 687.42\n",
      "<-- Epoch: 77. Average Test loss: 25.6721. Test Reconstruction loss: 24.9829. Test KLD loss: 0.6892. Time: 687.75\n",
      "<-- Epoch: 78. Average Train loss: 21.9800. Train Reconstruction loss: 20.6780. Train KLD loss: 1.3020. Time: 689.59\n",
      "<-- Epoch: 78. Average Test loss: 25.6908. Test Reconstruction loss: 25.0453. Test KLD loss: 0.6455. Time: 689.93\n",
      "<-- Epoch: 79. Average Train loss: 21.9206. Train Reconstruction loss: 20.5863. Train KLD loss: 1.3343. Time: 691.45\n",
      "<-- Epoch: 79. Average Test loss: 25.7711. Test Reconstruction loss: 25.1112. Test KLD loss: 0.6599. Time: 692.10\n",
      "<-- Epoch: 80. Average Train loss: 22.0225. Train Reconstruction loss: 20.6144. Train KLD loss: 1.4081. Time: 694.38\n",
      "<-- Epoch: 80. Average Test loss: 25.7416. Test Reconstruction loss: 25.0413. Test KLD loss: 0.7004. Time: 695.01\n",
      "<-- Epoch: 81. Average Train loss: 21.8690. Train Reconstruction loss: 20.4415. Train KLD loss: 1.4275. Time: 696.68\n",
      "<-- Epoch: 81. Average Test loss: 25.7126. Test Reconstruction loss: 25.0146. Test KLD loss: 0.6980. Time: 697.21\n",
      "<-- Epoch: 82. Average Train loss: 21.9369. Train Reconstruction loss: 20.4271. Train KLD loss: 1.5098. Time: 698.96\n",
      "<-- Epoch: 82. Average Test loss: 25.7045. Test Reconstruction loss: 24.8843. Test KLD loss: 0.8202. Time: 699.53\n",
      "<-- Epoch: 83. Average Train loss: 21.8067. Train Reconstruction loss: 20.2311. Train KLD loss: 1.5756. Time: 701.05\n",
      "<-- Epoch: 83. Average Test loss: 25.7422. Test Reconstruction loss: 24.9757. Test KLD loss: 0.7665. Time: 701.54\n",
      "<-- Epoch: 84. Average Train loss: 21.7964. Train Reconstruction loss: 20.2001. Train KLD loss: 1.5963. Time: 703.03\n",
      "<-- Epoch: 84. Average Test loss: 25.9147. Test Reconstruction loss: 25.0017. Test KLD loss: 0.9130. Time: 703.43\n",
      "<-- Epoch: 85. Average Train loss: 21.6461. Train Reconstruction loss: 19.9748. Train KLD loss: 1.6713. Time: 704.83\n",
      "<-- Epoch: 85. Average Test loss: 25.8655. Test Reconstruction loss: 25.0582. Test KLD loss: 0.8074. Time: 705.17\n",
      "<-- Epoch: 86. Average Train loss: 21.6903. Train Reconstruction loss: 19.9462. Train KLD loss: 1.7441. Time: 706.31\n",
      "<-- Epoch: 86. Average Test loss: 25.8812. Test Reconstruction loss: 24.9581. Test KLD loss: 0.9231. Time: 706.61\n",
      "<-- Epoch: 87. Average Train loss: 21.7399. Train Reconstruction loss: 19.8686. Train KLD loss: 1.8713. Time: 707.68\n",
      "<-- Epoch: 87. Average Test loss: 26.0322. Test Reconstruction loss: 25.0984. Test KLD loss: 0.9339. Time: 707.97\n",
      "<-- Epoch: 88. Average Train loss: 21.5051. Train Reconstruction loss: 19.6801. Train KLD loss: 1.8250. Time: 709.00\n",
      "<-- Epoch: 88. Average Test loss: 26.0141. Test Reconstruction loss: 25.0853. Test KLD loss: 0.9288. Time: 709.31\n",
      "<-- Epoch: 89. Average Train loss: 21.4826. Train Reconstruction loss: 19.6069. Train KLD loss: 1.8756. Time: 710.62\n",
      "<-- Epoch: 89. Average Test loss: 26.1785. Test Reconstruction loss: 25.0766. Test KLD loss: 1.1019. Time: 710.92\n",
      "<-- Epoch: 90. Average Train loss: 21.5519. Train Reconstruction loss: 19.5383. Train KLD loss: 2.0136. Time: 711.94\n",
      "<-- Epoch: 90. Average Test loss: 26.0001. Test Reconstruction loss: 24.9279. Test KLD loss: 1.0721. Time: 712.25\n",
      "<-- Epoch: 91. Average Train loss: 21.5601. Train Reconstruction loss: 19.4679. Train KLD loss: 2.0922. Time: 713.27\n",
      "<-- Epoch: 91. Average Test loss: 26.1705. Test Reconstruction loss: 25.1204. Test KLD loss: 1.0501. Time: 713.57\n",
      "<-- Epoch: 92. Average Train loss: 21.2830. Train Reconstruction loss: 19.1995. Train KLD loss: 2.0835. Time: 714.63\n",
      "<-- Epoch: 92. Average Test loss: 26.2328. Test Reconstruction loss: 25.0697. Test KLD loss: 1.1631. Time: 714.91\n",
      "<-- Epoch: 93. Average Train loss: 21.3358. Train Reconstruction loss: 19.1915. Train KLD loss: 2.1443. Time: 715.92\n",
      "<-- Epoch: 93. Average Test loss: 26.4567. Test Reconstruction loss: 25.1954. Test KLD loss: 1.2613. Time: 716.23\n",
      "<-- Epoch: 94. Average Train loss: 21.1837. Train Reconstruction loss: 18.9571. Train KLD loss: 2.2266. Time: 717.23\n",
      "<-- Epoch: 94. Average Test loss: 26.4720. Test Reconstruction loss: 25.2400. Test KLD loss: 1.2320. Time: 717.52\n",
      "<-- Epoch: 95. Average Train loss: 21.1388. Train Reconstruction loss: 18.8758. Train KLD loss: 2.2631. Time: 718.55\n",
      "<-- Epoch: 95. Average Test loss: 26.4354. Test Reconstruction loss: 25.2996. Test KLD loss: 1.1358. Time: 718.84\n",
      "<-- Epoch: 96. Average Train loss: 21.1528. Train Reconstruction loss: 18.8496. Train KLD loss: 2.3032. Time: 719.86\n",
      "<-- Epoch: 96. Average Test loss: 26.5431. Test Reconstruction loss: 25.1964. Test KLD loss: 1.3467. Time: 720.18\n",
      "<-- Epoch: 97. Average Train loss: 21.1916. Train Reconstruction loss: 18.8207. Train KLD loss: 2.3708. Time: 721.19\n",
      "<-- Epoch: 97. Average Test loss: 26.5168. Test Reconstruction loss: 25.2452. Test KLD loss: 1.2715. Time: 721.49\n",
      "<-- Epoch: 98. Average Train loss: 21.1209. Train Reconstruction loss: 18.6394. Train KLD loss: 2.4816. Time: 722.50\n",
      "<-- Epoch: 98. Average Test loss: 26.6480. Test Reconstruction loss: 25.2101. Test KLD loss: 1.4380. Time: 722.79\n",
      "<-- Epoch: 99. Average Train loss: 20.8965. Train Reconstruction loss: 18.4231. Train KLD loss: 2.4735. Time: 723.80\n",
      "<-- Epoch: 99. Average Test loss: 26.7217. Test Reconstruction loss: 25.2940. Test KLD loss: 1.4277. Time: 724.10\n",
      "<-- Epoch: 100. Average Train loss: 21.0506. Train Reconstruction loss: 18.4646. Train KLD loss: 2.5860. Time: 725.10\n",
      "<-- Epoch: 100. Average Test loss: 26.7153. Test Reconstruction loss: 25.2041. Test KLD loss: 1.5111. Time: 725.41\n",
      "<-- Epoch: 101. Average Train loss: 20.9400. Train Reconstruction loss: 18.2601. Train KLD loss: 2.6799. Time: 726.41\n",
      "<-- Epoch: 101. Average Test loss: 26.8597. Test Reconstruction loss: 25.3420. Test KLD loss: 1.5178. Time: 726.71\n",
      "<-- Epoch: 102. Average Train loss: 20.7875. Train Reconstruction loss: 18.0912. Train KLD loss: 2.6963. Time: 727.71\n",
      "<-- Epoch: 102. Average Test loss: 27.0387. Test Reconstruction loss: 25.4434. Test KLD loss: 1.5952. Time: 728.00\n",
      "<-- Epoch: 103. Average Train loss: 20.8954. Train Reconstruction loss: 18.1212. Train KLD loss: 2.7741. Time: 729.03\n",
      "<-- Epoch: 103. Average Test loss: 26.7401. Test Reconstruction loss: 25.1945. Test KLD loss: 1.5456. Time: 729.44\n",
      "<-- Epoch: 104. Average Train loss: 20.7110. Train Reconstruction loss: 17.8583. Train KLD loss: 2.8527. Time: 730.98\n",
      "<-- Epoch: 104. Average Test loss: 26.9361. Test Reconstruction loss: 25.4204. Test KLD loss: 1.5157. Time: 731.72\n",
      "<-- Epoch: 105. Average Train loss: 20.7163. Train Reconstruction loss: 17.8783. Train KLD loss: 2.8380. Time: 733.70\n",
      "<-- Epoch: 105. Average Test loss: 27.0419. Test Reconstruction loss: 25.3788. Test KLD loss: 1.6632. Time: 734.18\n",
      "<-- Epoch: 106. Average Train loss: 20.6842. Train Reconstruction loss: 17.7431. Train KLD loss: 2.9411. Time: 735.73\n",
      "<-- Epoch: 106. Average Test loss: 26.9505. Test Reconstruction loss: 25.4058. Test KLD loss: 1.5448. Time: 736.29\n",
      "<-- Epoch: 107. Average Train loss: 20.5153. Train Reconstruction loss: 17.5947. Train KLD loss: 2.9207. Time: 737.62\n",
      "<-- Epoch: 107. Average Test loss: 27.0762. Test Reconstruction loss: 25.4050. Test KLD loss: 1.6712. Time: 737.95\n",
      "<-- Epoch: 108. Average Train loss: 20.4382. Train Reconstruction loss: 17.4442. Train KLD loss: 2.9940. Time: 739.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 108. Average Test loss: 27.2466. Test Reconstruction loss: 25.4794. Test KLD loss: 1.7671. Time: 740.23\n",
      "<-- Epoch: 109. Average Train loss: 20.5593. Train Reconstruction loss: 17.4330. Train KLD loss: 3.1263. Time: 742.60\n",
      "<-- Epoch: 109. Average Test loss: 27.2272. Test Reconstruction loss: 25.4312. Test KLD loss: 1.7960. Time: 743.30\n",
      "<-- Epoch: 110. Average Train loss: 20.4402. Train Reconstruction loss: 17.2313. Train KLD loss: 3.2090. Time: 745.39\n",
      "<-- Epoch: 110. Average Test loss: 27.4312. Test Reconstruction loss: 25.6416. Test KLD loss: 1.7896. Time: 746.08\n",
      "<-- Epoch: 111. Average Train loss: 20.5390. Train Reconstruction loss: 17.2221. Train KLD loss: 3.3169. Time: 748.34\n",
      "<-- Epoch: 111. Average Test loss: 27.5367. Test Reconstruction loss: 25.2221. Test KLD loss: 2.3146. Time: 748.90\n",
      "<-- Epoch: 112. Average Train loss: 20.4337. Train Reconstruction loss: 17.0429. Train KLD loss: 3.3908. Time: 750.92\n",
      "<-- Epoch: 112. Average Test loss: 27.3984. Test Reconstruction loss: 25.5960. Test KLD loss: 1.8024. Time: 751.53\n",
      "<-- Epoch: 113. Average Train loss: 20.3057. Train Reconstruction loss: 16.8799. Train KLD loss: 3.4258. Time: 752.83\n",
      "<-- Epoch: 113. Average Test loss: 27.6619. Test Reconstruction loss: 25.5654. Test KLD loss: 2.0964. Time: 753.14\n",
      "<-- Epoch: 114. Average Train loss: 20.2160. Train Reconstruction loss: 16.7935. Train KLD loss: 3.4225. Time: 754.17\n",
      "<-- Epoch: 114. Average Test loss: 27.8173. Test Reconstruction loss: 25.8734. Test KLD loss: 1.9439. Time: 754.47\n",
      "<-- Epoch: 115. Average Train loss: 20.1218. Train Reconstruction loss: 16.6171. Train KLD loss: 3.5046. Time: 755.54\n",
      "<-- Epoch: 115. Average Test loss: 27.8073. Test Reconstruction loss: 25.8571. Test KLD loss: 1.9501. Time: 755.85\n",
      "<-- Epoch: 116. Average Train loss: 20.0786. Train Reconstruction loss: 16.5853. Train KLD loss: 3.4932. Time: 756.97\n",
      "<-- Epoch: 116. Average Test loss: 27.5707. Test Reconstruction loss: 25.7413. Test KLD loss: 1.8294. Time: 757.30\n",
      "<-- Epoch: 117. Average Train loss: 19.9266. Train Reconstruction loss: 16.3012. Train KLD loss: 3.6254. Time: 758.41\n",
      "<-- Epoch: 117. Average Test loss: 27.9085. Test Reconstruction loss: 25.6697. Test KLD loss: 2.2388. Time: 758.76\n",
      "<-- Epoch: 118. Average Train loss: 19.9640. Train Reconstruction loss: 16.2762. Train KLD loss: 3.6878. Time: 759.93\n",
      "<-- Epoch: 118. Average Test loss: 28.0369. Test Reconstruction loss: 25.8621. Test KLD loss: 2.1748. Time: 760.26\n",
      "<-- Epoch: 119. Average Train loss: 19.8251. Train Reconstruction loss: 16.1620. Train KLD loss: 3.6631. Time: 761.32\n",
      "<-- Epoch: 119. Average Test loss: 27.8768. Test Reconstruction loss: 25.8265. Test KLD loss: 2.0504. Time: 761.66\n",
      "<-- Epoch: 120. Average Train loss: 19.8938. Train Reconstruction loss: 16.1182. Train KLD loss: 3.7755. Time: 762.86\n",
      "<-- Epoch: 120. Average Test loss: 28.1936. Test Reconstruction loss: 25.6023. Test KLD loss: 2.5914. Time: 763.30\n",
      "<-- Epoch: 121. Average Train loss: 20.0165. Train Reconstruction loss: 16.1132. Train KLD loss: 3.9033. Time: 764.68\n",
      "<-- Epoch: 121. Average Test loss: 28.2168. Test Reconstruction loss: 25.9149. Test KLD loss: 2.3019. Time: 765.04\n",
      "<-- Epoch: 122. Average Train loss: 19.6708. Train Reconstruction loss: 15.8674. Train KLD loss: 3.8034. Time: 766.23\n",
      "<-- Epoch: 122. Average Test loss: 27.9870. Test Reconstruction loss: 25.7840. Test KLD loss: 2.2030. Time: 766.59\n",
      "<-- Epoch: 123. Average Train loss: 19.7807. Train Reconstruction loss: 15.7330. Train KLD loss: 4.0477. Time: 767.76\n",
      "<-- Epoch: 123. Average Test loss: 28.2739. Test Reconstruction loss: 25.9536. Test KLD loss: 2.3202. Time: 768.08\n",
      "<-- Epoch: 124. Average Train loss: 19.5746. Train Reconstruction loss: 15.5528. Train KLD loss: 4.0218. Time: 769.27\n",
      "<-- Epoch: 124. Average Test loss: 28.3326. Test Reconstruction loss: 25.8600. Test KLD loss: 2.4726. Time: 769.60\n",
      "<-- Epoch: 125. Average Train loss: 19.5641. Train Reconstruction loss: 15.4720. Train KLD loss: 4.0921. Time: 771.11\n",
      "<-- Epoch: 125. Average Test loss: 28.6079. Test Reconstruction loss: 26.3120. Test KLD loss: 2.2959. Time: 771.57\n",
      "<-- Epoch: 126. Average Train loss: 19.5248. Train Reconstruction loss: 15.3587. Train KLD loss: 4.1661. Time: 772.86\n",
      "<-- Epoch: 126. Average Test loss: 28.8604. Test Reconstruction loss: 25.8181. Test KLD loss: 3.0423. Time: 773.23\n",
      "<-- Epoch: 127. Average Train loss: 19.4501. Train Reconstruction loss: 15.1722. Train KLD loss: 4.2780. Time: 774.61\n",
      "<-- Epoch: 127. Average Test loss: 28.7875. Test Reconstruction loss: 26.5059. Test KLD loss: 2.2815. Time: 774.91\n",
      "<-- Epoch: 128. Average Train loss: 19.5492. Train Reconstruction loss: 15.2255. Train KLD loss: 4.3237. Time: 776.01\n",
      "<-- Epoch: 128. Average Test loss: 28.5301. Test Reconstruction loss: 25.9413. Test KLD loss: 2.5887. Time: 776.34\n",
      "<-- Epoch: 129. Average Train loss: 19.4579. Train Reconstruction loss: 15.0789. Train KLD loss: 4.3790. Time: 777.47\n",
      "<-- Epoch: 129. Average Test loss: 28.9311. Test Reconstruction loss: 26.4749. Test KLD loss: 2.4562. Time: 777.81\n",
      "<-- Epoch: 130. Average Train loss: 19.4630. Train Reconstruction loss: 14.9561. Train KLD loss: 4.5069. Time: 778.96\n",
      "<-- Epoch: 130. Average Test loss: 28.8813. Test Reconstruction loss: 26.3763. Test KLD loss: 2.5049. Time: 779.27\n",
      "<-- Epoch: 131. Average Train loss: 18.9768. Train Reconstruction loss: 14.5851. Train KLD loss: 4.3917. Time: 780.31\n",
      "<-- Epoch: 131. Average Test loss: 28.9480. Test Reconstruction loss: 26.3223. Test KLD loss: 2.6257. Time: 780.61\n",
      "<-- Epoch: 132. Average Train loss: 19.2658. Train Reconstruction loss: 14.7056. Train KLD loss: 4.5602. Time: 781.76\n",
      "<-- Epoch: 132. Average Test loss: 29.5449. Test Reconstruction loss: 26.6706. Test KLD loss: 2.8743. Time: 782.11\n",
      "<-- Epoch: 133. Average Train loss: 19.1200. Train Reconstruction loss: 14.5561. Train KLD loss: 4.5638. Time: 783.24\n",
      "<-- Epoch: 133. Average Test loss: 29.3290. Test Reconstruction loss: 26.5939. Test KLD loss: 2.7351. Time: 783.62\n",
      "<-- Epoch: 134. Average Train loss: 19.0383. Train Reconstruction loss: 14.4857. Train KLD loss: 4.5526. Time: 784.87\n",
      "<-- Epoch: 134. Average Test loss: 29.0244. Test Reconstruction loss: 26.4648. Test KLD loss: 2.5596. Time: 785.20\n",
      "<-- Epoch: 135. Average Train loss: 18.8654. Train Reconstruction loss: 14.2237. Train KLD loss: 4.6417. Time: 786.31\n",
      "<-- Epoch: 135. Average Test loss: 29.4842. Test Reconstruction loss: 26.7147. Test KLD loss: 2.7695. Time: 786.68\n",
      "<-- Epoch: 136. Average Train loss: 18.9386. Train Reconstruction loss: 14.2284. Train KLD loss: 4.7102. Time: 787.94\n",
      "<-- Epoch: 136. Average Test loss: 29.9466. Test Reconstruction loss: 26.7893. Test KLD loss: 3.1573. Time: 788.27\n",
      "<-- Epoch: 137. Average Train loss: 18.7527. Train Reconstruction loss: 14.0209. Train KLD loss: 4.7318. Time: 789.46\n",
      "<-- Epoch: 137. Average Test loss: 29.8297. Test Reconstruction loss: 26.9657. Test KLD loss: 2.8640. Time: 789.76\n",
      "<-- Epoch: 138. Average Train loss: 18.6119. Train Reconstruction loss: 13.8805. Train KLD loss: 4.7315. Time: 791.38\n",
      "<-- Epoch: 138. Average Test loss: 29.6780. Test Reconstruction loss: 26.7618. Test KLD loss: 2.9162. Time: 791.77\n",
      "<-- Epoch: 139. Average Train loss: 18.5834. Train Reconstruction loss: 13.6982. Train KLD loss: 4.8852. Time: 792.89\n",
      "<-- Epoch: 139. Average Test loss: 29.7227. Test Reconstruction loss: 26.4145. Test KLD loss: 3.3082. Time: 793.22\n",
      "<-- Epoch: 140. Average Train loss: 18.7511. Train Reconstruction loss: 13.7955. Train KLD loss: 4.9556. Time: 794.55\n",
      "<-- Epoch: 140. Average Test loss: 29.7032. Test Reconstruction loss: 26.5702. Test KLD loss: 3.1330. Time: 794.93\n",
      "<-- Epoch: 141. Average Train loss: 18.5664. Train Reconstruction loss: 13.5329. Train KLD loss: 5.0335. Time: 796.24\n",
      "<-- Epoch: 141. Average Test loss: 30.3080. Test Reconstruction loss: 27.2449. Test KLD loss: 3.0631. Time: 796.60\n",
      "<-- Epoch: 142. Average Train loss: 18.4020. Train Reconstruction loss: 13.4684. Train KLD loss: 4.9337. Time: 797.75\n",
      "<-- Epoch: 142. Average Test loss: 29.9547. Test Reconstruction loss: 26.6823. Test KLD loss: 3.2724. Time: 798.05\n",
      "<-- Epoch: 143. Average Train loss: 18.4451. Train Reconstruction loss: 13.4002. Train KLD loss: 5.0449. Time: 799.08\n",
      "<-- Epoch: 143. Average Test loss: 30.2486. Test Reconstruction loss: 26.9323. Test KLD loss: 3.3163. Time: 799.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 144. Average Train loss: 18.3352. Train Reconstruction loss: 13.2289. Train KLD loss: 5.1062. Time: 800.42\n",
      "<-- Epoch: 144. Average Test loss: 30.4579. Test Reconstruction loss: 27.6036. Test KLD loss: 2.8543. Time: 800.72\n",
      "<-- Epoch: 145. Average Train loss: 18.3676. Train Reconstruction loss: 13.1574. Train KLD loss: 5.2102. Time: 802.02\n",
      "<-- Epoch: 145. Average Test loss: 30.3995. Test Reconstruction loss: 27.1803. Test KLD loss: 3.2192. Time: 802.45\n",
      "<-- Epoch: 146. Average Train loss: 18.2921. Train Reconstruction loss: 13.0446. Train KLD loss: 5.2474. Time: 803.78\n",
      "<-- Epoch: 146. Average Test loss: 30.7752. Test Reconstruction loss: 27.3993. Test KLD loss: 3.3759. Time: 804.22\n",
      "<-- Epoch: 147. Average Train loss: 18.3213. Train Reconstruction loss: 12.9584. Train KLD loss: 5.3630. Time: 805.71\n",
      "<-- Epoch: 147. Average Test loss: 30.7502. Test Reconstruction loss: 27.4212. Test KLD loss: 3.3290. Time: 806.16\n",
      "<-- Epoch: 148. Average Train loss: 18.2371. Train Reconstruction loss: 12.8304. Train KLD loss: 5.4068. Time: 807.27\n",
      "<-- Epoch: 148. Average Test loss: 30.8082. Test Reconstruction loss: 27.5088. Test KLD loss: 3.2994. Time: 807.61\n",
      "<-- Epoch: 149. Average Train loss: 18.0527. Train Reconstruction loss: 12.7029. Train KLD loss: 5.3498. Time: 808.86\n",
      "<-- Epoch: 149. Average Test loss: 30.9244. Test Reconstruction loss: 27.9048. Test KLD loss: 3.0196. Time: 809.30\n",
      "<-- Epoch: 150. Average Train loss: 18.0382. Train Reconstruction loss: 12.5605. Train KLD loss: 5.4776. Time: 810.46\n",
      "<-- Epoch: 150. Average Test loss: 30.7756. Test Reconstruction loss: 27.6675. Test KLD loss: 3.1081. Time: 810.84\n",
      "<-- Epoch: 151. Average Train loss: 17.9600. Train Reconstruction loss: 12.3953. Train KLD loss: 5.5647. Time: 812.05\n",
      "<-- Epoch: 151. Average Test loss: 31.2152. Test Reconstruction loss: 27.8309. Test KLD loss: 3.3843. Time: 812.40\n",
      "<-- Epoch: 152. Average Train loss: 17.9963. Train Reconstruction loss: 12.4624. Train KLD loss: 5.5339. Time: 813.64\n",
      "<-- Epoch: 152. Average Test loss: 31.5473. Test Reconstruction loss: 28.0123. Test KLD loss: 3.5351. Time: 813.97\n",
      "<-- Epoch: 153. Average Train loss: 17.7509. Train Reconstruction loss: 12.2812. Train KLD loss: 5.4697. Time: 815.32\n",
      "<-- Epoch: 153. Average Test loss: 31.1831. Test Reconstruction loss: 27.5833. Test KLD loss: 3.5998. Time: 815.64\n",
      "<-- Epoch: 154. Average Train loss: 17.8667. Train Reconstruction loss: 12.2266. Train KLD loss: 5.6400. Time: 816.81\n",
      "<-- Epoch: 154. Average Test loss: 31.3598. Test Reconstruction loss: 27.5251. Test KLD loss: 3.8347. Time: 817.18\n",
      "<-- Epoch: 155. Average Train loss: 17.7012. Train Reconstruction loss: 12.0335. Train KLD loss: 5.6677. Time: 818.39\n",
      "<-- Epoch: 155. Average Test loss: 31.6619. Test Reconstruction loss: 28.3821. Test KLD loss: 3.2797. Time: 818.76\n",
      "<-- Epoch: 156. Average Train loss: 17.7337. Train Reconstruction loss: 11.9280. Train KLD loss: 5.8057. Time: 819.93\n",
      "<-- Epoch: 156. Average Test loss: 32.3382. Test Reconstruction loss: 27.9265. Test KLD loss: 4.4117. Time: 820.28\n",
      "<-- Epoch: 157. Average Train loss: 17.6421. Train Reconstruction loss: 11.9088. Train KLD loss: 5.7332. Time: 821.51\n",
      "<-- Epoch: 157. Average Test loss: 31.7743. Test Reconstruction loss: 27.8081. Test KLD loss: 3.9662. Time: 821.81\n",
      "<-- Epoch: 158. Average Train loss: 17.4887. Train Reconstruction loss: 11.6904. Train KLD loss: 5.7983. Time: 822.92\n",
      "<-- Epoch: 158. Average Test loss: 32.3116. Test Reconstruction loss: 28.7569. Test KLD loss: 3.5547. Time: 823.24\n",
      "<-- Epoch: 159. Average Train loss: 17.7056. Train Reconstruction loss: 11.8350. Train KLD loss: 5.8706. Time: 824.42\n",
      "<-- Epoch: 159. Average Test loss: 32.2205. Test Reconstruction loss: 28.1116. Test KLD loss: 4.1089. Time: 824.76\n",
      "<-- Epoch: 160. Average Train loss: 17.4080. Train Reconstruction loss: 11.5116. Train KLD loss: 5.8964. Time: 826.00\n",
      "<-- Epoch: 160. Average Test loss: 32.3869. Test Reconstruction loss: 27.9927. Test KLD loss: 4.3942. Time: 826.97\n",
      "<-- Epoch: 161. Average Train loss: 17.3631. Train Reconstruction loss: 11.4295. Train KLD loss: 5.9335. Time: 829.02\n",
      "<-- Epoch: 161. Average Test loss: 32.7914. Test Reconstruction loss: 29.0828. Test KLD loss: 3.7086. Time: 829.65\n",
      "<-- Epoch: 162. Average Train loss: 17.3774. Train Reconstruction loss: 11.3666. Train KLD loss: 6.0107. Time: 831.86\n",
      "<-- Epoch: 162. Average Test loss: 32.5761. Test Reconstruction loss: 28.0479. Test KLD loss: 4.5281. Time: 832.50\n",
      "<-- Epoch: 163. Average Train loss: 17.2472. Train Reconstruction loss: 11.1623. Train KLD loss: 6.0849. Time: 834.01\n",
      "<-- Epoch: 163. Average Test loss: 32.5152. Test Reconstruction loss: 29.0283. Test KLD loss: 3.4869. Time: 834.81\n",
      "<-- Epoch: 164. Average Train loss: 17.3777. Train Reconstruction loss: 11.2974. Train KLD loss: 6.0803. Time: 836.76\n",
      "<-- Epoch: 164. Average Test loss: 33.0395. Test Reconstruction loss: 28.3979. Test KLD loss: 4.6416. Time: 837.29\n",
      "<-- Epoch: 165. Average Train loss: 17.2970. Train Reconstruction loss: 11.1761. Train KLD loss: 6.1209. Time: 838.82\n",
      "<-- Epoch: 165. Average Test loss: 32.6313. Test Reconstruction loss: 28.5367. Test KLD loss: 4.0946. Time: 839.36\n",
      "<-- Epoch: 166. Average Train loss: 16.9496. Train Reconstruction loss: 10.8317. Train KLD loss: 6.1179. Time: 840.89\n",
      "<-- Epoch: 166. Average Test loss: 33.1539. Test Reconstruction loss: 29.2630. Test KLD loss: 3.8908. Time: 841.22\n",
      "<-- Epoch: 167. Average Train loss: 17.0404. Train Reconstruction loss: 10.8304. Train KLD loss: 6.2100. Time: 842.53\n",
      "<-- Epoch: 167. Average Test loss: 33.6312. Test Reconstruction loss: 29.1875. Test KLD loss: 4.4436. Time: 842.95\n",
      "<-- Epoch: 168. Average Train loss: 17.0409. Train Reconstruction loss: 10.7895. Train KLD loss: 6.2514. Time: 844.38\n",
      "<-- Epoch: 168. Average Test loss: 33.3133. Test Reconstruction loss: 29.2189. Test KLD loss: 4.0944. Time: 844.75\n",
      "<-- Epoch: 169. Average Train loss: 17.0570. Train Reconstruction loss: 10.7294. Train KLD loss: 6.3276. Time: 845.92\n",
      "<-- Epoch: 169. Average Test loss: 33.8023. Test Reconstruction loss: 29.5861. Test KLD loss: 4.2162. Time: 846.28\n",
      "<-- Epoch: 170. Average Train loss: 16.9496. Train Reconstruction loss: 10.6545. Train KLD loss: 6.2951. Time: 847.58\n",
      "<-- Epoch: 170. Average Test loss: 33.6991. Test Reconstruction loss: 29.0128. Test KLD loss: 4.6863. Time: 848.09\n",
      "<-- Epoch: 171. Average Train loss: 16.9538. Train Reconstruction loss: 10.5344. Train KLD loss: 6.4193. Time: 849.27\n",
      "<-- Epoch: 171. Average Test loss: 33.8495. Test Reconstruction loss: 29.2576. Test KLD loss: 4.5919. Time: 849.65\n",
      "<-- Epoch: 172. Average Train loss: 16.7705. Train Reconstruction loss: 10.4142. Train KLD loss: 6.3564. Time: 850.74\n",
      "<-- Epoch: 172. Average Test loss: 33.7403. Test Reconstruction loss: 29.2499. Test KLD loss: 4.4904. Time: 851.13\n",
      "<-- Epoch: 173. Average Train loss: 16.6913. Train Reconstruction loss: 10.2442. Train KLD loss: 6.4471. Time: 852.27\n",
      "<-- Epoch: 173. Average Test loss: 34.2476. Test Reconstruction loss: 29.9467. Test KLD loss: 4.3009. Time: 852.69\n",
      "<-- Epoch: 174. Average Train loss: 16.7491. Train Reconstruction loss: 10.2697. Train KLD loss: 6.4794. Time: 854.02\n",
      "<-- Epoch: 174. Average Test loss: 34.1580. Test Reconstruction loss: 29.9674. Test KLD loss: 4.1907. Time: 854.45\n",
      "<-- Epoch: 175. Average Train loss: 16.6248. Train Reconstruction loss: 10.1375. Train KLD loss: 6.4873. Time: 855.81\n",
      "<-- Epoch: 175. Average Test loss: 33.9960. Test Reconstruction loss: 29.5074. Test KLD loss: 4.4886. Time: 856.12\n",
      "<-- Epoch: 176. Average Train loss: 16.6473. Train Reconstruction loss: 10.1023. Train KLD loss: 6.5451. Time: 857.64\n",
      "<-- Epoch: 176. Average Test loss: 34.5147. Test Reconstruction loss: 29.9775. Test KLD loss: 4.5372. Time: 858.11\n",
      "<-- Epoch: 177. Average Train loss: 16.7228. Train Reconstruction loss: 10.0606. Train KLD loss: 6.6621. Time: 859.62\n",
      "<-- Epoch: 177. Average Test loss: 34.3842. Test Reconstruction loss: 29.7263. Test KLD loss: 4.6579. Time: 860.05\n",
      "<-- Epoch: 178. Average Train loss: 16.6272. Train Reconstruction loss: 9.8928. Train KLD loss: 6.7344. Time: 861.74\n",
      "<-- Epoch: 178. Average Test loss: 34.4233. Test Reconstruction loss: 29.8428. Test KLD loss: 4.5805. Time: 862.32\n",
      "<-- Epoch: 179. Average Train loss: 16.4152. Train Reconstruction loss: 9.8137. Train KLD loss: 6.6015. Time: 864.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 179. Average Test loss: 34.9751. Test Reconstruction loss: 30.6535. Test KLD loss: 4.3216. Time: 864.63\n",
      "<-- Epoch: 180. Average Train loss: 16.4923. Train Reconstruction loss: 9.7694. Train KLD loss: 6.7230. Time: 866.46\n",
      "<-- Epoch: 180. Average Test loss: 35.4083. Test Reconstruction loss: 30.5183. Test KLD loss: 4.8900. Time: 867.04\n",
      "<-- Epoch: 181. Average Train loss: 16.2940. Train Reconstruction loss: 9.6504. Train KLD loss: 6.6437. Time: 868.37\n",
      "<-- Epoch: 181. Average Test loss: 34.9995. Test Reconstruction loss: 30.4156. Test KLD loss: 4.5839. Time: 868.70\n",
      "<-- Epoch: 182. Average Train loss: 16.3510. Train Reconstruction loss: 9.5334. Train KLD loss: 6.8177. Time: 869.97\n",
      "<-- Epoch: 182. Average Test loss: 35.3080. Test Reconstruction loss: 31.1175. Test KLD loss: 4.1905. Time: 870.35\n",
      "<-- Epoch: 183. Average Train loss: 16.1859. Train Reconstruction loss: 9.3693. Train KLD loss: 6.8167. Time: 871.66\n",
      "<-- Epoch: 183. Average Test loss: 36.0857. Test Reconstruction loss: 31.7650. Test KLD loss: 4.3207. Time: 872.00\n",
      "<-- Epoch: 184. Average Train loss: 16.2957. Train Reconstruction loss: 9.4067. Train KLD loss: 6.8890. Time: 873.11\n",
      "<-- Epoch: 184. Average Test loss: 35.5188. Test Reconstruction loss: 30.9780. Test KLD loss: 4.5408. Time: 873.48\n",
      "<-- Epoch: 185. Average Train loss: 16.1164. Train Reconstruction loss: 9.2917. Train KLD loss: 6.8247. Time: 874.73\n",
      "<-- Epoch: 185. Average Test loss: 35.9367. Test Reconstruction loss: 30.8837. Test KLD loss: 5.0531. Time: 875.20\n",
      "<-- Epoch: 186. Average Train loss: 16.2251. Train Reconstruction loss: 9.1950. Train KLD loss: 7.0301. Time: 877.02\n",
      "<-- Epoch: 186. Average Test loss: 35.9405. Test Reconstruction loss: 31.4022. Test KLD loss: 4.5383. Time: 877.76\n",
      "<-- Epoch: 187. Average Train loss: 15.9393. Train Reconstruction loss: 8.9995. Train KLD loss: 6.9398. Time: 879.85\n",
      "<-- Epoch: 187. Average Test loss: 35.9469. Test Reconstruction loss: 30.9769. Test KLD loss: 4.9700. Time: 880.46\n",
      "<-- Epoch: 188. Average Train loss: 15.8369. Train Reconstruction loss: 8.9226. Train KLD loss: 6.9143. Time: 882.71\n",
      "<-- Epoch: 188. Average Test loss: 36.2020. Test Reconstruction loss: 31.4023. Test KLD loss: 4.7997. Time: 883.39\n",
      "<-- Epoch: 189. Average Train loss: 16.0814. Train Reconstruction loss: 9.0040. Train KLD loss: 7.0774. Time: 886.30\n",
      "<-- Epoch: 189. Average Test loss: 36.1908. Test Reconstruction loss: 31.2737. Test KLD loss: 4.9171. Time: 886.77\n",
      "<-- Epoch: 190. Average Train loss: 15.8131. Train Reconstruction loss: 8.7777. Train KLD loss: 7.0354. Time: 888.98\n",
      "<-- Epoch: 190. Average Test loss: 36.3589. Test Reconstruction loss: 31.8205. Test KLD loss: 4.5384. Time: 889.50\n",
      "<-- Epoch: 191. Average Train loss: 15.9482. Train Reconstruction loss: 8.9404. Train KLD loss: 7.0079. Time: 891.32\n",
      "<-- Epoch: 191. Average Test loss: 36.8634. Test Reconstruction loss: 31.6583. Test KLD loss: 5.2051. Time: 891.83\n",
      "<-- Epoch: 192. Average Train loss: 15.9807. Train Reconstruction loss: 8.8171. Train KLD loss: 7.1636. Time: 893.73\n",
      "<-- Epoch: 192. Average Test loss: 36.6867. Test Reconstruction loss: 31.5775. Test KLD loss: 5.1092. Time: 894.29\n",
      "<-- Epoch: 193. Average Train loss: 16.0118. Train Reconstruction loss: 8.8340. Train KLD loss: 7.1778. Time: 896.14\n",
      "<-- Epoch: 193. Average Test loss: 37.1094. Test Reconstruction loss: 32.7215. Test KLD loss: 4.3880. Time: 896.54\n",
      "<-- Epoch: 194. Average Train loss: 15.6414. Train Reconstruction loss: 8.6156. Train KLD loss: 7.0258. Time: 897.62\n",
      "<-- Epoch: 194. Average Test loss: 37.0264. Test Reconstruction loss: 31.7363. Test KLD loss: 5.2901. Time: 898.08\n",
      "<-- Epoch: 195. Average Train loss: 15.6359. Train Reconstruction loss: 8.5461. Train KLD loss: 7.0898. Time: 899.28\n",
      "<-- Epoch: 195. Average Test loss: 37.3419. Test Reconstruction loss: 32.9276. Test KLD loss: 4.4143. Time: 899.58\n",
      "<-- Epoch: 196. Average Train loss: 15.6947. Train Reconstruction loss: 8.5004. Train KLD loss: 7.1943. Time: 900.62\n",
      "<-- Epoch: 196. Average Test loss: 37.3067. Test Reconstruction loss: 32.7059. Test KLD loss: 4.6008. Time: 900.94\n",
      "<-- Epoch: 197. Average Train loss: 15.6419. Train Reconstruction loss: 8.5331. Train KLD loss: 7.1088. Time: 902.12\n",
      "<-- Epoch: 197. Average Test loss: 37.9094. Test Reconstruction loss: 32.5970. Test KLD loss: 5.3124. Time: 902.50\n",
      "<-- Epoch: 198. Average Train loss: 15.6443. Train Reconstruction loss: 8.4120. Train KLD loss: 7.2323. Time: 903.95\n",
      "<-- Epoch: 198. Average Test loss: 37.9159. Test Reconstruction loss: 33.1219. Test KLD loss: 4.7940. Time: 904.30\n",
      "<-- Epoch: 199. Average Train loss: 15.5631. Train Reconstruction loss: 8.2662. Train KLD loss: 7.2970. Time: 905.38\n",
      "<-- Epoch: 199. Average Test loss: 38.0495. Test Reconstruction loss: 33.0252. Test KLD loss: 5.0243. Time: 905.69\n",
      "<-- Epoch: 200. Average Train loss: 15.7406. Train Reconstruction loss: 8.4058. Train KLD loss: 7.3349. Time: 906.86\n",
      "<-- Epoch: 200. Average Test loss: 38.3060. Test Reconstruction loss: 32.7274. Test KLD loss: 5.5786. Time: 907.26\n",
      "<-- Epoch: 201. Average Train loss: 15.5354. Train Reconstruction loss: 8.2578. Train KLD loss: 7.2776. Time: 908.61\n",
      "<-- Epoch: 201. Average Test loss: 37.7722. Test Reconstruction loss: 32.3409. Test KLD loss: 5.4313. Time: 908.90\n",
      "<-- Epoch: 202. Average Train loss: 15.4208. Train Reconstruction loss: 8.0886. Train KLD loss: 7.3322. Time: 910.20\n",
      "<-- Epoch: 202. Average Test loss: 37.9347. Test Reconstruction loss: 32.9564. Test KLD loss: 4.9782. Time: 910.59\n",
      "<-- Epoch: 203. Average Train loss: 15.3528. Train Reconstruction loss: 8.0124. Train KLD loss: 7.3403. Time: 911.86\n",
      "<-- Epoch: 203. Average Test loss: 38.5526. Test Reconstruction loss: 33.3214. Test KLD loss: 5.2312. Time: 912.20\n",
      "<-- Epoch: 204. Average Train loss: 15.6057. Train Reconstruction loss: 8.2146. Train KLD loss: 7.3911. Time: 913.60\n",
      "<-- Epoch: 204. Average Test loss: 38.2904. Test Reconstruction loss: 32.7005. Test KLD loss: 5.5898. Time: 913.98\n",
      "<-- Epoch: 205. Average Train loss: 15.3090. Train Reconstruction loss: 7.9837. Train KLD loss: 7.3253. Time: 915.24\n",
      "<-- Epoch: 205. Average Test loss: 38.7913. Test Reconstruction loss: 33.1734. Test KLD loss: 5.6178. Time: 915.65\n",
      "<-- Epoch: 206. Average Train loss: 15.4315. Train Reconstruction loss: 7.9330. Train KLD loss: 7.4985. Time: 917.14\n",
      "<-- Epoch: 206. Average Test loss: 38.9285. Test Reconstruction loss: 33.1065. Test KLD loss: 5.8220. Time: 917.57\n",
      "<-- Epoch: 207. Average Train loss: 15.4662. Train Reconstruction loss: 7.8911. Train KLD loss: 7.5751. Time: 918.77\n",
      "<-- Epoch: 207. Average Test loss: 38.9709. Test Reconstruction loss: 33.9609. Test KLD loss: 5.0100. Time: 919.07\n",
      "<-- Epoch: 208. Average Train loss: 15.2723. Train Reconstruction loss: 7.7712. Train KLD loss: 7.5011. Time: 920.10\n",
      "<-- Epoch: 208. Average Test loss: 38.7825. Test Reconstruction loss: 33.3936. Test KLD loss: 5.3890. Time: 920.41\n",
      "<-- Epoch: 209. Average Train loss: 15.3010. Train Reconstruction loss: 7.8642. Train KLD loss: 7.4368. Time: 921.41\n",
      "<-- Epoch: 209. Average Test loss: 39.1526. Test Reconstruction loss: 33.9534. Test KLD loss: 5.1992. Time: 921.71\n",
      "<-- Epoch: 210. Average Train loss: 15.2468. Train Reconstruction loss: 7.6855. Train KLD loss: 7.5614. Time: 922.72\n",
      "<-- Epoch: 210. Average Test loss: 39.7518. Test Reconstruction loss: 34.5954. Test KLD loss: 5.1564. Time: 923.01\n",
      "<-- Epoch: 211. Average Train loss: 15.1730. Train Reconstruction loss: 7.6154. Train KLD loss: 7.5576. Time: 924.06\n",
      "<-- Epoch: 211. Average Test loss: 39.9396. Test Reconstruction loss: 34.7465. Test KLD loss: 5.1931. Time: 924.37\n",
      "<-- Epoch: 212. Average Train loss: 15.3046. Train Reconstruction loss: 7.7193. Train KLD loss: 7.5853. Time: 925.38\n",
      "<-- Epoch: 212. Average Test loss: 39.8802. Test Reconstruction loss: 34.9536. Test KLD loss: 4.9266. Time: 925.68\n",
      "<-- Epoch: 213. Average Train loss: 15.1976. Train Reconstruction loss: 7.6453. Train KLD loss: 7.5523. Time: 926.69\n",
      "<-- Epoch: 213. Average Test loss: 40.0044. Test Reconstruction loss: 34.8046. Test KLD loss: 5.1998. Time: 926.98\n",
      "<-- Epoch: 214. Average Train loss: 15.1521. Train Reconstruction loss: 7.5308. Train KLD loss: 7.6213. Time: 927.98\n",
      "<-- Epoch: 214. Average Test loss: 40.1936. Test Reconstruction loss: 34.6017. Test KLD loss: 5.5919. Time: 928.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 215. Average Train loss: 15.0559. Train Reconstruction loss: 7.4396. Train KLD loss: 7.6163. Time: 929.31\n",
      "<-- Epoch: 215. Average Test loss: 40.2229. Test Reconstruction loss: 35.0523. Test KLD loss: 5.1705. Time: 929.61\n",
      "<-- Epoch: 216. Average Train loss: 14.9113. Train Reconstruction loss: 7.3419. Train KLD loss: 7.5694. Time: 930.62\n",
      "<-- Epoch: 216. Average Test loss: 40.3203. Test Reconstruction loss: 34.8490. Test KLD loss: 5.4713. Time: 930.91\n",
      "<-- Epoch: 217. Average Train loss: 15.1992. Train Reconstruction loss: 7.5320. Train KLD loss: 7.6672. Time: 931.92\n",
      "<-- Epoch: 217. Average Test loss: 40.2415. Test Reconstruction loss: 34.6607. Test KLD loss: 5.5808. Time: 932.23\n",
      "<-- Epoch: 218. Average Train loss: 15.0338. Train Reconstruction loss: 7.4837. Train KLD loss: 7.5501. Time: 933.23\n",
      "<-- Epoch: 218. Average Test loss: 41.0429. Test Reconstruction loss: 35.3849. Test KLD loss: 5.6580. Time: 933.53\n",
      "<-- Epoch: 219. Average Train loss: 15.0953. Train Reconstruction loss: 7.3964. Train KLD loss: 7.6990. Time: 934.53\n",
      "<-- Epoch: 219. Average Test loss: 40.7537. Test Reconstruction loss: 35.1077. Test KLD loss: 5.6460. Time: 934.83\n",
      "<-- Epoch: 220. Average Train loss: 14.9152. Train Reconstruction loss: 7.1980. Train KLD loss: 7.7172. Time: 935.84\n",
      "<-- Epoch: 220. Average Test loss: 40.7837. Test Reconstruction loss: 35.5089. Test KLD loss: 5.2748. Time: 936.15\n",
      "<-- Epoch: 221. Average Train loss: 14.9187. Train Reconstruction loss: 7.2451. Train KLD loss: 7.6735. Time: 937.16\n",
      "<-- Epoch: 221. Average Test loss: 41.0987. Test Reconstruction loss: 35.3132. Test KLD loss: 5.7855. Time: 937.46\n",
      "<-- Epoch: 222. Average Train loss: 14.9534. Train Reconstruction loss: 7.1940. Train KLD loss: 7.7594. Time: 938.48\n",
      "<-- Epoch: 222. Average Test loss: 40.8640. Test Reconstruction loss: 34.4147. Test KLD loss: 6.4493. Time: 938.78\n",
      "<-- Epoch: 223. Average Train loss: 15.1719. Train Reconstruction loss: 7.2316. Train KLD loss: 7.9403. Time: 939.79\n",
      "<-- Epoch: 223. Average Test loss: 41.4102. Test Reconstruction loss: 35.3932. Test KLD loss: 6.0170. Time: 940.09\n",
      "<-- Epoch: 224. Average Train loss: 14.7723. Train Reconstruction loss: 7.0261. Train KLD loss: 7.7461. Time: 941.11\n",
      "<-- Epoch: 224. Average Test loss: 41.5564. Test Reconstruction loss: 35.6248. Test KLD loss: 5.9316. Time: 941.41\n",
      "<-- Epoch: 225. Average Train loss: 14.8062. Train Reconstruction loss: 6.9673. Train KLD loss: 7.8389. Time: 942.43\n",
      "<-- Epoch: 225. Average Test loss: 41.7440. Test Reconstruction loss: 36.3823. Test KLD loss: 5.3617. Time: 942.72\n",
      "<-- Epoch: 226. Average Train loss: 14.7846. Train Reconstruction loss: 7.1007. Train KLD loss: 7.6839. Time: 943.74\n",
      "<-- Epoch: 226. Average Test loss: 41.4821. Test Reconstruction loss: 35.4210. Test KLD loss: 6.0611. Time: 944.03\n",
      "<-- Epoch: 227. Average Train loss: 14.8663. Train Reconstruction loss: 6.9914. Train KLD loss: 7.8750. Time: 945.05\n",
      "<-- Epoch: 227. Average Test loss: 42.1389. Test Reconstruction loss: 36.5351. Test KLD loss: 5.6038. Time: 945.40\n",
      "<-- Epoch: 228. Average Train loss: 14.8924. Train Reconstruction loss: 7.0683. Train KLD loss: 7.8241. Time: 946.42\n",
      "<-- Epoch: 228. Average Test loss: 42.0463. Test Reconstruction loss: 36.2249. Test KLD loss: 5.8215. Time: 946.71\n",
      "<-- Epoch: 229. Average Train loss: 14.8287. Train Reconstruction loss: 7.0128. Train KLD loss: 7.8159. Time: 948.02\n",
      "<-- Epoch: 229. Average Test loss: 42.0867. Test Reconstruction loss: 35.9606. Test KLD loss: 6.1261. Time: 948.38\n",
      "<-- Epoch: 230. Average Train loss: 14.7571. Train Reconstruction loss: 6.8574. Train KLD loss: 7.8997. Time: 949.76\n",
      "<-- Epoch: 230. Average Test loss: 42.1340. Test Reconstruction loss: 36.8338. Test KLD loss: 5.3002. Time: 950.09\n",
      "<-- Epoch: 231. Average Train loss: 14.9033. Train Reconstruction loss: 6.8534. Train KLD loss: 8.0499. Time: 951.40\n",
      "<-- Epoch: 231. Average Test loss: 42.3749. Test Reconstruction loss: 36.5250. Test KLD loss: 5.8499. Time: 951.79\n",
      "<-- Epoch: 232. Average Train loss: 14.6267. Train Reconstruction loss: 6.7616. Train KLD loss: 7.8651. Time: 953.16\n",
      "<-- Epoch: 232. Average Test loss: 42.4259. Test Reconstruction loss: 36.5533. Test KLD loss: 5.8725. Time: 953.53\n",
      "<-- Epoch: 233. Average Train loss: 14.5881. Train Reconstruction loss: 6.6813. Train KLD loss: 7.9068. Time: 954.89\n",
      "<-- Epoch: 233. Average Test loss: 42.9079. Test Reconstruction loss: 37.7196. Test KLD loss: 5.1883. Time: 955.29\n",
      "<-- Epoch: 234. Average Train loss: 14.6379. Train Reconstruction loss: 6.6778. Train KLD loss: 7.9601. Time: 956.69\n",
      "<-- Epoch: 234. Average Test loss: 43.1015. Test Reconstruction loss: 37.0749. Test KLD loss: 6.0266. Time: 957.00\n",
      "<-- Epoch: 235. Average Train loss: 14.8152. Train Reconstruction loss: 6.7840. Train KLD loss: 8.0312. Time: 958.31\n",
      "<-- Epoch: 235. Average Test loss: 42.6250. Test Reconstruction loss: 36.9304. Test KLD loss: 5.6946. Time: 958.62\n",
      "<-- Epoch: 236. Average Train loss: 14.6061. Train Reconstruction loss: 6.6176. Train KLD loss: 7.9885. Time: 959.90\n",
      "<-- Epoch: 236. Average Test loss: 42.8561. Test Reconstruction loss: 36.9259. Test KLD loss: 5.9302. Time: 960.37\n",
      "<-- Epoch: 237. Average Train loss: 14.4440. Train Reconstruction loss: 6.4777. Train KLD loss: 7.9663. Time: 961.61\n",
      "<-- Epoch: 237. Average Test loss: 43.2185. Test Reconstruction loss: 37.1949. Test KLD loss: 6.0236. Time: 961.93\n",
      "<-- Epoch: 238. Average Train loss: 14.7464. Train Reconstruction loss: 6.6373. Train KLD loss: 8.1090. Time: 963.10\n",
      "<-- Epoch: 238. Average Test loss: 43.2734. Test Reconstruction loss: 36.9002. Test KLD loss: 6.3731. Time: 963.47\n",
      "<-- Epoch: 239. Average Train loss: 14.5656. Train Reconstruction loss: 6.5668. Train KLD loss: 7.9988. Time: 964.57\n",
      "<-- Epoch: 239. Average Test loss: 43.3451. Test Reconstruction loss: 37.2308. Test KLD loss: 6.1143. Time: 964.88\n",
      "<-- Epoch: 240. Average Train loss: 14.5041. Train Reconstruction loss: 6.4406. Train KLD loss: 8.0635. Time: 966.23\n",
      "<-- Epoch: 240. Average Test loss: 43.1532. Test Reconstruction loss: 37.2033. Test KLD loss: 5.9500. Time: 966.52\n",
      "<-- Epoch: 241. Average Train loss: 14.4930. Train Reconstruction loss: 6.5328. Train KLD loss: 7.9603. Time: 967.53\n",
      "<-- Epoch: 241. Average Test loss: 44.2337. Test Reconstruction loss: 38.1808. Test KLD loss: 6.0529. Time: 967.83\n",
      "<-- Epoch: 242. Average Train loss: 14.5682. Train Reconstruction loss: 6.4543. Train KLD loss: 8.1139. Time: 968.84\n",
      "<-- Epoch: 242. Average Test loss: 43.7534. Test Reconstruction loss: 37.6921. Test KLD loss: 6.0613. Time: 969.15\n",
      "<-- Epoch: 243. Average Train loss: 14.5316. Train Reconstruction loss: 6.4849. Train KLD loss: 8.0466. Time: 970.20\n",
      "<-- Epoch: 243. Average Test loss: 44.1477. Test Reconstruction loss: 38.1449. Test KLD loss: 6.0028. Time: 970.50\n",
      "<-- Epoch: 244. Average Train loss: 14.6115. Train Reconstruction loss: 6.4864. Train KLD loss: 8.1251. Time: 971.78\n",
      "<-- Epoch: 244. Average Test loss: 43.7188. Test Reconstruction loss: 37.5419. Test KLD loss: 6.1769. Time: 972.19\n",
      "<-- Epoch: 245. Average Train loss: 14.3149. Train Reconstruction loss: 6.2226. Train KLD loss: 8.0923. Time: 973.23\n",
      "<-- Epoch: 245. Average Test loss: 44.1497. Test Reconstruction loss: 38.2194. Test KLD loss: 5.9303. Time: 973.51\n",
      "<-- Epoch: 246. Average Train loss: 14.3249. Train Reconstruction loss: 6.2446. Train KLD loss: 8.0803. Time: 974.53\n",
      "<-- Epoch: 246. Average Test loss: 44.4570. Test Reconstruction loss: 38.3740. Test KLD loss: 6.0830. Time: 974.82\n",
      "<-- Epoch: 247. Average Train loss: 14.4636. Train Reconstruction loss: 6.4133. Train KLD loss: 8.0503. Time: 975.84\n",
      "<-- Epoch: 247. Average Test loss: 44.6613. Test Reconstruction loss: 38.5848. Test KLD loss: 6.0765. Time: 976.15\n",
      "<-- Epoch: 248. Average Train loss: 14.3901. Train Reconstruction loss: 6.1462. Train KLD loss: 8.2439. Time: 977.18\n",
      "<-- Epoch: 248. Average Test loss: 44.2002. Test Reconstruction loss: 37.9368. Test KLD loss: 6.2633. Time: 977.49\n",
      "<-- Epoch: 249. Average Train loss: 14.2419. Train Reconstruction loss: 6.2320. Train KLD loss: 8.0099. Time: 978.51\n",
      "<-- Epoch: 249. Average Test loss: 44.7432. Test Reconstruction loss: 38.9251. Test KLD loss: 5.8181. Time: 978.81\n",
      "<-- Epoch: 250. Average Train loss: 14.4752. Train Reconstruction loss: 6.2511. Train KLD loss: 8.2241. Time: 979.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 250. Average Test loss: 44.7347. Test Reconstruction loss: 38.4631. Test KLD loss: 6.2716. Time: 980.16\n",
      "<-- Epoch: 251. Average Train loss: 14.3711. Train Reconstruction loss: 6.2160. Train KLD loss: 8.1550. Time: 981.18\n",
      "<-- Epoch: 251. Average Test loss: 44.5888. Test Reconstruction loss: 38.0763. Test KLD loss: 6.5125. Time: 981.51\n",
      "<-- Epoch: 252. Average Train loss: 14.2419. Train Reconstruction loss: 5.9544. Train KLD loss: 8.2875. Time: 982.55\n",
      "<-- Epoch: 252. Average Test loss: 44.9777. Test Reconstruction loss: 38.9152. Test KLD loss: 6.0626. Time: 982.85\n",
      "<-- Epoch: 253. Average Train loss: 14.2814. Train Reconstruction loss: 6.1479. Train KLD loss: 8.1336. Time: 983.93\n",
      "<-- Epoch: 253. Average Test loss: 44.8417. Test Reconstruction loss: 38.6853. Test KLD loss: 6.1565. Time: 984.24\n",
      "<-- Epoch: 254. Average Train loss: 14.4040. Train Reconstruction loss: 6.1163. Train KLD loss: 8.2877. Time: 985.27\n",
      "<-- Epoch: 254. Average Test loss: 45.2111. Test Reconstruction loss: 38.7732. Test KLD loss: 6.4379. Time: 985.56\n",
      "<-- Epoch: 255. Average Train loss: 14.2646. Train Reconstruction loss: 5.9962. Train KLD loss: 8.2684. Time: 986.58\n",
      "<-- Epoch: 255. Average Test loss: 45.3499. Test Reconstruction loss: 39.0290. Test KLD loss: 6.3209. Time: 986.87\n",
      "<-- Epoch: 256. Average Train loss: 14.3158. Train Reconstruction loss: 6.0840. Train KLD loss: 8.2319. Time: 987.93\n",
      "<-- Epoch: 256. Average Test loss: 45.5925. Test Reconstruction loss: 38.5309. Test KLD loss: 7.0617. Time: 988.26\n",
      "<-- Epoch: 257. Average Train loss: 14.4441. Train Reconstruction loss: 5.9804. Train KLD loss: 8.4637. Time: 989.29\n",
      "<-- Epoch: 257. Average Test loss: 45.0875. Test Reconstruction loss: 39.3358. Test KLD loss: 5.7517. Time: 989.60\n",
      "<-- Epoch: 258. Average Train loss: 14.3970. Train Reconstruction loss: 6.1293. Train KLD loss: 8.2677. Time: 990.76\n",
      "<-- Epoch: 258. Average Test loss: 46.7966. Test Reconstruction loss: 40.5047. Test KLD loss: 6.2919. Time: 991.14\n",
      "<-- Epoch: 259. Average Train loss: 14.1622. Train Reconstruction loss: 5.9042. Train KLD loss: 8.2581. Time: 992.46\n",
      "<-- Epoch: 259. Average Test loss: 45.8369. Test Reconstruction loss: 39.4434. Test KLD loss: 6.3935. Time: 992.91\n",
      "<-- Epoch: 260. Average Train loss: 14.1786. Train Reconstruction loss: 6.0151. Train KLD loss: 8.1635. Time: 994.33\n",
      "<-- Epoch: 260. Average Test loss: 45.8405. Test Reconstruction loss: 39.7464. Test KLD loss: 6.0940. Time: 994.62\n",
      "<-- Epoch: 261. Average Train loss: 14.1219. Train Reconstruction loss: 5.7727. Train KLD loss: 8.3493. Time: 995.68\n",
      "<-- Epoch: 261. Average Test loss: 45.7579. Test Reconstruction loss: 39.2593. Test KLD loss: 6.4986. Time: 995.97\n",
      "<-- Epoch: 262. Average Train loss: 14.0896. Train Reconstruction loss: 5.8367. Train KLD loss: 8.2529. Time: 997.34\n",
      "<-- Epoch: 262. Average Test loss: 46.6261. Test Reconstruction loss: 40.7435. Test KLD loss: 5.8827. Time: 997.72\n",
      "<-- Epoch: 263. Average Train loss: 14.2332. Train Reconstruction loss: 5.8098. Train KLD loss: 8.4235. Time: 998.97\n",
      "<-- Epoch: 263. Average Test loss: 45.8340. Test Reconstruction loss: 39.3650. Test KLD loss: 6.4690. Time: 999.32\n",
      "<-- Epoch: 264. Average Train loss: 14.1004. Train Reconstruction loss: 5.7864. Train KLD loss: 8.3139. Time: 1000.61\n",
      "<-- Epoch: 264. Average Test loss: 46.7936. Test Reconstruction loss: 40.2642. Test KLD loss: 6.5294. Time: 1000.99\n",
      "<-- Epoch: 265. Average Train loss: 14.2745. Train Reconstruction loss: 5.8335. Train KLD loss: 8.4411. Time: 1002.12\n",
      "<-- Epoch: 265. Average Test loss: 46.3996. Test Reconstruction loss: 39.9838. Test KLD loss: 6.4158. Time: 1002.46\n",
      "<-- Epoch: 266. Average Train loss: 13.9950. Train Reconstruction loss: 5.6862. Train KLD loss: 8.3088. Time: 1003.52\n",
      "<-- Epoch: 266. Average Test loss: 46.5537. Test Reconstruction loss: 40.7786. Test KLD loss: 5.7751. Time: 1003.85\n",
      "<-- Epoch: 267. Average Train loss: 14.3186. Train Reconstruction loss: 5.8613. Train KLD loss: 8.4573. Time: 1004.98\n",
      "<-- Epoch: 267. Average Test loss: 47.1460. Test Reconstruction loss: 40.3411. Test KLD loss: 6.8049. Time: 1005.31\n",
      "<-- Epoch: 268. Average Train loss: 13.8526. Train Reconstruction loss: 5.6043. Train KLD loss: 8.2483. Time: 1006.40\n",
      "<-- Epoch: 268. Average Test loss: 46.1486. Test Reconstruction loss: 39.7600. Test KLD loss: 6.3886. Time: 1006.72\n",
      "<-- Epoch: 269. Average Train loss: 14.0817. Train Reconstruction loss: 5.8236. Train KLD loss: 8.2582. Time: 1007.91\n",
      "<-- Epoch: 269. Average Test loss: 47.1402. Test Reconstruction loss: 41.1516. Test KLD loss: 5.9886. Time: 1008.31\n",
      "<-- Epoch: 270. Average Train loss: 14.0755. Train Reconstruction loss: 5.6612. Train KLD loss: 8.4143. Time: 1009.44\n",
      "<-- Epoch: 270. Average Test loss: 46.5693. Test Reconstruction loss: 40.2907. Test KLD loss: 6.2786. Time: 1009.78\n",
      "<-- Epoch: 271. Average Train loss: 14.0958. Train Reconstruction loss: 5.7737. Train KLD loss: 8.3221. Time: 1011.19\n",
      "<-- Epoch: 271. Average Test loss: 47.3633. Test Reconstruction loss: 40.9527. Test KLD loss: 6.4106. Time: 1011.48\n",
      "<-- Epoch: 272. Average Train loss: 13.8926. Train Reconstruction loss: 5.5810. Train KLD loss: 8.3116. Time: 1012.51\n",
      "<-- Epoch: 272. Average Test loss: 47.9231. Test Reconstruction loss: 41.4983. Test KLD loss: 6.4248. Time: 1012.80\n",
      "<-- Epoch: 273. Average Train loss: 14.0220. Train Reconstruction loss: 5.7199. Train KLD loss: 8.3021. Time: 1013.83\n",
      "<-- Epoch: 273. Average Test loss: 47.4534. Test Reconstruction loss: 40.9141. Test KLD loss: 6.5393. Time: 1014.14\n",
      "<-- Epoch: 274. Average Train loss: 14.0196. Train Reconstruction loss: 5.6103. Train KLD loss: 8.4093. Time: 1015.17\n",
      "<-- Epoch: 274. Average Test loss: 47.1203. Test Reconstruction loss: 40.6506. Test KLD loss: 6.4697. Time: 1015.48\n",
      "<-- Epoch: 275. Average Train loss: 14.0778. Train Reconstruction loss: 5.6370. Train KLD loss: 8.4408. Time: 1016.51\n",
      "<-- Epoch: 275. Average Test loss: 47.4615. Test Reconstruction loss: 40.4623. Test KLD loss: 6.9992. Time: 1016.81\n",
      "<-- Epoch: 276. Average Train loss: 14.0025. Train Reconstruction loss: 5.4848. Train KLD loss: 8.5177. Time: 1017.83\n",
      "<-- Epoch: 276. Average Test loss: 48.0262. Test Reconstruction loss: 41.2200. Test KLD loss: 6.8063. Time: 1018.15\n",
      "<-- Epoch: 277. Average Train loss: 13.9140. Train Reconstruction loss: 5.4677. Train KLD loss: 8.4462. Time: 1019.19\n",
      "<-- Epoch: 277. Average Test loss: 47.3988. Test Reconstruction loss: 40.7693. Test KLD loss: 6.6295. Time: 1019.49\n",
      "<-- Epoch: 278. Average Train loss: 14.0680. Train Reconstruction loss: 5.5204. Train KLD loss: 8.5476. Time: 1020.52\n",
      "<-- Epoch: 278. Average Test loss: 47.5847. Test Reconstruction loss: 40.9648. Test KLD loss: 6.6199. Time: 1020.81\n",
      "<-- Epoch: 279. Average Train loss: 13.9551. Train Reconstruction loss: 5.4806. Train KLD loss: 8.4744. Time: 1021.84\n",
      "<-- Epoch: 279. Average Test loss: 47.5780. Test Reconstruction loss: 41.2392. Test KLD loss: 6.3388. Time: 1022.16\n",
      "<-- Epoch: 280. Average Train loss: 13.9331. Train Reconstruction loss: 5.4795. Train KLD loss: 8.4536. Time: 1023.46\n",
      "<-- Epoch: 280. Average Test loss: 47.8524. Test Reconstruction loss: 41.1821. Test KLD loss: 6.6703. Time: 1023.80\n",
      "<-- Epoch: 281. Average Train loss: 13.7957. Train Reconstruction loss: 5.3385. Train KLD loss: 8.4572. Time: 1024.84\n",
      "<-- Epoch: 281. Average Test loss: 47.7460. Test Reconstruction loss: 41.4377. Test KLD loss: 6.3083. Time: 1025.15\n",
      "<-- Epoch: 282. Average Train loss: 13.6216. Train Reconstruction loss: 5.2353. Train KLD loss: 8.3863. Time: 1026.19\n",
      "<-- Epoch: 282. Average Test loss: 48.7071. Test Reconstruction loss: 42.5021. Test KLD loss: 6.2050. Time: 1026.49\n",
      "<-- Epoch: 283. Average Train loss: 13.8177. Train Reconstruction loss: 5.2337. Train KLD loss: 8.5840. Time: 1027.69\n",
      "<-- Epoch: 283. Average Test loss: 48.8116. Test Reconstruction loss: 42.2038. Test KLD loss: 6.6078. Time: 1028.07\n",
      "<-- Epoch: 284. Average Train loss: 13.9440. Train Reconstruction loss: 5.4187. Train KLD loss: 8.5253. Time: 1029.37\n",
      "<-- Epoch: 284. Average Test loss: 48.9607. Test Reconstruction loss: 42.5256. Test KLD loss: 6.4351. Time: 1029.81\n",
      "<-- Epoch: 285. Average Train loss: 14.0023. Train Reconstruction loss: 5.3738. Train KLD loss: 8.6284. Time: 1030.93\n",
      "<-- Epoch: 285. Average Test loss: 48.5463. Test Reconstruction loss: 42.3160. Test KLD loss: 6.2303. Time: 1031.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 286. Average Train loss: 13.9384. Train Reconstruction loss: 5.3414. Train KLD loss: 8.5970. Time: 1032.55\n",
      "<-- Epoch: 286. Average Test loss: 48.7957. Test Reconstruction loss: 42.1018. Test KLD loss: 6.6939. Time: 1032.88\n",
      "<-- Epoch: 287. Average Train loss: 14.0077. Train Reconstruction loss: 5.4299. Train KLD loss: 8.5777. Time: 1034.03\n",
      "<-- Epoch: 287. Average Test loss: 48.7822. Test Reconstruction loss: 42.2957. Test KLD loss: 6.4865. Time: 1034.36\n",
      "<-- Epoch: 288. Average Train loss: 13.8827. Train Reconstruction loss: 5.3714. Train KLD loss: 8.5113. Time: 1035.39\n",
      "<-- Epoch: 288. Average Test loss: 48.5983. Test Reconstruction loss: 41.7927. Test KLD loss: 6.8056. Time: 1035.69\n",
      "<-- Epoch: 289. Average Train loss: 13.8040. Train Reconstruction loss: 5.2257. Train KLD loss: 8.5784. Time: 1036.87\n",
      "<-- Epoch: 289. Average Test loss: 48.6525. Test Reconstruction loss: 42.3516. Test KLD loss: 6.3009. Time: 1037.21\n",
      "<-- Epoch: 290. Average Train loss: 13.8874. Train Reconstruction loss: 5.2809. Train KLD loss: 8.6066. Time: 1039.18\n",
      "<-- Epoch: 290. Average Test loss: 49.1085. Test Reconstruction loss: 42.7999. Test KLD loss: 6.3086. Time: 1039.76\n",
      "<-- Epoch: 291. Average Train loss: 13.7417. Train Reconstruction loss: 5.1477. Train KLD loss: 8.5940. Time: 1041.78\n",
      "<-- Epoch: 291. Average Test loss: 49.0381. Test Reconstruction loss: 42.2108. Test KLD loss: 6.8272. Time: 1042.30\n",
      "<-- Epoch: 292. Average Train loss: 13.8860. Train Reconstruction loss: 5.3150. Train KLD loss: 8.5710. Time: 1043.52\n",
      "<-- Epoch: 292. Average Test loss: 49.9853. Test Reconstruction loss: 43.2409. Test KLD loss: 6.7445. Time: 1043.91\n",
      "<-- Epoch: 293. Average Train loss: 13.8263. Train Reconstruction loss: 5.2890. Train KLD loss: 8.5373. Time: 1045.19\n",
      "<-- Epoch: 293. Average Test loss: 49.1980. Test Reconstruction loss: 42.6323. Test KLD loss: 6.5656. Time: 1045.50\n",
      "<-- Epoch: 294. Average Train loss: 13.7367. Train Reconstruction loss: 5.0903. Train KLD loss: 8.6464. Time: 1046.96\n",
      "<-- Epoch: 294. Average Test loss: 50.0128. Test Reconstruction loss: 43.2980. Test KLD loss: 6.7149. Time: 1047.31\n",
      "<-- Epoch: 295. Average Train loss: 13.6420. Train Reconstruction loss: 5.1309. Train KLD loss: 8.5111. Time: 1048.37\n",
      "<-- Epoch: 295. Average Test loss: 49.6965. Test Reconstruction loss: 43.3480. Test KLD loss: 6.3485. Time: 1048.67\n",
      "<-- Epoch: 296. Average Train loss: 13.9561. Train Reconstruction loss: 5.3449. Train KLD loss: 8.6112. Time: 1049.79\n",
      "<-- Epoch: 296. Average Test loss: 49.2598. Test Reconstruction loss: 42.3019. Test KLD loss: 6.9579. Time: 1050.24\n",
      "<-- Epoch: 297. Average Train loss: 13.7523. Train Reconstruction loss: 5.0711. Train KLD loss: 8.6811. Time: 1051.50\n",
      "<-- Epoch: 297. Average Test loss: 49.7898. Test Reconstruction loss: 42.6605. Test KLD loss: 7.1293. Time: 1051.95\n",
      "<-- Epoch: 298. Average Train loss: 13.6970. Train Reconstruction loss: 5.0633. Train KLD loss: 8.6337. Time: 1053.20\n",
      "<-- Epoch: 298. Average Test loss: 49.7162. Test Reconstruction loss: 43.0802. Test KLD loss: 6.6360. Time: 1053.54\n",
      "<-- Epoch: 299. Average Train loss: 13.6780. Train Reconstruction loss: 5.0399. Train KLD loss: 8.6382. Time: 1054.75\n",
      "<-- Epoch: 299. Average Test loss: 49.9161. Test Reconstruction loss: 42.8411. Test KLD loss: 7.0750. Time: 1055.07\n",
      "<-- Epoch: 300. Average Train loss: 13.5264. Train Reconstruction loss: 4.9327. Train KLD loss: 8.5937. Time: 1056.22\n",
      "<-- Epoch: 300. Average Test loss: 50.0239. Test Reconstruction loss: 43.4817. Test KLD loss: 6.5422. Time: 1056.52\n",
      "<-- Epoch: 301. Average Train loss: 13.7138. Train Reconstruction loss: 5.0152. Train KLD loss: 8.6986. Time: 1057.57\n",
      "<-- Epoch: 301. Average Test loss: 49.9561. Test Reconstruction loss: 43.4006. Test KLD loss: 6.5556. Time: 1057.88\n",
      "<-- Epoch: 302. Average Train loss: 13.8719. Train Reconstruction loss: 5.1583. Train KLD loss: 8.7136. Time: 1059.26\n",
      "<-- Epoch: 302. Average Test loss: 50.6284. Test Reconstruction loss: 43.8675. Test KLD loss: 6.7609. Time: 1059.64\n",
      "<-- Epoch: 303. Average Train loss: 13.4173. Train Reconstruction loss: 4.9456. Train KLD loss: 8.4717. Time: 1060.99\n",
      "<-- Epoch: 303. Average Test loss: 50.2774. Test Reconstruction loss: 43.9349. Test KLD loss: 6.3426. Time: 1061.49\n",
      "<-- Epoch: 304. Average Train loss: 13.4604. Train Reconstruction loss: 4.9455. Train KLD loss: 8.5149. Time: 1063.36\n",
      "<-- Epoch: 304. Average Test loss: 50.5750. Test Reconstruction loss: 44.0691. Test KLD loss: 6.5058. Time: 1064.26\n",
      "<-- Epoch: 305. Average Train loss: 13.5667. Train Reconstruction loss: 5.0228. Train KLD loss: 8.5439. Time: 1066.43\n",
      "<-- Epoch: 305. Average Test loss: 50.0414. Test Reconstruction loss: 43.7546. Test KLD loss: 6.2868. Time: 1067.02\n",
      "<-- Epoch: 306. Average Train loss: 13.7664. Train Reconstruction loss: 5.0465. Train KLD loss: 8.7199. Time: 1069.07\n",
      "<-- Epoch: 306. Average Test loss: 49.9885. Test Reconstruction loss: 43.0445. Test KLD loss: 6.9440. Time: 1069.59\n",
      "<-- Epoch: 307. Average Train loss: 13.5861. Train Reconstruction loss: 4.8933. Train KLD loss: 8.6928. Time: 1071.39\n",
      "<-- Epoch: 307. Average Test loss: 50.4967. Test Reconstruction loss: 43.7064. Test KLD loss: 6.7903. Time: 1071.90\n",
      "<-- Epoch: 308. Average Train loss: 13.3836. Train Reconstruction loss: 4.8421. Train KLD loss: 8.5415. Time: 1073.63\n",
      "<-- Epoch: 308. Average Test loss: 50.0106. Test Reconstruction loss: 43.1648. Test KLD loss: 6.8459. Time: 1073.98\n",
      "<-- Epoch: 309. Average Train loss: 13.6834. Train Reconstruction loss: 4.9361. Train KLD loss: 8.7473. Time: 1075.17\n",
      "<-- Epoch: 309. Average Test loss: 50.8236. Test Reconstruction loss: 43.2372. Test KLD loss: 7.5864. Time: 1075.51\n",
      "<-- Epoch: 310. Average Train loss: 13.6234. Train Reconstruction loss: 4.9858. Train KLD loss: 8.6376. Time: 1076.69\n",
      "<-- Epoch: 310. Average Test loss: 50.8302. Test Reconstruction loss: 43.8965. Test KLD loss: 6.9337. Time: 1077.02\n",
      "<-- Epoch: 311. Average Train loss: 13.4455. Train Reconstruction loss: 4.8236. Train KLD loss: 8.6219. Time: 1078.10\n",
      "<-- Epoch: 311. Average Test loss: 50.8254. Test Reconstruction loss: 44.4488. Test KLD loss: 6.3766. Time: 1078.51\n",
      "<-- Epoch: 312. Average Train loss: 13.5130. Train Reconstruction loss: 4.8285. Train KLD loss: 8.6845. Time: 1079.67\n",
      "<-- Epoch: 312. Average Test loss: 51.0862. Test Reconstruction loss: 44.2634. Test KLD loss: 6.8228. Time: 1080.03\n",
      "<-- Epoch: 313. Average Train loss: 13.6459. Train Reconstruction loss: 4.9474. Train KLD loss: 8.6985. Time: 1081.17\n",
      "<-- Epoch: 313. Average Test loss: 50.7641. Test Reconstruction loss: 44.0018. Test KLD loss: 6.7623. Time: 1081.50\n",
      "<-- Epoch: 314. Average Train loss: 13.4831. Train Reconstruction loss: 4.8024. Train KLD loss: 8.6807. Time: 1082.70\n",
      "<-- Epoch: 314. Average Test loss: 50.9934. Test Reconstruction loss: 44.5865. Test KLD loss: 6.4069. Time: 1083.02\n",
      "<-- Epoch: 315. Average Train loss: 13.6156. Train Reconstruction loss: 4.9084. Train KLD loss: 8.7072. Time: 1084.10\n",
      "<-- Epoch: 315. Average Test loss: 51.4967. Test Reconstruction loss: 44.7354. Test KLD loss: 6.7614. Time: 1084.42\n",
      "<-- Epoch: 316. Average Train loss: 13.4838. Train Reconstruction loss: 4.7573. Train KLD loss: 8.7265. Time: 1085.50\n",
      "<-- Epoch: 316. Average Test loss: 50.7381. Test Reconstruction loss: 44.0039. Test KLD loss: 6.7342. Time: 1085.81\n",
      "<-- Epoch: 317. Average Train loss: 13.7517. Train Reconstruction loss: 4.9204. Train KLD loss: 8.8313. Time: 1086.95\n",
      "<-- Epoch: 317. Average Test loss: 51.4040. Test Reconstruction loss: 44.2667. Test KLD loss: 7.1373. Time: 1087.30\n",
      "<-- Epoch: 318. Average Train loss: 13.4157. Train Reconstruction loss: 4.6759. Train KLD loss: 8.7398. Time: 1088.43\n",
      "<-- Epoch: 318. Average Test loss: 50.8180. Test Reconstruction loss: 44.1945. Test KLD loss: 6.6234. Time: 1088.76\n",
      "<-- Epoch: 319. Average Train loss: 13.3273. Train Reconstruction loss: 4.6845. Train KLD loss: 8.6428. Time: 1089.83\n",
      "<-- Epoch: 319. Average Test loss: 51.3917. Test Reconstruction loss: 44.3319. Test KLD loss: 7.0598. Time: 1090.15\n",
      "<-- Epoch: 320. Average Train loss: 13.5978. Train Reconstruction loss: 4.7569. Train KLD loss: 8.8409. Time: 1091.36\n",
      "<-- Epoch: 320. Average Test loss: 51.4282. Test Reconstruction loss: 44.3363. Test KLD loss: 7.0919. Time: 1091.69\n",
      "<-- Epoch: 321. Average Train loss: 13.8162. Train Reconstruction loss: 4.8552. Train KLD loss: 8.9610. Time: 1092.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 321. Average Test loss: 51.2328. Test Reconstruction loss: 44.9129. Test KLD loss: 6.3198. Time: 1093.27\n",
      "<-- Epoch: 322. Average Train loss: 13.5101. Train Reconstruction loss: 4.8224. Train KLD loss: 8.6876. Time: 1094.45\n",
      "<-- Epoch: 322. Average Test loss: 51.5705. Test Reconstruction loss: 44.1708. Test KLD loss: 7.3997. Time: 1094.79\n",
      "<-- Epoch: 323. Average Train loss: 13.4687. Train Reconstruction loss: 4.6757. Train KLD loss: 8.7931. Time: 1096.04\n",
      "<-- Epoch: 323. Average Test loss: 51.2064. Test Reconstruction loss: 44.3287. Test KLD loss: 6.8777. Time: 1096.49\n",
      "<-- Epoch: 324. Average Train loss: 13.5011. Train Reconstruction loss: 4.7309. Train KLD loss: 8.7702. Time: 1097.67\n",
      "<-- Epoch: 324. Average Test loss: 51.8012. Test Reconstruction loss: 44.6180. Test KLD loss: 7.1831. Time: 1097.97\n",
      "<-- Epoch: 325. Average Train loss: 13.7230. Train Reconstruction loss: 4.7768. Train KLD loss: 8.9462. Time: 1099.08\n",
      "<-- Epoch: 325. Average Test loss: 51.4822. Test Reconstruction loss: 44.5821. Test KLD loss: 6.9002. Time: 1099.40\n",
      "<-- Epoch: 326. Average Train loss: 13.5212. Train Reconstruction loss: 4.6747. Train KLD loss: 8.8465. Time: 1100.55\n",
      "<-- Epoch: 326. Average Test loss: 52.0642. Test Reconstruction loss: 45.3381. Test KLD loss: 6.7261. Time: 1100.88\n",
      "<-- Epoch: 327. Average Train loss: 13.5113. Train Reconstruction loss: 4.7399. Train KLD loss: 8.7714. Time: 1102.04\n",
      "<-- Epoch: 327. Average Test loss: 51.9429. Test Reconstruction loss: 45.2200. Test KLD loss: 6.7229. Time: 1102.61\n",
      "<-- Epoch: 328. Average Train loss: 13.5096. Train Reconstruction loss: 4.5751. Train KLD loss: 8.9345. Time: 1104.41\n",
      "<-- Epoch: 328. Average Test loss: 51.9353. Test Reconstruction loss: 45.0406. Test KLD loss: 6.8948. Time: 1104.95\n",
      "<-- Epoch: 329. Average Train loss: 13.3090. Train Reconstruction loss: 4.6238. Train KLD loss: 8.6852. Time: 1106.73\n",
      "<-- Epoch: 329. Average Test loss: 51.8863. Test Reconstruction loss: 44.8628. Test KLD loss: 7.0235. Time: 1107.34\n",
      "<-- Epoch: 330. Average Train loss: 13.3117. Train Reconstruction loss: 4.5406. Train KLD loss: 8.7711. Time: 1108.71\n",
      "<-- Epoch: 330. Average Test loss: 51.8975. Test Reconstruction loss: 45.0331. Test KLD loss: 6.8644. Time: 1109.02\n",
      "<-- Epoch: 331. Average Train loss: 13.6118. Train Reconstruction loss: 4.8246. Train KLD loss: 8.7872. Time: 1110.21\n",
      "<-- Epoch: 331. Average Test loss: 52.6238. Test Reconstruction loss: 45.4208. Test KLD loss: 7.2030. Time: 1110.56\n",
      "<-- Epoch: 332. Average Train loss: 13.5145. Train Reconstruction loss: 4.5964. Train KLD loss: 8.9180. Time: 1111.84\n",
      "<-- Epoch: 332. Average Test loss: 52.1602. Test Reconstruction loss: 44.4577. Test KLD loss: 7.7024. Time: 1112.30\n",
      "<-- Epoch: 333. Average Train loss: 13.5020. Train Reconstruction loss: 4.6128. Train KLD loss: 8.8892. Time: 1113.90\n",
      "<-- Epoch: 333. Average Test loss: 52.1370. Test Reconstruction loss: 45.0452. Test KLD loss: 7.0918. Time: 1114.38\n",
      "<-- Epoch: 334. Average Train loss: 13.4270. Train Reconstruction loss: 4.5429. Train KLD loss: 8.8841. Time: 1116.16\n",
      "<-- Epoch: 334. Average Test loss: 52.8475. Test Reconstruction loss: 45.7567. Test KLD loss: 7.0908. Time: 1116.76\n",
      "<-- Epoch: 335. Average Train loss: 13.2527. Train Reconstruction loss: 4.4738. Train KLD loss: 8.7789. Time: 1118.19\n",
      "<-- Epoch: 335. Average Test loss: 52.4125. Test Reconstruction loss: 45.9510. Test KLD loss: 6.4614. Time: 1118.50\n",
      "<-- Epoch: 336. Average Train loss: 13.3176. Train Reconstruction loss: 4.5380. Train KLD loss: 8.7796. Time: 1119.60\n",
      "<-- Epoch: 336. Average Test loss: 52.9884. Test Reconstruction loss: 45.8936. Test KLD loss: 7.0948. Time: 1119.91\n",
      "<-- Epoch: 337. Average Train loss: 13.3202. Train Reconstruction loss: 4.5240. Train KLD loss: 8.7962. Time: 1121.03\n",
      "<-- Epoch: 337. Average Test loss: 54.2559. Test Reconstruction loss: 47.8059. Test KLD loss: 6.4500. Time: 1121.36\n",
      "<-- Epoch: 338. Average Train loss: 13.5350. Train Reconstruction loss: 4.6973. Train KLD loss: 8.8377. Time: 1122.46\n",
      "<-- Epoch: 338. Average Test loss: 52.7227. Test Reconstruction loss: 45.4684. Test KLD loss: 7.2543. Time: 1122.76\n",
      "<-- Epoch: 339. Average Train loss: 13.3032. Train Reconstruction loss: 4.5098. Train KLD loss: 8.7934. Time: 1123.88\n",
      "<-- Epoch: 339. Average Test loss: 53.8313. Test Reconstruction loss: 46.8991. Test KLD loss: 6.9322. Time: 1124.20\n",
      "<-- Epoch: 340. Average Train loss: 13.4561. Train Reconstruction loss: 4.5510. Train KLD loss: 8.9051. Time: 1125.44\n",
      "<-- Epoch: 340. Average Test loss: 52.6683. Test Reconstruction loss: 46.2209. Test KLD loss: 6.4474. Time: 1125.80\n",
      "<-- Epoch: 341. Average Train loss: 13.4558. Train Reconstruction loss: 4.6134. Train KLD loss: 8.8425. Time: 1127.10\n",
      "<-- Epoch: 341. Average Test loss: 53.7150. Test Reconstruction loss: 46.6331. Test KLD loss: 7.0820. Time: 1127.49\n",
      "<-- Epoch: 342. Average Train loss: 13.2591. Train Reconstruction loss: 4.4828. Train KLD loss: 8.7763. Time: 1129.02\n",
      "<-- Epoch: 342. Average Test loss: 53.3332. Test Reconstruction loss: 46.4239. Test KLD loss: 6.9093. Time: 1129.56\n",
      "<-- Epoch: 343. Average Train loss: 13.4124. Train Reconstruction loss: 4.4901. Train KLD loss: 8.9223. Time: 1131.11\n",
      "<-- Epoch: 343. Average Test loss: 53.2876. Test Reconstruction loss: 46.1046. Test KLD loss: 7.1830. Time: 1131.54\n",
      "<-- Epoch: 344. Average Train loss: 13.2008. Train Reconstruction loss: 4.3727. Train KLD loss: 8.8281. Time: 1132.78\n",
      "<-- Epoch: 344. Average Test loss: 53.2849. Test Reconstruction loss: 46.6477. Test KLD loss: 6.6371. Time: 1133.15\n",
      "<-- Epoch: 345. Average Train loss: 13.2870. Train Reconstruction loss: 4.4199. Train KLD loss: 8.8671. Time: 1134.42\n",
      "<-- Epoch: 345. Average Test loss: 53.2117. Test Reconstruction loss: 46.3711. Test KLD loss: 6.8406. Time: 1134.81\n",
      "<-- Epoch: 346. Average Train loss: 13.2783. Train Reconstruction loss: 4.5157. Train KLD loss: 8.7626. Time: 1136.33\n",
      "<-- Epoch: 346. Average Test loss: 53.9544. Test Reconstruction loss: 47.1254. Test KLD loss: 6.8291. Time: 1136.82\n",
      "<-- Epoch: 347. Average Train loss: 13.3624. Train Reconstruction loss: 4.4791. Train KLD loss: 8.8833. Time: 1138.29\n",
      "<-- Epoch: 347. Average Test loss: 53.1092. Test Reconstruction loss: 45.6874. Test KLD loss: 7.4217. Time: 1138.62\n",
      "<-- Epoch: 348. Average Train loss: 13.3517. Train Reconstruction loss: 4.4366. Train KLD loss: 8.9151. Time: 1140.25\n",
      "<-- Epoch: 348. Average Test loss: 53.1216. Test Reconstruction loss: 46.3598. Test KLD loss: 6.7618. Time: 1140.67\n",
      "<-- Epoch: 349. Average Train loss: 13.2104. Train Reconstruction loss: 4.4316. Train KLD loss: 8.7787. Time: 1142.18\n",
      "<-- Epoch: 349. Average Test loss: 53.6437. Test Reconstruction loss: 46.9163. Test KLD loss: 6.7275. Time: 1142.58\n",
      "<-- Epoch: 350. Average Train loss: 13.1149. Train Reconstruction loss: 4.3646. Train KLD loss: 8.7502. Time: 1144.08\n",
      "<-- Epoch: 350. Average Test loss: 53.2819. Test Reconstruction loss: 46.2904. Test KLD loss: 6.9915. Time: 1144.56\n",
      "<-- Epoch: 351. Average Train loss: 13.3631. Train Reconstruction loss: 4.3939. Train KLD loss: 8.9691. Time: 1146.03\n",
      "<-- Epoch: 351. Average Test loss: 53.9752. Test Reconstruction loss: 47.1457. Test KLD loss: 6.8295. Time: 1146.48\n",
      "<-- Epoch: 352. Average Train loss: 13.1697. Train Reconstruction loss: 4.3699. Train KLD loss: 8.7998. Time: 1147.85\n",
      "<-- Epoch: 352. Average Test loss: 53.9781. Test Reconstruction loss: 46.4836. Test KLD loss: 7.4945. Time: 1148.27\n",
      "<-- Epoch: 353. Average Train loss: 13.2676. Train Reconstruction loss: 4.3838. Train KLD loss: 8.8838. Time: 1149.66\n",
      "<-- Epoch: 353. Average Test loss: 53.7323. Test Reconstruction loss: 46.8986. Test KLD loss: 6.8336. Time: 1150.01\n",
      "<-- Epoch: 354. Average Train loss: 13.4002. Train Reconstruction loss: 4.4640. Train KLD loss: 8.9362. Time: 1151.32\n",
      "<-- Epoch: 354. Average Test loss: 54.0288. Test Reconstruction loss: 46.8714. Test KLD loss: 7.1574. Time: 1151.78\n",
      "<-- Epoch: 355. Average Train loss: 13.3908. Train Reconstruction loss: 4.3370. Train KLD loss: 9.0538. Time: 1153.04\n",
      "<-- Epoch: 355. Average Test loss: 54.4408. Test Reconstruction loss: 47.2832. Test KLD loss: 7.1576. Time: 1153.41\n",
      "<-- Epoch: 356. Average Train loss: 13.2207. Train Reconstruction loss: 4.3700. Train KLD loss: 8.8507. Time: 1154.80\n",
      "<-- Epoch: 356. Average Test loss: 54.4001. Test Reconstruction loss: 47.4894. Test KLD loss: 6.9106. Time: 1155.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 357. Average Train loss: 13.3527. Train Reconstruction loss: 4.4071. Train KLD loss: 8.9455. Time: 1156.35\n",
      "<-- Epoch: 357. Average Test loss: 53.8446. Test Reconstruction loss: 46.4383. Test KLD loss: 7.4064. Time: 1156.64\n",
      "<-- Epoch: 358. Average Train loss: 13.3394. Train Reconstruction loss: 4.3352. Train KLD loss: 9.0041. Time: 1157.90\n",
      "<-- Epoch: 358. Average Test loss: 54.1788. Test Reconstruction loss: 47.3869. Test KLD loss: 6.7919. Time: 1158.41\n",
      "<-- Epoch: 359. Average Train loss: 13.2140. Train Reconstruction loss: 4.3528. Train KLD loss: 8.8611. Time: 1159.66\n",
      "<-- Epoch: 359. Average Test loss: 54.7446. Test Reconstruction loss: 48.1141. Test KLD loss: 6.6305. Time: 1160.00\n",
      "<-- Epoch: 360. Average Train loss: 13.0719. Train Reconstruction loss: 4.2531. Train KLD loss: 8.8189. Time: 1161.43\n",
      "<-- Epoch: 360. Average Test loss: 55.6072. Test Reconstruction loss: 48.3573. Test KLD loss: 7.2499. Time: 1161.75\n",
      "<-- Epoch: 361. Average Train loss: 13.4841. Train Reconstruction loss: 4.4407. Train KLD loss: 9.0434. Time: 1162.90\n",
      "<-- Epoch: 361. Average Test loss: 54.1893. Test Reconstruction loss: 47.2512. Test KLD loss: 6.9381. Time: 1163.21\n",
      "<-- Epoch: 362. Average Train loss: 13.2114. Train Reconstruction loss: 4.3267. Train KLD loss: 8.8848. Time: 1164.60\n",
      "<-- Epoch: 362. Average Test loss: 54.1460. Test Reconstruction loss: 46.4331. Test KLD loss: 7.7129. Time: 1164.96\n",
      "<-- Epoch: 363. Average Train loss: 13.1936. Train Reconstruction loss: 4.3194. Train KLD loss: 8.8742. Time: 1166.35\n",
      "<-- Epoch: 363. Average Test loss: 54.9467. Test Reconstruction loss: 47.7327. Test KLD loss: 7.2140. Time: 1166.72\n",
      "<-- Epoch: 364. Average Train loss: 13.2264. Train Reconstruction loss: 4.3182. Train KLD loss: 8.9082. Time: 1167.92\n",
      "<-- Epoch: 364. Average Test loss: 54.4423. Test Reconstruction loss: 47.1685. Test KLD loss: 7.2738. Time: 1168.25\n",
      "<-- Epoch: 365. Average Train loss: 13.1094. Train Reconstruction loss: 4.1734. Train KLD loss: 8.9360. Time: 1169.54\n",
      "<-- Epoch: 365. Average Test loss: 55.0750. Test Reconstruction loss: 47.6312. Test KLD loss: 7.4438. Time: 1169.86\n",
      "<-- Epoch: 366. Average Train loss: 13.1737. Train Reconstruction loss: 4.3616. Train KLD loss: 8.8120. Time: 1171.22\n",
      "<-- Epoch: 366. Average Test loss: 54.1136. Test Reconstruction loss: 46.6745. Test KLD loss: 7.4390. Time: 1171.60\n",
      "<-- Epoch: 367. Average Train loss: 13.2841. Train Reconstruction loss: 4.2459. Train KLD loss: 9.0382. Time: 1172.91\n",
      "<-- Epoch: 367. Average Test loss: 55.1884. Test Reconstruction loss: 48.1998. Test KLD loss: 6.9886. Time: 1173.40\n",
      "<-- Epoch: 368. Average Train loss: 13.3293. Train Reconstruction loss: 4.2985. Train KLD loss: 9.0308. Time: 1174.73\n",
      "<-- Epoch: 368. Average Test loss: 54.0174. Test Reconstruction loss: 46.7698. Test KLD loss: 7.2476. Time: 1175.05\n",
      "<-- Epoch: 369. Average Train loss: 13.0748. Train Reconstruction loss: 4.1978. Train KLD loss: 8.8770. Time: 1176.61\n",
      "<-- Epoch: 369. Average Test loss: 54.7080. Test Reconstruction loss: 47.9106. Test KLD loss: 6.7974. Time: 1177.01\n",
      "<-- Epoch: 370. Average Train loss: 13.0853. Train Reconstruction loss: 4.2155. Train KLD loss: 8.8698. Time: 1178.39\n",
      "<-- Epoch: 370. Average Test loss: 54.9861. Test Reconstruction loss: 47.7706. Test KLD loss: 7.2155. Time: 1178.72\n",
      "<-- Epoch: 371. Average Train loss: 13.1099. Train Reconstruction loss: 4.1460. Train KLD loss: 8.9639. Time: 1180.05\n",
      "<-- Epoch: 371. Average Test loss: 54.4853. Test Reconstruction loss: 47.4104. Test KLD loss: 7.0749. Time: 1180.41\n",
      "<-- Epoch: 372. Average Train loss: 13.0927. Train Reconstruction loss: 4.2801. Train KLD loss: 8.8125. Time: 1181.86\n",
      "<-- Epoch: 372. Average Test loss: 54.8795. Test Reconstruction loss: 47.7052. Test KLD loss: 7.1742. Time: 1182.28\n",
      "<-- Epoch: 373. Average Train loss: 13.0219. Train Reconstruction loss: 4.1524. Train KLD loss: 8.8695. Time: 1183.76\n",
      "<-- Epoch: 373. Average Test loss: 55.3739. Test Reconstruction loss: 48.4497. Test KLD loss: 6.9243. Time: 1184.11\n",
      "<-- Epoch: 374. Average Train loss: 13.0655. Train Reconstruction loss: 4.2156. Train KLD loss: 8.8499. Time: 1185.61\n",
      "<-- Epoch: 374. Average Test loss: 55.3335. Test Reconstruction loss: 48.2544. Test KLD loss: 7.0791. Time: 1185.96\n",
      "<-- Epoch: 375. Average Train loss: 13.2492. Train Reconstruction loss: 4.2237. Train KLD loss: 9.0255. Time: 1187.45\n",
      "<-- Epoch: 375. Average Test loss: 55.9063. Test Reconstruction loss: 48.2013. Test KLD loss: 7.7050. Time: 1187.84\n",
      "<-- Epoch: 376. Average Train loss: 13.3542. Train Reconstruction loss: 4.2446. Train KLD loss: 9.1096. Time: 1189.38\n",
      "<-- Epoch: 376. Average Test loss: 55.0235. Test Reconstruction loss: 47.6436. Test KLD loss: 7.3799. Time: 1189.73\n",
      "<-- Epoch: 377. Average Train loss: 13.3010. Train Reconstruction loss: 4.2373. Train KLD loss: 9.0636. Time: 1191.07\n",
      "<-- Epoch: 377. Average Test loss: 55.5408. Test Reconstruction loss: 47.8082. Test KLD loss: 7.7326. Time: 1191.42\n",
      "<-- Epoch: 378. Average Train loss: 12.9788. Train Reconstruction loss: 4.0103. Train KLD loss: 8.9685. Time: 1192.62\n",
      "<-- Epoch: 378. Average Test loss: 55.3220. Test Reconstruction loss: 47.9700. Test KLD loss: 7.3520. Time: 1192.95\n",
      "<-- Epoch: 379. Average Train loss: 13.0803. Train Reconstruction loss: 4.1425. Train KLD loss: 8.9379. Time: 1194.28\n",
      "<-- Epoch: 379. Average Test loss: 55.2770. Test Reconstruction loss: 47.5783. Test KLD loss: 7.6987. Time: 1194.62\n",
      "<-- Epoch: 380. Average Train loss: 13.3177. Train Reconstruction loss: 4.1327. Train KLD loss: 9.1849. Time: 1196.45\n",
      "<-- Epoch: 380. Average Test loss: 55.8955. Test Reconstruction loss: 49.0037. Test KLD loss: 6.8919. Time: 1196.82\n",
      "<-- Epoch: 381. Average Train loss: 13.0695. Train Reconstruction loss: 4.2393. Train KLD loss: 8.8303. Time: 1197.97\n",
      "<-- Epoch: 381. Average Test loss: 55.5008. Test Reconstruction loss: 48.2216. Test KLD loss: 7.2792. Time: 1198.29\n",
      "<-- Epoch: 382. Average Train loss: 13.1123. Train Reconstruction loss: 4.1561. Train KLD loss: 8.9562. Time: 1199.45\n",
      "<-- Epoch: 382. Average Test loss: 56.0776. Test Reconstruction loss: 48.9220. Test KLD loss: 7.1556. Time: 1199.76\n",
      "<-- Epoch: 383. Average Train loss: 13.3981. Train Reconstruction loss: 4.1916. Train KLD loss: 9.2066. Time: 1200.92\n",
      "<-- Epoch: 383. Average Test loss: 56.6501. Test Reconstruction loss: 48.8593. Test KLD loss: 7.7908. Time: 1201.23\n",
      "<-- Epoch: 384. Average Train loss: 13.1260. Train Reconstruction loss: 4.2071. Train KLD loss: 8.9190. Time: 1202.44\n",
      "<-- Epoch: 384. Average Test loss: 55.6190. Test Reconstruction loss: 48.1421. Test KLD loss: 7.4770. Time: 1202.79\n",
      "<-- Epoch: 385. Average Train loss: 12.9268. Train Reconstruction loss: 4.0497. Train KLD loss: 8.8771. Time: 1204.24\n",
      "<-- Epoch: 385. Average Test loss: 56.7924. Test Reconstruction loss: 49.8016. Test KLD loss: 6.9908. Time: 1204.57\n",
      "<-- Epoch: 386. Average Train loss: 13.1278. Train Reconstruction loss: 4.2079. Train KLD loss: 8.9199. Time: 1205.85\n",
      "<-- Epoch: 386. Average Test loss: 56.3430. Test Reconstruction loss: 48.8865. Test KLD loss: 7.4565. Time: 1206.24\n",
      "<-- Epoch: 387. Average Train loss: 13.0741. Train Reconstruction loss: 4.0961. Train KLD loss: 8.9780. Time: 1207.62\n",
      "<-- Epoch: 387. Average Test loss: 56.2831. Test Reconstruction loss: 48.8719. Test KLD loss: 7.4112. Time: 1207.98\n",
      "<-- Epoch: 388. Average Train loss: 13.2546. Train Reconstruction loss: 4.1103. Train KLD loss: 9.1442. Time: 1209.35\n",
      "<-- Epoch: 388. Average Test loss: 56.4360. Test Reconstruction loss: 49.0234. Test KLD loss: 7.4126. Time: 1209.70\n",
      "<-- Epoch: 389. Average Train loss: 13.0927. Train Reconstruction loss: 4.0991. Train KLD loss: 8.9936. Time: 1211.13\n",
      "<-- Epoch: 389. Average Test loss: 56.0655. Test Reconstruction loss: 48.6398. Test KLD loss: 7.4257. Time: 1211.43\n",
      "<-- Epoch: 390. Average Train loss: 13.1753. Train Reconstruction loss: 4.1114. Train KLD loss: 9.0639. Time: 1213.06\n",
      "<-- Epoch: 390. Average Test loss: 55.9630. Test Reconstruction loss: 48.9202. Test KLD loss: 7.0428. Time: 1213.45\n",
      "<-- Epoch: 391. Average Train loss: 13.2046. Train Reconstruction loss: 4.0464. Train KLD loss: 9.1582. Time: 1215.31\n",
      "<-- Epoch: 391. Average Test loss: 56.4975. Test Reconstruction loss: 48.6893. Test KLD loss: 7.8081. Time: 1215.75\n",
      "<-- Epoch: 392. Average Train loss: 13.1399. Train Reconstruction loss: 4.0566. Train KLD loss: 9.0834. Time: 1216.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 392. Average Test loss: 56.4390. Test Reconstruction loss: 49.1599. Test KLD loss: 7.2791. Time: 1217.32\n",
      "<-- Epoch: 393. Average Train loss: 13.0225. Train Reconstruction loss: 4.0279. Train KLD loss: 8.9945. Time: 1218.69\n",
      "<-- Epoch: 393. Average Test loss: 56.5135. Test Reconstruction loss: 48.7808. Test KLD loss: 7.7327. Time: 1218.99\n",
      "<-- Epoch: 394. Average Train loss: 12.9152. Train Reconstruction loss: 3.9291. Train KLD loss: 8.9861. Time: 1220.29\n",
      "<-- Epoch: 394. Average Test loss: 56.3634. Test Reconstruction loss: 49.0908. Test KLD loss: 7.2726. Time: 1220.58\n",
      "<-- Epoch: 395. Average Train loss: 13.0463. Train Reconstruction loss: 4.0164. Train KLD loss: 9.0298. Time: 1221.92\n",
      "<-- Epoch: 395. Average Test loss: 56.0250. Test Reconstruction loss: 48.9623. Test KLD loss: 7.0627. Time: 1222.26\n",
      "<-- Epoch: 396. Average Train loss: 12.9072. Train Reconstruction loss: 3.9315. Train KLD loss: 8.9757. Time: 1223.47\n",
      "<-- Epoch: 396. Average Test loss: 56.4581. Test Reconstruction loss: 49.0947. Test KLD loss: 7.3634. Time: 1223.79\n",
      "<-- Epoch: 397. Average Train loss: 13.1361. Train Reconstruction loss: 4.0872. Train KLD loss: 9.0490. Time: 1225.27\n",
      "<-- Epoch: 397. Average Test loss: 56.9721. Test Reconstruction loss: 49.6200. Test KLD loss: 7.3520. Time: 1225.68\n",
      "<-- Epoch: 398. Average Train loss: 13.0340. Train Reconstruction loss: 3.8938. Train KLD loss: 9.1403. Time: 1226.93\n",
      "<-- Epoch: 398. Average Test loss: 56.1294. Test Reconstruction loss: 49.1665. Test KLD loss: 6.9629. Time: 1227.33\n",
      "<-- Epoch: 399. Average Train loss: 13.1349. Train Reconstruction loss: 4.0928. Train KLD loss: 9.0421. Time: 1228.75\n",
      "<-- Epoch: 399. Average Test loss: 56.3609. Test Reconstruction loss: 48.9984. Test KLD loss: 7.3625. Time: 1229.11\n",
      "<-- Epoch: 400. Average Train loss: 13.0389. Train Reconstruction loss: 4.0792. Train KLD loss: 8.9597. Time: 1230.32\n",
      "<-- Epoch: 400. Average Test loss: 57.6554. Test Reconstruction loss: 50.2343. Test KLD loss: 7.4211. Time: 1230.62\n",
      "<-- Epoch: 401. Average Train loss: 13.0645. Train Reconstruction loss: 4.0397. Train KLD loss: 9.0248. Time: 1231.95\n",
      "<-- Epoch: 401. Average Test loss: 57.0549. Test Reconstruction loss: 49.6906. Test KLD loss: 7.3643. Time: 1232.30\n",
      "<-- Epoch: 402. Average Train loss: 13.0045. Train Reconstruction loss: 3.9748. Train KLD loss: 9.0297. Time: 1233.51\n",
      "<-- Epoch: 402. Average Test loss: 57.2880. Test Reconstruction loss: 50.3666. Test KLD loss: 6.9214. Time: 1233.81\n",
      "<-- Epoch: 403. Average Train loss: 12.8790. Train Reconstruction loss: 3.9585. Train KLD loss: 8.9206. Time: 1235.52\n",
      "<-- Epoch: 403. Average Test loss: 56.7924. Test Reconstruction loss: 49.8123. Test KLD loss: 6.9801. Time: 1235.83\n",
      "<-- Epoch: 404. Average Train loss: 13.0707. Train Reconstruction loss: 4.0346. Train KLD loss: 9.0360. Time: 1237.06\n",
      "<-- Epoch: 404. Average Test loss: 56.7691. Test Reconstruction loss: 49.5154. Test KLD loss: 7.2537. Time: 1237.39\n",
      "<-- Epoch: 405. Average Train loss: 13.0053. Train Reconstruction loss: 3.9184. Train KLD loss: 9.0869. Time: 1239.64\n",
      "<-- Epoch: 405. Average Test loss: 56.4581. Test Reconstruction loss: 48.9793. Test KLD loss: 7.4787. Time: 1240.27\n",
      "<-- Epoch: 406. Average Train loss: 13.0744. Train Reconstruction loss: 4.0393. Train KLD loss: 9.0351. Time: 1242.65\n",
      "<-- Epoch: 406. Average Test loss: 56.9576. Test Reconstruction loss: 49.5290. Test KLD loss: 7.4286. Time: 1243.25\n",
      "<-- Epoch: 407. Average Train loss: 12.8310. Train Reconstruction loss: 3.8821. Train KLD loss: 8.9489. Time: 1245.63\n",
      "<-- Epoch: 407. Average Test loss: 57.5160. Test Reconstruction loss: 50.1495. Test KLD loss: 7.3664. Time: 1246.16\n",
      "<-- Epoch: 408. Average Train loss: 12.9485. Train Reconstruction loss: 3.8361. Train KLD loss: 9.1123. Time: 1247.69\n",
      "<-- Epoch: 408. Average Test loss: 57.5923. Test Reconstruction loss: 50.6119. Test KLD loss: 6.9804. Time: 1248.04\n",
      "<-- Epoch: 409. Average Train loss: 13.2299. Train Reconstruction loss: 4.0963. Train KLD loss: 9.1336. Time: 1249.42\n",
      "<-- Epoch: 409. Average Test loss: 56.7107. Test Reconstruction loss: 49.6267. Test KLD loss: 7.0839. Time: 1249.81\n",
      "<-- Epoch: 410. Average Train loss: 13.0117. Train Reconstruction loss: 3.9081. Train KLD loss: 9.1036. Time: 1251.24\n",
      "<-- Epoch: 410. Average Test loss: 57.2995. Test Reconstruction loss: 50.3762. Test KLD loss: 6.9232. Time: 1251.58\n",
      "<-- Epoch: 411. Average Train loss: 12.7834. Train Reconstruction loss: 3.7728. Train KLD loss: 9.0106. Time: 1252.87\n",
      "<-- Epoch: 411. Average Test loss: 56.6432. Test Reconstruction loss: 49.5892. Test KLD loss: 7.0541. Time: 1253.18\n",
      "<-- Epoch: 412. Average Train loss: 12.8021. Train Reconstruction loss: 3.9719. Train KLD loss: 8.8302. Time: 1254.51\n",
      "<-- Epoch: 412. Average Test loss: 57.4473. Test Reconstruction loss: 50.1826. Test KLD loss: 7.2648. Time: 1254.94\n",
      "<-- Epoch: 413. Average Train loss: 12.9778. Train Reconstruction loss: 3.8742. Train KLD loss: 9.1036. Time: 1256.37\n",
      "<-- Epoch: 413. Average Test loss: 57.3281. Test Reconstruction loss: 50.3584. Test KLD loss: 6.9696. Time: 1256.72\n",
      "<-- Epoch: 414. Average Train loss: 12.9023. Train Reconstruction loss: 3.8380. Train KLD loss: 9.0643. Time: 1258.22\n",
      "<-- Epoch: 414. Average Test loss: 57.0467. Test Reconstruction loss: 49.5973. Test KLD loss: 7.4494. Time: 1258.52\n",
      "<-- Epoch: 415. Average Train loss: 12.8208. Train Reconstruction loss: 3.8346. Train KLD loss: 8.9862. Time: 1260.37\n",
      "<-- Epoch: 415. Average Test loss: 57.4565. Test Reconstruction loss: 50.4497. Test KLD loss: 7.0068. Time: 1260.92\n",
      "<-- Epoch: 416. Average Train loss: 13.1152. Train Reconstruction loss: 3.9800. Train KLD loss: 9.1352. Time: 1263.55\n",
      "<-- Epoch: 416. Average Test loss: 58.0028. Test Reconstruction loss: 50.3834. Test KLD loss: 7.6194. Time: 1264.18\n",
      "<-- Epoch: 417. Average Train loss: 13.2054. Train Reconstruction loss: 4.0155. Train KLD loss: 9.1899. Time: 1266.52\n",
      "<-- Epoch: 417. Average Test loss: 58.4841. Test Reconstruction loss: 50.9926. Test KLD loss: 7.4915. Time: 1267.11\n",
      "<-- Epoch: 418. Average Train loss: 13.0657. Train Reconstruction loss: 3.9422. Train KLD loss: 9.1235. Time: 1269.61\n",
      "<-- Epoch: 418. Average Test loss: 57.3061. Test Reconstruction loss: 49.3970. Test KLD loss: 7.9092. Time: 1270.22\n",
      "<-- Epoch: 419. Average Train loss: 12.9834. Train Reconstruction loss: 3.9246. Train KLD loss: 9.0587. Time: 1273.09\n",
      "<-- Epoch: 419. Average Test loss: 57.7374. Test Reconstruction loss: 50.3107. Test KLD loss: 7.4266. Time: 1274.08\n",
      "<-- Epoch: 420. Average Train loss: 12.9104. Train Reconstruction loss: 3.7592. Train KLD loss: 9.1512. Time: 1275.59\n",
      "<-- Epoch: 420. Average Test loss: 58.1927. Test Reconstruction loss: 50.5996. Test KLD loss: 7.5931. Time: 1275.89\n",
      "<-- Epoch: 421. Average Train loss: 12.9850. Train Reconstruction loss: 3.7801. Train KLD loss: 9.2050. Time: 1277.09\n",
      "<-- Epoch: 421. Average Test loss: 57.8496. Test Reconstruction loss: 50.0169. Test KLD loss: 7.8327. Time: 1277.40\n",
      "<-- Epoch: 422. Average Train loss: 12.8254. Train Reconstruction loss: 3.8776. Train KLD loss: 8.9478. Time: 1278.75\n",
      "<-- Epoch: 422. Average Test loss: 58.1918. Test Reconstruction loss: 50.7723. Test KLD loss: 7.4194. Time: 1279.06\n",
      "<-- Epoch: 423. Average Train loss: 12.7874. Train Reconstruction loss: 3.7578. Train KLD loss: 9.0297. Time: 1280.70\n",
      "<-- Epoch: 423. Average Test loss: 57.8575. Test Reconstruction loss: 50.3315. Test KLD loss: 7.5260. Time: 1281.11\n",
      "<-- Epoch: 424. Average Train loss: 12.9421. Train Reconstruction loss: 3.8849. Train KLD loss: 9.0571. Time: 1282.80\n",
      "<-- Epoch: 424. Average Test loss: 58.0666. Test Reconstruction loss: 50.3584. Test KLD loss: 7.7083. Time: 1283.15\n",
      "<-- Epoch: 425. Average Train loss: 12.9771. Train Reconstruction loss: 3.8785. Train KLD loss: 9.0986. Time: 1284.68\n",
      "<-- Epoch: 425. Average Test loss: 57.8410. Test Reconstruction loss: 50.0845. Test KLD loss: 7.7565. Time: 1285.04\n",
      "<-- Epoch: 426. Average Train loss: 13.1397. Train Reconstruction loss: 3.9348. Train KLD loss: 9.2049. Time: 1286.35\n",
      "<-- Epoch: 426. Average Test loss: 57.5593. Test Reconstruction loss: 49.7464. Test KLD loss: 7.8129. Time: 1286.66\n",
      "<-- Epoch: 427. Average Train loss: 12.9775. Train Reconstruction loss: 3.8228. Train KLD loss: 9.1546. Time: 1288.07\n",
      "<-- Epoch: 427. Average Test loss: 57.9005. Test Reconstruction loss: 50.9541. Test KLD loss: 6.9465. Time: 1288.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 428. Average Train loss: 12.6214. Train Reconstruction loss: 3.6189. Train KLD loss: 9.0025. Time: 1289.77\n",
      "<-- Epoch: 428. Average Test loss: 57.7365. Test Reconstruction loss: 50.5594. Test KLD loss: 7.1770. Time: 1290.16\n",
      "<-- Epoch: 429. Average Train loss: 12.8235. Train Reconstruction loss: 3.7587. Train KLD loss: 9.0648. Time: 1291.85\n",
      "<-- Epoch: 429. Average Test loss: 57.4803. Test Reconstruction loss: 49.8407. Test KLD loss: 7.6396. Time: 1292.34\n",
      "<-- Epoch: 430. Average Train loss: 12.9939. Train Reconstruction loss: 3.8958. Train KLD loss: 9.0982. Time: 1293.88\n",
      "<-- Epoch: 430. Average Test loss: 57.9322. Test Reconstruction loss: 50.4827. Test KLD loss: 7.4495. Time: 1294.30\n",
      "<-- Epoch: 431. Average Train loss: 12.9534. Train Reconstruction loss: 3.8708. Train KLD loss: 9.0826. Time: 1295.64\n",
      "<-- Epoch: 431. Average Test loss: 57.9987. Test Reconstruction loss: 50.7678. Test KLD loss: 7.2309. Time: 1295.94\n",
      "<-- Epoch: 432. Average Train loss: 12.9162. Train Reconstruction loss: 3.8331. Train KLD loss: 9.0830. Time: 1297.64\n",
      "<-- Epoch: 432. Average Test loss: 58.2736. Test Reconstruction loss: 50.9443. Test KLD loss: 7.3294. Time: 1298.05\n",
      "<-- Epoch: 433. Average Train loss: 13.0344. Train Reconstruction loss: 3.8734. Train KLD loss: 9.1610. Time: 1299.63\n",
      "<-- Epoch: 433. Average Test loss: 57.3707. Test Reconstruction loss: 50.1561. Test KLD loss: 7.2146. Time: 1300.03\n",
      "<-- Epoch: 434. Average Train loss: 12.9995. Train Reconstruction loss: 3.9167. Train KLD loss: 9.0828. Time: 1301.50\n",
      "<-- Epoch: 434. Average Test loss: 58.6891. Test Reconstruction loss: 51.1719. Test KLD loss: 7.5172. Time: 1301.92\n",
      "<-- Epoch: 435. Average Train loss: 12.7768. Train Reconstruction loss: 3.7612. Train KLD loss: 9.0156. Time: 1303.60\n",
      "<-- Epoch: 435. Average Test loss: 57.5314. Test Reconstruction loss: 50.8737. Test KLD loss: 6.6576. Time: 1303.97\n",
      "<-- Epoch: 436. Average Train loss: 12.7005. Train Reconstruction loss: 3.7507. Train KLD loss: 8.9498. Time: 1305.94\n",
      "<-- Epoch: 436. Average Test loss: 58.7954. Test Reconstruction loss: 51.8540. Test KLD loss: 6.9414. Time: 1306.44\n",
      "<-- Epoch: 437. Average Train loss: 13.0955. Train Reconstruction loss: 3.9334. Train KLD loss: 9.1621. Time: 1308.29\n",
      "<-- Epoch: 437. Average Test loss: 57.8106. Test Reconstruction loss: 49.9788. Test KLD loss: 7.8318. Time: 1308.60\n",
      "<-- Epoch: 438. Average Train loss: 12.7886. Train Reconstruction loss: 3.7157. Train KLD loss: 9.0730. Time: 1309.82\n",
      "<-- Epoch: 438. Average Test loss: 58.2549. Test Reconstruction loss: 51.1252. Test KLD loss: 7.1297. Time: 1310.16\n",
      "<-- Epoch: 439. Average Train loss: 12.7949. Train Reconstruction loss: 3.6170. Train KLD loss: 9.1779. Time: 1311.61\n",
      "<-- Epoch: 439. Average Test loss: 58.5253. Test Reconstruction loss: 51.7140. Test KLD loss: 6.8113. Time: 1311.91\n",
      "<-- Epoch: 440. Average Train loss: 13.1205. Train Reconstruction loss: 3.7816. Train KLD loss: 9.3388. Time: 1313.14\n",
      "<-- Epoch: 440. Average Test loss: 58.2785. Test Reconstruction loss: 50.9687. Test KLD loss: 7.3098. Time: 1313.44\n",
      "<-- Epoch: 441. Average Train loss: 12.7056. Train Reconstruction loss: 3.6559. Train KLD loss: 9.0496. Time: 1314.67\n",
      "<-- Epoch: 441. Average Test loss: 58.9146. Test Reconstruction loss: 52.2049. Test KLD loss: 6.7097. Time: 1314.97\n",
      "<-- Epoch: 442. Average Train loss: 12.9012. Train Reconstruction loss: 3.7489. Train KLD loss: 9.1523. Time: 1316.24\n",
      "<-- Epoch: 442. Average Test loss: 58.5735. Test Reconstruction loss: 51.7349. Test KLD loss: 6.8386. Time: 1316.57\n",
      "<-- Epoch: 443. Average Train loss: 12.9478. Train Reconstruction loss: 3.8823. Train KLD loss: 9.0656. Time: 1317.90\n",
      "<-- Epoch: 443. Average Test loss: 58.6721. Test Reconstruction loss: 50.9799. Test KLD loss: 7.6923. Time: 1318.22\n",
      "<-- Epoch: 444. Average Train loss: 12.8167. Train Reconstruction loss: 3.6729. Train KLD loss: 9.1438. Time: 1319.43\n",
      "<-- Epoch: 444. Average Test loss: 58.6526. Test Reconstruction loss: 51.4102. Test KLD loss: 7.2424. Time: 1319.72\n",
      "<-- Epoch: 445. Average Train loss: 12.8620. Train Reconstruction loss: 3.7339. Train KLD loss: 9.1280. Time: 1320.94\n",
      "<-- Epoch: 445. Average Test loss: 59.0248. Test Reconstruction loss: 51.5739. Test KLD loss: 7.4509. Time: 1321.37\n",
      "<-- Epoch: 446. Average Train loss: 12.7416. Train Reconstruction loss: 3.6331. Train KLD loss: 9.1085. Time: 1322.81\n",
      "<-- Epoch: 446. Average Test loss: 59.3583. Test Reconstruction loss: 52.1970. Test KLD loss: 7.1613. Time: 1324.05\n",
      "<-- Epoch: 447. Average Train loss: 12.8563. Train Reconstruction loss: 3.7736. Train KLD loss: 9.0827. Time: 1327.14\n",
      "<-- Epoch: 447. Average Test loss: 58.9316. Test Reconstruction loss: 51.4702. Test KLD loss: 7.4613. Time: 1327.54\n",
      "<-- Epoch: 448. Average Train loss: 12.9212. Train Reconstruction loss: 3.7806. Train KLD loss: 9.1406. Time: 1331.38\n",
      "<-- Epoch: 448. Average Test loss: 58.2620. Test Reconstruction loss: 50.5708. Test KLD loss: 7.6912. Time: 1332.11\n",
      "<-- Epoch: 449. Average Train loss: 12.7245. Train Reconstruction loss: 3.5968. Train KLD loss: 9.1277. Time: 1335.43\n",
      "<-- Epoch: 449. Average Test loss: 58.8785. Test Reconstruction loss: 51.4035. Test KLD loss: 7.4750. Time: 1336.09\n",
      "<-- Epoch: 450. Average Train loss: 12.7466. Train Reconstruction loss: 3.5258. Train KLD loss: 9.2209. Time: 1339.25\n",
      "<-- Epoch: 450. Average Test loss: 59.5833. Test Reconstruction loss: 52.6223. Test KLD loss: 6.9610. Time: 1340.05\n",
      "<-- Epoch: 451. Average Train loss: 12.8065. Train Reconstruction loss: 3.7243. Train KLD loss: 9.0823. Time: 1342.94\n",
      "<-- Epoch: 451. Average Test loss: 59.1233. Test Reconstruction loss: 51.6010. Test KLD loss: 7.5223. Time: 1343.78\n",
      "<-- Epoch: 452. Average Train loss: 12.7486. Train Reconstruction loss: 3.6469. Train KLD loss: 9.1017. Time: 1347.69\n",
      "<-- Epoch: 452. Average Test loss: 58.6644. Test Reconstruction loss: 51.6014. Test KLD loss: 7.0630. Time: 1348.55\n",
      "<-- Epoch: 453. Average Train loss: 12.7985. Train Reconstruction loss: 3.7295. Train KLD loss: 9.0690. Time: 1350.47\n",
      "<-- Epoch: 453. Average Test loss: 58.7848. Test Reconstruction loss: 50.9679. Test KLD loss: 7.8169. Time: 1350.79\n",
      "<-- Epoch: 454. Average Train loss: 12.7199. Train Reconstruction loss: 3.5512. Train KLD loss: 9.1687. Time: 1352.17\n",
      "<-- Epoch: 454. Average Test loss: 59.7679. Test Reconstruction loss: 51.6960. Test KLD loss: 8.0719. Time: 1352.54\n",
      "<-- Epoch: 455. Average Train loss: 12.6184. Train Reconstruction loss: 3.5518. Train KLD loss: 9.0665. Time: 1353.93\n",
      "<-- Epoch: 455. Average Test loss: 59.1922. Test Reconstruction loss: 52.0077. Test KLD loss: 7.1845. Time: 1354.30\n",
      "<-- Epoch: 456. Average Train loss: 12.9390. Train Reconstruction loss: 3.7873. Train KLD loss: 9.1517. Time: 1355.57\n",
      "<-- Epoch: 456. Average Test loss: 59.3417. Test Reconstruction loss: 52.0947. Test KLD loss: 7.2471. Time: 1355.89\n",
      "<-- Epoch: 457. Average Train loss: 12.7824. Train Reconstruction loss: 3.7015. Train KLD loss: 9.0810. Time: 1357.58\n",
      "<-- Epoch: 457. Average Test loss: 58.7191. Test Reconstruction loss: 51.3438. Test KLD loss: 7.3754. Time: 1357.93\n",
      "<-- Epoch: 458. Average Train loss: 13.0175. Train Reconstruction loss: 3.7082. Train KLD loss: 9.3092. Time: 1359.41\n",
      "<-- Epoch: 458. Average Test loss: 58.7915. Test Reconstruction loss: 51.2353. Test KLD loss: 7.5562. Time: 1359.73\n",
      "<-- Epoch: 459. Average Train loss: 12.7733. Train Reconstruction loss: 3.6650. Train KLD loss: 9.1082. Time: 1360.99\n",
      "<-- Epoch: 459. Average Test loss: 59.0904. Test Reconstruction loss: 51.8397. Test KLD loss: 7.2507. Time: 1361.33\n",
      "<-- Epoch: 460. Average Train loss: 12.6373. Train Reconstruction loss: 3.5461. Train KLD loss: 9.0912. Time: 1362.65\n",
      "<-- Epoch: 460. Average Test loss: 59.4468. Test Reconstruction loss: 52.1802. Test KLD loss: 7.2667. Time: 1362.94\n",
      "<-- Epoch: 461. Average Train loss: 13.0176. Train Reconstruction loss: 3.8761. Train KLD loss: 9.1415. Time: 1364.66\n",
      "<-- Epoch: 461. Average Test loss: 60.3599. Test Reconstruction loss: 52.6492. Test KLD loss: 7.7106. Time: 1364.97\n",
      "<-- Epoch: 462. Average Train loss: 12.8165. Train Reconstruction loss: 3.6170. Train KLD loss: 9.1995. Time: 1366.39\n",
      "<-- Epoch: 462. Average Test loss: 60.3568. Test Reconstruction loss: 52.7248. Test KLD loss: 7.6320. Time: 1366.70\n",
      "<-- Epoch: 463. Average Train loss: 12.8989. Train Reconstruction loss: 3.6627. Train KLD loss: 9.2362. Time: 1368.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 463. Average Test loss: 61.0488. Test Reconstruction loss: 52.9351. Test KLD loss: 8.1138. Time: 1368.40\n",
      "<-- Epoch: 464. Average Train loss: 12.7905. Train Reconstruction loss: 3.5616. Train KLD loss: 9.2289. Time: 1369.77\n",
      "<-- Epoch: 464. Average Test loss: 60.2060. Test Reconstruction loss: 52.6945. Test KLD loss: 7.5115. Time: 1370.09\n",
      "<-- Epoch: 465. Average Train loss: 12.9367. Train Reconstruction loss: 3.7233. Train KLD loss: 9.2135. Time: 1371.48\n",
      "<-- Epoch: 465. Average Test loss: 59.1118. Test Reconstruction loss: 51.6385. Test KLD loss: 7.4733. Time: 1371.80\n",
      "<-- Epoch: 466. Average Train loss: 12.9157. Train Reconstruction loss: 3.6829. Train KLD loss: 9.2328. Time: 1373.19\n",
      "<-- Epoch: 466. Average Test loss: 59.3936. Test Reconstruction loss: 51.9406. Test KLD loss: 7.4530. Time: 1373.52\n",
      "<-- Epoch: 467. Average Train loss: 12.7144. Train Reconstruction loss: 3.5948. Train KLD loss: 9.1196. Time: 1374.85\n",
      "<-- Epoch: 467. Average Test loss: 59.8280. Test Reconstruction loss: 52.5838. Test KLD loss: 7.2443. Time: 1375.20\n",
      "<-- Epoch: 468. Average Train loss: 12.5418. Train Reconstruction loss: 3.5649. Train KLD loss: 8.9770. Time: 1376.53\n",
      "<-- Epoch: 468. Average Test loss: 60.6383. Test Reconstruction loss: 53.3183. Test KLD loss: 7.3200. Time: 1376.83\n",
      "<-- Epoch: 469. Average Train loss: 12.6770. Train Reconstruction loss: 3.6208. Train KLD loss: 9.0562. Time: 1378.16\n",
      "<-- Epoch: 469. Average Test loss: 59.9097. Test Reconstruction loss: 52.3699. Test KLD loss: 7.5398. Time: 1378.46\n",
      "<-- Epoch: 470. Average Train loss: 12.7801. Train Reconstruction loss: 3.6637. Train KLD loss: 9.1164. Time: 1379.84\n",
      "<-- Epoch: 470. Average Test loss: 58.8890. Test Reconstruction loss: 51.1178. Test KLD loss: 7.7712. Time: 1380.18\n",
      "<-- Epoch: 471. Average Train loss: 12.7899. Train Reconstruction loss: 3.5415. Train KLD loss: 9.2484. Time: 1381.60\n",
      "<-- Epoch: 471. Average Test loss: 59.5329. Test Reconstruction loss: 52.1786. Test KLD loss: 7.3543. Time: 1381.92\n",
      "<-- Epoch: 472. Average Train loss: 12.8748. Train Reconstruction loss: 3.6586. Train KLD loss: 9.2162. Time: 1383.26\n",
      "<-- Epoch: 472. Average Test loss: 60.2944. Test Reconstruction loss: 52.6616. Test KLD loss: 7.6328. Time: 1383.59\n",
      "<-- Epoch: 473. Average Train loss: 12.8956. Train Reconstruction loss: 3.6654. Train KLD loss: 9.2302. Time: 1384.93\n",
      "<-- Epoch: 473. Average Test loss: 60.1618. Test Reconstruction loss: 52.5023. Test KLD loss: 7.6595. Time: 1385.26\n",
      "<-- Epoch: 474. Average Train loss: 12.7601. Train Reconstruction loss: 3.5996. Train KLD loss: 9.1606. Time: 1386.58\n",
      "<-- Epoch: 474. Average Test loss: 59.2848. Test Reconstruction loss: 51.7557. Test KLD loss: 7.5291. Time: 1386.91\n",
      "<-- Epoch: 475. Average Train loss: 12.6520. Train Reconstruction loss: 3.5993. Train KLD loss: 9.0527. Time: 1388.28\n",
      "<-- Epoch: 475. Average Test loss: 59.7846. Test Reconstruction loss: 52.5020. Test KLD loss: 7.2826. Time: 1388.62\n",
      "<-- Epoch: 476. Average Train loss: 12.8123. Train Reconstruction loss: 3.7228. Train KLD loss: 9.0895. Time: 1390.06\n",
      "<-- Epoch: 476. Average Test loss: 59.2354. Test Reconstruction loss: 51.6350. Test KLD loss: 7.6004. Time: 1390.37\n",
      "<-- Epoch: 477. Average Train loss: 12.6468. Train Reconstruction loss: 3.5192. Train KLD loss: 9.1277. Time: 1391.66\n",
      "<-- Epoch: 477. Average Test loss: 59.6957. Test Reconstruction loss: 51.8605. Test KLD loss: 7.8352. Time: 1391.98\n",
      "<-- Epoch: 478. Average Train loss: 12.8031. Train Reconstruction loss: 3.5863. Train KLD loss: 9.2169. Time: 1393.28\n",
      "<-- Epoch: 478. Average Test loss: 60.4976. Test Reconstruction loss: 52.9473. Test KLD loss: 7.5503. Time: 1393.60\n",
      "<-- Epoch: 479. Average Train loss: 13.0759. Train Reconstruction loss: 3.7874. Train KLD loss: 9.2886. Time: 1394.91\n",
      "<-- Epoch: 479. Average Test loss: 60.2777. Test Reconstruction loss: 53.1429. Test KLD loss: 7.1349. Time: 1395.23\n",
      "<-- Epoch: 480. Average Train loss: 12.7263. Train Reconstruction loss: 3.5301. Train KLD loss: 9.1962. Time: 1396.47\n",
      "<-- Epoch: 480. Average Test loss: 59.5451. Test Reconstruction loss: 52.4413. Test KLD loss: 7.1038. Time: 1396.77\n",
      "<-- Epoch: 481. Average Train loss: 12.6247. Train Reconstruction loss: 3.5632. Train KLD loss: 9.0615. Time: 1398.04\n",
      "<-- Epoch: 481. Average Test loss: 60.0868. Test Reconstruction loss: 51.9340. Test KLD loss: 8.1529. Time: 1398.36\n",
      "<-- Epoch: 482. Average Train loss: 12.7525. Train Reconstruction loss: 3.5665. Train KLD loss: 9.1860. Time: 1399.63\n",
      "<-- Epoch: 482. Average Test loss: 60.1661. Test Reconstruction loss: 52.4816. Test KLD loss: 7.6845. Time: 1399.93\n",
      "<-- Epoch: 483. Average Train loss: 12.5873. Train Reconstruction loss: 3.4866. Train KLD loss: 9.1007. Time: 1401.22\n",
      "<-- Epoch: 483. Average Test loss: 60.1388. Test Reconstruction loss: 52.7093. Test KLD loss: 7.4296. Time: 1401.94\n",
      "<-- Epoch: 484. Average Train loss: 12.6570. Train Reconstruction loss: 3.5410. Train KLD loss: 9.1159. Time: 1403.50\n",
      "<-- Epoch: 484. Average Test loss: 60.1810. Test Reconstruction loss: 52.6393. Test KLD loss: 7.5417. Time: 1403.84\n",
      "<-- Epoch: 485. Average Train loss: 12.7344. Train Reconstruction loss: 3.5525. Train KLD loss: 9.1819. Time: 1405.32\n",
      "<-- Epoch: 485. Average Test loss: 60.4809. Test Reconstruction loss: 53.2652. Test KLD loss: 7.2157. Time: 1405.67\n",
      "<-- Epoch: 486. Average Train loss: 12.6986. Train Reconstruction loss: 3.5851. Train KLD loss: 9.1135. Time: 1407.20\n",
      "<-- Epoch: 486. Average Test loss: 59.5320. Test Reconstruction loss: 51.7499. Test KLD loss: 7.7821. Time: 1407.54\n",
      "<-- Epoch: 487. Average Train loss: 12.6779. Train Reconstruction loss: 3.5927. Train KLD loss: 9.0852. Time: 1408.93\n",
      "<-- Epoch: 487. Average Test loss: 60.5803. Test Reconstruction loss: 52.9922. Test KLD loss: 7.5882. Time: 1409.25\n",
      "<-- Epoch: 488. Average Train loss: 12.5167. Train Reconstruction loss: 3.4439. Train KLD loss: 9.0728. Time: 1410.53\n",
      "<-- Epoch: 488. Average Test loss: 60.2786. Test Reconstruction loss: 53.0173. Test KLD loss: 7.2614. Time: 1410.83\n",
      "<-- Epoch: 489. Average Train loss: 12.5860. Train Reconstruction loss: 3.4928. Train KLD loss: 9.0932. Time: 1412.36\n",
      "<-- Epoch: 489. Average Test loss: 60.6245. Test Reconstruction loss: 53.1249. Test KLD loss: 7.4996. Time: 1412.67\n",
      "<-- Epoch: 490. Average Train loss: 12.9381. Train Reconstruction loss: 3.6336. Train KLD loss: 9.3045. Time: 1414.08\n",
      "<-- Epoch: 490. Average Test loss: 60.1703. Test Reconstruction loss: 52.5033. Test KLD loss: 7.6670. Time: 1414.42\n",
      "<-- Epoch: 491. Average Train loss: 12.9357. Train Reconstruction loss: 3.6012. Train KLD loss: 9.3344. Time: 1416.21\n",
      "<-- Epoch: 491. Average Test loss: 60.5490. Test Reconstruction loss: 52.6607. Test KLD loss: 7.8882. Time: 1416.55\n",
      "<-- Epoch: 492. Average Train loss: 12.6416. Train Reconstruction loss: 3.5173. Train KLD loss: 9.1244. Time: 1417.92\n",
      "<-- Epoch: 492. Average Test loss: 60.5587. Test Reconstruction loss: 52.7311. Test KLD loss: 7.8276. Time: 1418.27\n",
      "<-- Epoch: 493. Average Train loss: 12.7436. Train Reconstruction loss: 3.4390. Train KLD loss: 9.3047. Time: 1419.67\n",
      "<-- Epoch: 493. Average Test loss: 60.5784. Test Reconstruction loss: 53.0595. Test KLD loss: 7.5189. Time: 1419.99\n",
      "<-- Epoch: 494. Average Train loss: 12.9238. Train Reconstruction loss: 3.6134. Train KLD loss: 9.3104. Time: 1421.31\n",
      "<-- Epoch: 494. Average Test loss: 60.8889. Test Reconstruction loss: 53.6384. Test KLD loss: 7.2505. Time: 1421.63\n",
      "<-- Epoch: 495. Average Train loss: 12.8817. Train Reconstruction loss: 3.5587. Train KLD loss: 9.3230. Time: 1422.91\n",
      "<-- Epoch: 495. Average Test loss: 60.9036. Test Reconstruction loss: 53.2916. Test KLD loss: 7.6120. Time: 1423.22\n",
      "<-- Epoch: 496. Average Train loss: 12.4663. Train Reconstruction loss: 3.5491. Train KLD loss: 8.9172. Time: 1424.48\n",
      "<-- Epoch: 496. Average Test loss: 60.5008. Test Reconstruction loss: 52.1950. Test KLD loss: 8.3059. Time: 1424.78\n",
      "<-- Epoch: 497. Average Train loss: 12.7315. Train Reconstruction loss: 3.5090. Train KLD loss: 9.2225. Time: 1426.12\n",
      "<-- Epoch: 497. Average Test loss: 60.7616. Test Reconstruction loss: 53.3752. Test KLD loss: 7.3865. Time: 1426.46\n",
      "<-- Epoch: 498. Average Train loss: 12.5650. Train Reconstruction loss: 3.4350. Train KLD loss: 9.1301. Time: 1427.86\n",
      "<-- Epoch: 498. Average Test loss: 60.5916. Test Reconstruction loss: 52.9990. Test KLD loss: 7.5926. Time: 1428.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 499. Average Train loss: 12.8347. Train Reconstruction loss: 3.5773. Train KLD loss: 9.2574. Time: 1429.57\n",
      "<-- Epoch: 499. Average Test loss: 61.6621. Test Reconstruction loss: 53.9873. Test KLD loss: 7.6748. Time: 1429.90\n",
      "<-- Epoch: 500. Average Train loss: 12.7880. Train Reconstruction loss: 3.6084. Train KLD loss: 9.1797. Time: 1431.28\n",
      "<-- Epoch: 500. Average Test loss: 60.6882. Test Reconstruction loss: 53.4452. Test KLD loss: 7.2430. Time: 1431.59\n",
      "<-- Epoch: 501. Average Train loss: 12.6460. Train Reconstruction loss: 3.4711. Train KLD loss: 9.1749. Time: 1433.10\n",
      "<-- Epoch: 501. Average Test loss: 60.5858. Test Reconstruction loss: 53.1294. Test KLD loss: 7.4563. Time: 1433.46\n",
      "<-- Epoch: 502. Average Train loss: 12.7359. Train Reconstruction loss: 3.4316. Train KLD loss: 9.3043. Time: 1434.81\n",
      "<-- Epoch: 502. Average Test loss: 61.1018. Test Reconstruction loss: 52.7467. Test KLD loss: 8.3550. Time: 1435.13\n",
      "<-- Epoch: 503. Average Train loss: 12.5127. Train Reconstruction loss: 3.3495. Train KLD loss: 9.1632. Time: 1436.45\n",
      "<-- Epoch: 503. Average Test loss: 60.6685. Test Reconstruction loss: 53.3776. Test KLD loss: 7.2909. Time: 1436.78\n",
      "<-- Epoch: 504. Average Train loss: 12.5888. Train Reconstruction loss: 3.4309. Train KLD loss: 9.1579. Time: 1438.10\n",
      "<-- Epoch: 504. Average Test loss: 60.1797. Test Reconstruction loss: 52.4148. Test KLD loss: 7.7649. Time: 1438.42\n",
      "<-- Epoch: 505. Average Train loss: 12.7171. Train Reconstruction loss: 3.3839. Train KLD loss: 9.3332. Time: 1439.75\n",
      "<-- Epoch: 505. Average Test loss: 61.4137. Test Reconstruction loss: 54.0515. Test KLD loss: 7.3621. Time: 1440.07\n",
      "<-- Epoch: 506. Average Train loss: 12.5663. Train Reconstruction loss: 3.4403. Train KLD loss: 9.1260. Time: 1441.51\n",
      "<-- Epoch: 506. Average Test loss: 60.6983. Test Reconstruction loss: 52.9754. Test KLD loss: 7.7229. Time: 1441.83\n",
      "<-- Epoch: 507. Average Train loss: 12.9324. Train Reconstruction loss: 3.5308. Train KLD loss: 9.4016. Time: 1443.40\n",
      "<-- Epoch: 507. Average Test loss: 60.9669. Test Reconstruction loss: 53.4160. Test KLD loss: 7.5509. Time: 1443.79\n",
      "<-- Epoch: 508. Average Train loss: 12.6636. Train Reconstruction loss: 3.4928. Train KLD loss: 9.1708. Time: 1445.16\n",
      "<-- Epoch: 508. Average Test loss: 61.2175. Test Reconstruction loss: 54.0274. Test KLD loss: 7.1901. Time: 1445.48\n",
      "<-- Epoch: 509. Average Train loss: 12.8168. Train Reconstruction loss: 3.5372. Train KLD loss: 9.2796. Time: 1446.92\n",
      "<-- Epoch: 509. Average Test loss: 61.1701. Test Reconstruction loss: 53.5822. Test KLD loss: 7.5879. Time: 1447.24\n",
      "<-- Epoch: 510. Average Train loss: 12.7283. Train Reconstruction loss: 3.5938. Train KLD loss: 9.1345. Time: 1448.53\n",
      "<-- Epoch: 510. Average Test loss: 60.9204. Test Reconstruction loss: 53.1532. Test KLD loss: 7.7672. Time: 1448.83\n",
      "<-- Epoch: 511. Average Train loss: 13.0140. Train Reconstruction loss: 3.5769. Train KLD loss: 9.4371. Time: 1450.17\n",
      "<-- Epoch: 511. Average Test loss: 61.0592. Test Reconstruction loss: 53.3209. Test KLD loss: 7.7383. Time: 1450.48\n",
      "<-- Epoch: 512. Average Train loss: 12.5261. Train Reconstruction loss: 3.3824. Train KLD loss: 9.1437. Time: 1451.76\n",
      "<-- Epoch: 512. Average Test loss: 60.6888. Test Reconstruction loss: 53.3815. Test KLD loss: 7.3073. Time: 1452.06\n",
      "<-- Epoch: 513. Average Train loss: 12.7990. Train Reconstruction loss: 3.5737. Train KLD loss: 9.2252. Time: 1453.36\n",
      "<-- Epoch: 513. Average Test loss: 62.2478. Test Reconstruction loss: 54.2406. Test KLD loss: 8.0072. Time: 1453.66\n",
      "<-- Epoch: 514. Average Train loss: 12.5756. Train Reconstruction loss: 3.3362. Train KLD loss: 9.2394. Time: 1455.02\n",
      "<-- Epoch: 514. Average Test loss: 62.8649. Test Reconstruction loss: 55.1752. Test KLD loss: 7.6897. Time: 1455.34\n",
      "<-- Epoch: 515. Average Train loss: 12.5564. Train Reconstruction loss: 3.4824. Train KLD loss: 9.0740. Time: 1456.65\n",
      "<-- Epoch: 515. Average Test loss: 61.4165. Test Reconstruction loss: 54.2909. Test KLD loss: 7.1256. Time: 1456.95\n",
      "<-- Epoch: 516. Average Train loss: 12.5912. Train Reconstruction loss: 3.4210. Train KLD loss: 9.1702. Time: 1458.35\n",
      "<-- Epoch: 516. Average Test loss: 60.6702. Test Reconstruction loss: 52.8762. Test KLD loss: 7.7940. Time: 1458.65\n",
      "<-- Epoch: 517. Average Train loss: 12.6258. Train Reconstruction loss: 3.4780. Train KLD loss: 9.1478. Time: 1460.00\n",
      "<-- Epoch: 517. Average Test loss: 61.7762. Test Reconstruction loss: 54.1015. Test KLD loss: 7.6747. Time: 1460.34\n",
      "<-- Epoch: 518. Average Train loss: 12.5893. Train Reconstruction loss: 3.3395. Train KLD loss: 9.2498. Time: 1461.65\n",
      "<-- Epoch: 518. Average Test loss: 61.2781. Test Reconstruction loss: 53.9564. Test KLD loss: 7.3217. Time: 1461.95\n",
      "<-- Epoch: 519. Average Train loss: 12.6497. Train Reconstruction loss: 3.4358. Train KLD loss: 9.2139. Time: 1463.29\n",
      "<-- Epoch: 519. Average Test loss: 60.8352. Test Reconstruction loss: 52.8642. Test KLD loss: 7.9710. Time: 1463.63\n",
      "<-- Epoch: 520. Average Train loss: 12.5699. Train Reconstruction loss: 3.2610. Train KLD loss: 9.3089. Time: 1465.01\n",
      "<-- Epoch: 520. Average Test loss: 61.2031. Test Reconstruction loss: 53.3095. Test KLD loss: 7.8935. Time: 1465.37\n",
      "<-- Epoch: 521. Average Train loss: 12.7692. Train Reconstruction loss: 3.4338. Train KLD loss: 9.3353. Time: 1466.75\n",
      "<-- Epoch: 521. Average Test loss: 61.4552. Test Reconstruction loss: 53.9126. Test KLD loss: 7.5426. Time: 1467.09\n",
      "<-- Epoch: 522. Average Train loss: 12.5230. Train Reconstruction loss: 3.2607. Train KLD loss: 9.2623. Time: 1468.45\n",
      "<-- Epoch: 522. Average Test loss: 61.7179. Test Reconstruction loss: 54.2193. Test KLD loss: 7.4987. Time: 1468.79\n",
      "<-- Epoch: 523. Average Train loss: 12.6046. Train Reconstruction loss: 3.4111. Train KLD loss: 9.1935. Time: 1470.14\n",
      "<-- Epoch: 523. Average Test loss: 62.0445. Test Reconstruction loss: 54.3091. Test KLD loss: 7.7354. Time: 1470.48\n",
      "<-- Epoch: 524. Average Train loss: 12.7233. Train Reconstruction loss: 3.3663. Train KLD loss: 9.3570. Time: 1471.98\n",
      "<-- Epoch: 524. Average Test loss: 62.0958. Test Reconstruction loss: 54.5412. Test KLD loss: 7.5546. Time: 1472.33\n",
      "<-- Epoch: 525. Average Train loss: 12.7808. Train Reconstruction loss: 3.4342. Train KLD loss: 9.3466. Time: 1473.74\n",
      "<-- Epoch: 525. Average Test loss: 62.0052. Test Reconstruction loss: 54.5122. Test KLD loss: 7.4931. Time: 1474.06\n",
      "<-- Epoch: 526. Average Train loss: 12.5888. Train Reconstruction loss: 3.3588. Train KLD loss: 9.2299. Time: 1475.47\n",
      "<-- Epoch: 526. Average Test loss: 61.8876. Test Reconstruction loss: 54.1384. Test KLD loss: 7.7492. Time: 1475.77\n",
      "<-- Epoch: 527. Average Train loss: 12.8215. Train Reconstruction loss: 3.4232. Train KLD loss: 9.3983. Time: 1477.14\n",
      "<-- Epoch: 527. Average Test loss: 61.1756. Test Reconstruction loss: 53.2047. Test KLD loss: 7.9709. Time: 1477.48\n",
      "<-- Epoch: 528. Average Train loss: 12.6500. Train Reconstruction loss: 3.4002. Train KLD loss: 9.2498. Time: 1478.93\n",
      "<-- Epoch: 528. Average Test loss: 62.4508. Test Reconstruction loss: 54.9870. Test KLD loss: 7.4638. Time: 1479.26\n",
      "<-- Epoch: 529. Average Train loss: 12.6345. Train Reconstruction loss: 3.3541. Train KLD loss: 9.2804. Time: 1480.62\n",
      "<-- Epoch: 529. Average Test loss: 61.1516. Test Reconstruction loss: 53.5550. Test KLD loss: 7.5966. Time: 1480.96\n",
      "<-- Epoch: 530. Average Train loss: 12.7310. Train Reconstruction loss: 3.4682. Train KLD loss: 9.2628. Time: 1482.42\n",
      "<-- Epoch: 530. Average Test loss: 61.7037. Test Reconstruction loss: 53.7038. Test KLD loss: 7.9999. Time: 1482.83\n",
      "<-- Epoch: 531. Average Train loss: 12.4858. Train Reconstruction loss: 3.3143. Train KLD loss: 9.1715. Time: 1484.33\n",
      "<-- Epoch: 531. Average Test loss: 62.0438. Test Reconstruction loss: 54.0861. Test KLD loss: 7.9576. Time: 1484.65\n",
      "<-- Epoch: 532. Average Train loss: 12.4894. Train Reconstruction loss: 3.3448. Train KLD loss: 9.1447. Time: 1486.04\n",
      "<-- Epoch: 532. Average Test loss: 62.0455. Test Reconstruction loss: 54.4075. Test KLD loss: 7.6380. Time: 1486.41\n",
      "<-- Epoch: 533. Average Train loss: 12.7426. Train Reconstruction loss: 3.4973. Train KLD loss: 9.2453. Time: 1487.94\n",
      "<-- Epoch: 533. Average Test loss: 61.9955. Test Reconstruction loss: 54.5536. Test KLD loss: 7.4419. Time: 1488.25\n",
      "<-- Epoch: 534. Average Train loss: 12.5809. Train Reconstruction loss: 3.4330. Train KLD loss: 9.1479. Time: 1489.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 534. Average Test loss: 62.4124. Test Reconstruction loss: 54.8800. Test KLD loss: 7.5324. Time: 1489.89\n",
      "<-- Epoch: 535. Average Train loss: 12.7242. Train Reconstruction loss: 3.4084. Train KLD loss: 9.3158. Time: 1491.59\n",
      "<-- Epoch: 535. Average Test loss: 61.2221. Test Reconstruction loss: 53.5336. Test KLD loss: 7.6885. Time: 1491.91\n",
      "<-- Epoch: 536. Average Train loss: 12.6135. Train Reconstruction loss: 3.3799. Train KLD loss: 9.2335. Time: 1493.84\n",
      "<-- Epoch: 536. Average Test loss: 61.8273. Test Reconstruction loss: 53.8976. Test KLD loss: 7.9297. Time: 1494.32\n",
      "<-- Epoch: 537. Average Train loss: 12.6832. Train Reconstruction loss: 3.3429. Train KLD loss: 9.3403. Time: 1496.49\n",
      "<-- Epoch: 537. Average Test loss: 62.3876. Test Reconstruction loss: 54.7773. Test KLD loss: 7.6103. Time: 1496.83\n",
      "<-- Epoch: 538. Average Train loss: 12.7445. Train Reconstruction loss: 3.5151. Train KLD loss: 9.2294. Time: 1498.92\n",
      "<-- Epoch: 538. Average Test loss: 62.2250. Test Reconstruction loss: 54.8253. Test KLD loss: 7.3997. Time: 1499.42\n",
      "<-- Epoch: 539. Average Train loss: 12.4702. Train Reconstruction loss: 3.3136. Train KLD loss: 9.1566. Time: 1501.07\n",
      "<-- Epoch: 539. Average Test loss: 62.4322. Test Reconstruction loss: 54.8811. Test KLD loss: 7.5511. Time: 1501.61\n",
      "<-- Epoch: 540. Average Train loss: 12.6131. Train Reconstruction loss: 3.4456. Train KLD loss: 9.1675. Time: 1503.11\n",
      "<-- Epoch: 540. Average Test loss: 62.2037. Test Reconstruction loss: 54.3985. Test KLD loss: 7.8052. Time: 1503.57\n",
      "<-- Epoch: 541. Average Train loss: 12.3735. Train Reconstruction loss: 3.2708. Train KLD loss: 9.1027. Time: 1505.09\n",
      "<-- Epoch: 541. Average Test loss: 62.4764. Test Reconstruction loss: 55.0457. Test KLD loss: 7.4307. Time: 1505.43\n",
      "<-- Epoch: 542. Average Train loss: 12.4461. Train Reconstruction loss: 3.3471. Train KLD loss: 9.0990. Time: 1506.72\n",
      "<-- Epoch: 542. Average Test loss: 62.3582. Test Reconstruction loss: 54.7126. Test KLD loss: 7.6456. Time: 1507.01\n",
      "<-- Epoch: 543. Average Train loss: 12.3656. Train Reconstruction loss: 3.2990. Train KLD loss: 9.0666. Time: 1508.52\n",
      "<-- Epoch: 543. Average Test loss: 62.2329. Test Reconstruction loss: 54.8050. Test KLD loss: 7.4279. Time: 1508.83\n",
      "<-- Epoch: 544. Average Train loss: 12.7496. Train Reconstruction loss: 3.3817. Train KLD loss: 9.3678. Time: 1510.16\n",
      "<-- Epoch: 544. Average Test loss: 61.7740. Test Reconstruction loss: 53.8075. Test KLD loss: 7.9665. Time: 1510.46\n",
      "<-- Epoch: 545. Average Train loss: 12.7132. Train Reconstruction loss: 3.4464. Train KLD loss: 9.2668. Time: 1511.76\n",
      "<-- Epoch: 545. Average Test loss: 62.7467. Test Reconstruction loss: 55.2009. Test KLD loss: 7.5458. Time: 1512.05\n",
      "<-- Epoch: 546. Average Train loss: 12.4914. Train Reconstruction loss: 3.2918. Train KLD loss: 9.1996. Time: 1513.38\n",
      "<-- Epoch: 546. Average Test loss: 62.7329. Test Reconstruction loss: 54.9405. Test KLD loss: 7.7924. Time: 1513.83\n",
      "<-- Epoch: 547. Average Train loss: 12.3827. Train Reconstruction loss: 3.3083. Train KLD loss: 9.0743. Time: 1515.40\n",
      "<-- Epoch: 547. Average Test loss: 62.1127. Test Reconstruction loss: 54.8997. Test KLD loss: 7.2129. Time: 1515.71\n",
      "<-- Epoch: 548. Average Train loss: 12.4802. Train Reconstruction loss: 3.3584. Train KLD loss: 9.1218. Time: 1517.01\n",
      "<-- Epoch: 548. Average Test loss: 62.1676. Test Reconstruction loss: 55.2212. Test KLD loss: 6.9464. Time: 1517.32\n",
      "<-- Epoch: 549. Average Train loss: 12.7939. Train Reconstruction loss: 3.5125. Train KLD loss: 9.2814. Time: 1518.62\n",
      "<-- Epoch: 549. Average Test loss: 61.3747. Test Reconstruction loss: 53.6371. Test KLD loss: 7.7376. Time: 1518.92\n",
      "<-- Epoch: 550. Average Train loss: 12.5434. Train Reconstruction loss: 3.3992. Train KLD loss: 9.1442. Time: 1520.22\n",
      "<-- Epoch: 550. Average Test loss: 62.5471. Test Reconstruction loss: 55.0460. Test KLD loss: 7.5011. Time: 1520.52\n",
      "<-- Epoch: 551. Average Train loss: 12.4856. Train Reconstruction loss: 3.3829. Train KLD loss: 9.1027. Time: 1522.07\n",
      "<-- Epoch: 551. Average Test loss: 61.8549. Test Reconstruction loss: 54.0542. Test KLD loss: 7.8007. Time: 1522.39\n",
      "<-- Epoch: 552. Average Train loss: 12.6829. Train Reconstruction loss: 3.2241. Train KLD loss: 9.4588. Time: 1523.90\n",
      "<-- Epoch: 552. Average Test loss: 61.7136. Test Reconstruction loss: 54.2266. Test KLD loss: 7.4870. Time: 1524.27\n",
      "<-- Epoch: 553. Average Train loss: 12.6635. Train Reconstruction loss: 3.3708. Train KLD loss: 9.2927. Time: 1525.68\n",
      "<-- Epoch: 553. Average Test loss: 62.1073. Test Reconstruction loss: 54.2223. Test KLD loss: 7.8850. Time: 1526.00\n",
      "<-- Epoch: 554. Average Train loss: 12.6373. Train Reconstruction loss: 3.3957. Train KLD loss: 9.2416. Time: 1527.49\n",
      "<-- Epoch: 554. Average Test loss: 62.8018. Test Reconstruction loss: 55.1516. Test KLD loss: 7.6501. Time: 1527.79\n",
      "<-- Epoch: 555. Average Train loss: 12.3516. Train Reconstruction loss: 3.2130. Train KLD loss: 9.1387. Time: 1529.22\n",
      "<-- Epoch: 555. Average Test loss: 62.1613. Test Reconstruction loss: 54.2754. Test KLD loss: 7.8858. Time: 1529.58\n",
      "<-- Epoch: 556. Average Train loss: 12.6062. Train Reconstruction loss: 3.4140. Train KLD loss: 9.1921. Time: 1531.06\n",
      "<-- Epoch: 556. Average Test loss: 62.7975. Test Reconstruction loss: 55.3237. Test KLD loss: 7.4738. Time: 1531.41\n",
      "<-- Epoch: 557. Average Train loss: 12.7437. Train Reconstruction loss: 3.3049. Train KLD loss: 9.4388. Time: 1532.82\n",
      "<-- Epoch: 557. Average Test loss: 61.7554. Test Reconstruction loss: 54.3894. Test KLD loss: 7.3659. Time: 1533.19\n",
      "<-- Epoch: 558. Average Train loss: 12.5208. Train Reconstruction loss: 3.3273. Train KLD loss: 9.1934. Time: 1534.75\n",
      "<-- Epoch: 558. Average Test loss: 62.4974. Test Reconstruction loss: 54.6920. Test KLD loss: 7.8054. Time: 1535.06\n",
      "<-- Epoch: 559. Average Train loss: 12.5814. Train Reconstruction loss: 3.2647. Train KLD loss: 9.3167. Time: 1536.42\n",
      "<-- Epoch: 559. Average Test loss: 62.7211. Test Reconstruction loss: 55.1333. Test KLD loss: 7.5878. Time: 1536.75\n",
      "<-- Epoch: 560. Average Train loss: 12.5710. Train Reconstruction loss: 3.3260. Train KLD loss: 9.2449. Time: 1538.26\n",
      "<-- Epoch: 560. Average Test loss: 62.1738. Test Reconstruction loss: 54.5695. Test KLD loss: 7.6043. Time: 1538.58\n",
      "<-- Epoch: 561. Average Train loss: 12.6518. Train Reconstruction loss: 3.3160. Train KLD loss: 9.3358. Time: 1540.01\n",
      "<-- Epoch: 561. Average Test loss: 62.6923. Test Reconstruction loss: 55.1397. Test KLD loss: 7.5527. Time: 1540.33\n",
      "<-- Epoch: 562. Average Train loss: 12.4381. Train Reconstruction loss: 3.3202. Train KLD loss: 9.1179. Time: 1541.77\n",
      "<-- Epoch: 562. Average Test loss: 61.8548. Test Reconstruction loss: 54.5402. Test KLD loss: 7.3146. Time: 1542.09\n",
      "<-- Epoch: 563. Average Train loss: 12.3212. Train Reconstruction loss: 3.2690. Train KLD loss: 9.0522. Time: 1543.50\n",
      "<-- Epoch: 563. Average Test loss: 61.7002. Test Reconstruction loss: 54.1142. Test KLD loss: 7.5860. Time: 1543.82\n",
      "<-- Epoch: 564. Average Train loss: 12.5346. Train Reconstruction loss: 3.3812. Train KLD loss: 9.1533. Time: 1545.38\n",
      "<-- Epoch: 564. Average Test loss: 62.3382. Test Reconstruction loss: 54.9309. Test KLD loss: 7.4073. Time: 1545.74\n",
      "<-- Epoch: 565. Average Train loss: 12.4406. Train Reconstruction loss: 3.2597. Train KLD loss: 9.1809. Time: 1547.18\n",
      "<-- Epoch: 565. Average Test loss: 62.5641. Test Reconstruction loss: 55.4204. Test KLD loss: 7.1438. Time: 1547.48\n",
      "<-- Epoch: 566. Average Train loss: 12.7229. Train Reconstruction loss: 3.5117. Train KLD loss: 9.2111. Time: 1548.86\n",
      "<-- Epoch: 566. Average Test loss: 62.7663. Test Reconstruction loss: 54.6702. Test KLD loss: 8.0962. Time: 1549.20\n",
      "<-- Epoch: 567. Average Train loss: 12.6414. Train Reconstruction loss: 3.3612. Train KLD loss: 9.2802. Time: 1550.72\n",
      "<-- Epoch: 567. Average Test loss: 63.1998. Test Reconstruction loss: 55.0842. Test KLD loss: 8.1156. Time: 1551.04\n",
      "<-- Epoch: 568. Average Train loss: 12.4681. Train Reconstruction loss: 3.2791. Train KLD loss: 9.1890. Time: 1552.52\n",
      "<-- Epoch: 568. Average Test loss: 62.4444. Test Reconstruction loss: 54.7509. Test KLD loss: 7.6935. Time: 1552.83\n",
      "<-- Epoch: 569. Average Train loss: 12.5796. Train Reconstruction loss: 3.3048. Train KLD loss: 9.2748. Time: 1554.37\n",
      "<-- Epoch: 569. Average Test loss: 62.7879. Test Reconstruction loss: 55.1047. Test KLD loss: 7.6832. Time: 1554.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 570. Average Train loss: 12.6334. Train Reconstruction loss: 3.3716. Train KLD loss: 9.2618. Time: 1556.02\n",
      "<-- Epoch: 570. Average Test loss: 62.6628. Test Reconstruction loss: 54.9843. Test KLD loss: 7.6785. Time: 1556.33\n",
      "<-- Epoch: 571. Average Train loss: 12.5934. Train Reconstruction loss: 3.2719. Train KLD loss: 9.3215. Time: 1557.73\n",
      "<-- Epoch: 571. Average Test loss: 63.0891. Test Reconstruction loss: 55.7754. Test KLD loss: 7.3137. Time: 1558.20\n",
      "<-- Epoch: 572. Average Train loss: 12.4073. Train Reconstruction loss: 3.2651. Train KLD loss: 9.1423. Time: 1559.75\n",
      "<-- Epoch: 572. Average Test loss: 61.8822. Test Reconstruction loss: 54.3669. Test KLD loss: 7.5153. Time: 1560.15\n",
      "<-- Epoch: 573. Average Train loss: 12.4794. Train Reconstruction loss: 3.2510. Train KLD loss: 9.2284. Time: 1561.68\n",
      "<-- Epoch: 573. Average Test loss: 63.4915. Test Reconstruction loss: 55.8857. Test KLD loss: 7.6058. Time: 1562.00\n",
      "<-- Epoch: 574. Average Train loss: 12.5445. Train Reconstruction loss: 3.2458. Train KLD loss: 9.2988. Time: 1563.48\n",
      "<-- Epoch: 574. Average Test loss: 62.8480. Test Reconstruction loss: 55.4625. Test KLD loss: 7.3855. Time: 1563.95\n",
      "<-- Epoch: 575. Average Train loss: 12.4664. Train Reconstruction loss: 3.2987. Train KLD loss: 9.1677. Time: 1565.60\n",
      "<-- Epoch: 575. Average Test loss: 62.8202. Test Reconstruction loss: 55.2564. Test KLD loss: 7.5638. Time: 1565.96\n",
      "<-- Epoch: 576. Average Train loss: 12.6821. Train Reconstruction loss: 3.4214. Train KLD loss: 9.2607. Time: 1567.58\n",
      "<-- Epoch: 576. Average Test loss: 62.1876. Test Reconstruction loss: 54.7915. Test KLD loss: 7.3961. Time: 1567.97\n",
      "<-- Epoch: 577. Average Train loss: 12.7131. Train Reconstruction loss: 3.3487. Train KLD loss: 9.3644. Time: 1569.75\n",
      "<-- Epoch: 577. Average Test loss: 62.6043. Test Reconstruction loss: 54.6618. Test KLD loss: 7.9425. Time: 1570.22\n",
      "<-- Epoch: 578. Average Train loss: 12.6229. Train Reconstruction loss: 3.2376. Train KLD loss: 9.3853. Time: 1571.82\n",
      "<-- Epoch: 578. Average Test loss: 63.1155. Test Reconstruction loss: 55.4484. Test KLD loss: 7.6671. Time: 1572.23\n",
      "<-- Epoch: 579. Average Train loss: 12.4359. Train Reconstruction loss: 3.3044. Train KLD loss: 9.1315. Time: 1573.87\n",
      "<-- Epoch: 579. Average Test loss: 63.0081. Test Reconstruction loss: 54.6362. Test KLD loss: 8.3719. Time: 1574.47\n",
      "<-- Epoch: 580. Average Train loss: 12.4090. Train Reconstruction loss: 3.1176. Train KLD loss: 9.2914. Time: 1576.61\n",
      "<-- Epoch: 580. Average Test loss: 63.2246. Test Reconstruction loss: 56.0950. Test KLD loss: 7.1295. Time: 1577.10\n",
      "<-- Epoch: 581. Average Train loss: 12.4451. Train Reconstruction loss: 3.3380. Train KLD loss: 9.1071. Time: 1579.24\n",
      "<-- Epoch: 581. Average Test loss: 63.3050. Test Reconstruction loss: 55.3075. Test KLD loss: 7.9975. Time: 1579.80\n",
      "<-- Epoch: 582. Average Train loss: 12.5086. Train Reconstruction loss: 3.1732. Train KLD loss: 9.3354. Time: 1581.73\n",
      "<-- Epoch: 582. Average Test loss: 62.3256. Test Reconstruction loss: 54.8614. Test KLD loss: 7.4642. Time: 1582.08\n",
      "<-- Epoch: 583. Average Train loss: 12.3555. Train Reconstruction loss: 3.2187. Train KLD loss: 9.1369. Time: 1583.68\n",
      "<-- Epoch: 583. Average Test loss: 63.0398. Test Reconstruction loss: 55.4720. Test KLD loss: 7.5679. Time: 1584.06\n",
      "<-- Epoch: 584. Average Train loss: 12.4312. Train Reconstruction loss: 3.1588. Train KLD loss: 9.2724. Time: 1585.54\n",
      "<-- Epoch: 584. Average Test loss: 63.0165. Test Reconstruction loss: 55.7638. Test KLD loss: 7.2526. Time: 1585.91\n",
      "<-- Epoch: 585. Average Train loss: 12.6592. Train Reconstruction loss: 3.2748. Train KLD loss: 9.3844. Time: 1587.62\n",
      "<-- Epoch: 585. Average Test loss: 62.9745. Test Reconstruction loss: 55.3793. Test KLD loss: 7.5952. Time: 1587.99\n",
      "<-- Epoch: 586. Average Train loss: 12.7563. Train Reconstruction loss: 3.3484. Train KLD loss: 9.4079. Time: 1589.56\n",
      "<-- Epoch: 586. Average Test loss: 62.6118. Test Reconstruction loss: 54.7336. Test KLD loss: 7.8781. Time: 1589.91\n",
      "<-- Epoch: 587. Average Train loss: 12.4828. Train Reconstruction loss: 3.2734. Train KLD loss: 9.2095. Time: 1591.40\n",
      "<-- Epoch: 587. Average Test loss: 61.9379. Test Reconstruction loss: 53.8157. Test KLD loss: 8.1222. Time: 1591.76\n",
      "<-- Epoch: 588. Average Train loss: 12.5761. Train Reconstruction loss: 3.1930. Train KLD loss: 9.3830. Time: 1593.35\n",
      "<-- Epoch: 588. Average Test loss: 63.3083. Test Reconstruction loss: 56.1572. Test KLD loss: 7.1511. Time: 1593.70\n",
      "<-- Epoch: 589. Average Train loss: 12.5225. Train Reconstruction loss: 3.2206. Train KLD loss: 9.3019. Time: 1595.32\n",
      "<-- Epoch: 589. Average Test loss: 62.8798. Test Reconstruction loss: 54.9597. Test KLD loss: 7.9202. Time: 1595.67\n",
      "<-- Epoch: 590. Average Train loss: 12.6902. Train Reconstruction loss: 3.2496. Train KLD loss: 9.4406. Time: 1597.26\n",
      "<-- Epoch: 590. Average Test loss: 62.3201. Test Reconstruction loss: 54.8420. Test KLD loss: 7.4781. Time: 1597.63\n",
      "<-- Epoch: 591. Average Train loss: 12.5131. Train Reconstruction loss: 3.2433. Train KLD loss: 9.2699. Time: 1599.09\n",
      "<-- Epoch: 591. Average Test loss: 64.3457. Test Reconstruction loss: 56.8224. Test KLD loss: 7.5233. Time: 1599.47\n",
      "<-- Epoch: 592. Average Train loss: 12.5415. Train Reconstruction loss: 3.3063. Train KLD loss: 9.2352. Time: 1601.18\n",
      "<-- Epoch: 592. Average Test loss: 63.7568. Test Reconstruction loss: 56.3632. Test KLD loss: 7.3936. Time: 1601.53\n",
      "<-- Epoch: 593. Average Train loss: 12.5802. Train Reconstruction loss: 3.2200. Train KLD loss: 9.3602. Time: 1603.06\n",
      "<-- Epoch: 593. Average Test loss: 62.7796. Test Reconstruction loss: 55.2898. Test KLD loss: 7.4898. Time: 1603.42\n",
      "<-- Epoch: 594. Average Train loss: 12.3576. Train Reconstruction loss: 3.2415. Train KLD loss: 9.1161. Time: 1604.98\n",
      "<-- Epoch: 594. Average Test loss: 63.4795. Test Reconstruction loss: 56.2270. Test KLD loss: 7.2525. Time: 1605.34\n",
      "<-- Epoch: 595. Average Train loss: 12.3924. Train Reconstruction loss: 3.2527. Train KLD loss: 9.1398. Time: 1606.83\n",
      "<-- Epoch: 595. Average Test loss: 63.3548. Test Reconstruction loss: 55.5989. Test KLD loss: 7.7559. Time: 1607.19\n",
      "<-- Epoch: 596. Average Train loss: 12.4350. Train Reconstruction loss: 3.2090. Train KLD loss: 9.2260. Time: 1608.72\n",
      "<-- Epoch: 596. Average Test loss: 62.9800. Test Reconstruction loss: 55.1538. Test KLD loss: 7.8263. Time: 1609.07\n",
      "<-- Epoch: 597. Average Train loss: 12.3753. Train Reconstruction loss: 3.1755. Train KLD loss: 9.1998. Time: 1610.58\n",
      "<-- Epoch: 597. Average Test loss: 63.1209. Test Reconstruction loss: 55.6640. Test KLD loss: 7.4568. Time: 1610.93\n",
      "<-- Epoch: 598. Average Train loss: 12.3765. Train Reconstruction loss: 3.1617. Train KLD loss: 9.2148. Time: 1612.50\n",
      "<-- Epoch: 598. Average Test loss: 63.0945. Test Reconstruction loss: 55.7945. Test KLD loss: 7.3000. Time: 1612.86\n",
      "<-- Epoch: 599. Average Train loss: 12.3398. Train Reconstruction loss: 3.2002. Train KLD loss: 9.1396. Time: 1614.43\n",
      "<-- Epoch: 599. Average Test loss: 62.5920. Test Reconstruction loss: 54.7681. Test KLD loss: 7.8240. Time: 1614.78\n",
      "<-- Epoch: 600. Average Train loss: 12.5287. Train Reconstruction loss: 3.2278. Train KLD loss: 9.3008. Time: 1616.43\n",
      "<-- Epoch: 600. Average Test loss: 63.0163. Test Reconstruction loss: 55.2176. Test KLD loss: 7.7986. Time: 1616.78\n",
      "<-- Epoch: 601. Average Train loss: 12.6529. Train Reconstruction loss: 3.2709. Train KLD loss: 9.3821. Time: 1618.38\n",
      "<-- Epoch: 601. Average Test loss: 63.5419. Test Reconstruction loss: 55.6610. Test KLD loss: 7.8808. Time: 1618.72\n",
      "<-- Epoch: 602. Average Train loss: 12.5957. Train Reconstruction loss: 3.1447. Train KLD loss: 9.4510. Time: 1620.26\n",
      "<-- Epoch: 602. Average Test loss: 63.7837. Test Reconstruction loss: 56.6694. Test KLD loss: 7.1143. Time: 1620.60\n",
      "<-- Epoch: 603. Average Train loss: 12.3706. Train Reconstruction loss: 3.1820. Train KLD loss: 9.1886. Time: 1622.10\n",
      "<-- Epoch: 603. Average Test loss: 62.7810. Test Reconstruction loss: 55.1123. Test KLD loss: 7.6687. Time: 1622.46\n",
      "<-- Epoch: 604. Average Train loss: 12.5544. Train Reconstruction loss: 3.1956. Train KLD loss: 9.3588. Time: 1623.98\n",
      "<-- Epoch: 604. Average Test loss: 62.6849. Test Reconstruction loss: 55.1923. Test KLD loss: 7.4926. Time: 1624.35\n",
      "<-- Epoch: 605. Average Train loss: 12.5451. Train Reconstruction loss: 3.2165. Train KLD loss: 9.3286. Time: 1625.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 605. Average Test loss: 62.9219. Test Reconstruction loss: 55.2559. Test KLD loss: 7.6659. Time: 1626.21\n",
      "<-- Epoch: 606. Average Train loss: 12.2992. Train Reconstruction loss: 3.0517. Train KLD loss: 9.2475. Time: 1627.72\n",
      "<-- Epoch: 606. Average Test loss: 64.4126. Test Reconstruction loss: 56.9672. Test KLD loss: 7.4454. Time: 1628.10\n",
      "<-- Epoch: 607. Average Train loss: 12.3665. Train Reconstruction loss: 3.1961. Train KLD loss: 9.1704. Time: 1629.62\n",
      "<-- Epoch: 607. Average Test loss: 63.7765. Test Reconstruction loss: 56.0609. Test KLD loss: 7.7157. Time: 1629.96\n",
      "<-- Epoch: 608. Average Train loss: 12.4123. Train Reconstruction loss: 3.1790. Train KLD loss: 9.2333. Time: 1631.57\n",
      "<-- Epoch: 608. Average Test loss: 64.0475. Test Reconstruction loss: 56.3827. Test KLD loss: 7.6648. Time: 1631.92\n",
      "<-- Epoch: 609. Average Train loss: 12.4916. Train Reconstruction loss: 3.2149. Train KLD loss: 9.2767. Time: 1633.49\n",
      "<-- Epoch: 609. Average Test loss: 63.5639. Test Reconstruction loss: 55.5761. Test KLD loss: 7.9878. Time: 1633.83\n",
      "<-- Epoch: 610. Average Train loss: 12.3132. Train Reconstruction loss: 3.1169. Train KLD loss: 9.1963. Time: 1635.36\n",
      "<-- Epoch: 610. Average Test loss: 63.5103. Test Reconstruction loss: 56.2894. Test KLD loss: 7.2209. Time: 1635.70\n",
      "<-- Epoch: 611. Average Train loss: 12.5873. Train Reconstruction loss: 3.2990. Train KLD loss: 9.2883. Time: 1637.29\n",
      "<-- Epoch: 611. Average Test loss: 63.0645. Test Reconstruction loss: 55.3003. Test KLD loss: 7.7642. Time: 1637.67\n",
      "<-- Epoch: 612. Average Train loss: 12.4734. Train Reconstruction loss: 3.1532. Train KLD loss: 9.3203. Time: 1639.21\n",
      "<-- Epoch: 612. Average Test loss: 63.8669. Test Reconstruction loss: 56.0796. Test KLD loss: 7.7873. Time: 1639.56\n",
      "<-- Epoch: 613. Average Train loss: 12.3045. Train Reconstruction loss: 3.1880. Train KLD loss: 9.1165. Time: 1641.13\n",
      "<-- Epoch: 613. Average Test loss: 63.4892. Test Reconstruction loss: 56.2833. Test KLD loss: 7.2058. Time: 1641.49\n",
      "<-- Epoch: 614. Average Train loss: 12.5003. Train Reconstruction loss: 3.3040. Train KLD loss: 9.1963. Time: 1643.07\n",
      "<-- Epoch: 614. Average Test loss: 63.1890. Test Reconstruction loss: 55.5115. Test KLD loss: 7.6775. Time: 1643.49\n",
      "<-- Epoch: 615. Average Train loss: 12.3919. Train Reconstruction loss: 3.1170. Train KLD loss: 9.2749. Time: 1645.05\n",
      "<-- Epoch: 615. Average Test loss: 64.8165. Test Reconstruction loss: 57.1882. Test KLD loss: 7.6283. Time: 1645.43\n",
      "<-- Epoch: 616. Average Train loss: 12.3697. Train Reconstruction loss: 3.1588. Train KLD loss: 9.2109. Time: 1646.95\n",
      "<-- Epoch: 616. Average Test loss: 64.2481. Test Reconstruction loss: 56.9954. Test KLD loss: 7.2527. Time: 1647.32\n",
      "<-- Epoch: 617. Average Train loss: 12.6234. Train Reconstruction loss: 3.2910. Train KLD loss: 9.3324. Time: 1648.92\n",
      "<-- Epoch: 617. Average Test loss: 63.6370. Test Reconstruction loss: 55.9684. Test KLD loss: 7.6686. Time: 1649.29\n",
      "<-- Epoch: 618. Average Train loss: 12.3818. Train Reconstruction loss: 3.2158. Train KLD loss: 9.1660. Time: 1650.87\n",
      "<-- Epoch: 618. Average Test loss: 63.5941. Test Reconstruction loss: 56.1204. Test KLD loss: 7.4736. Time: 1651.22\n",
      "<-- Epoch: 619. Average Train loss: 12.6753. Train Reconstruction loss: 3.2403. Train KLD loss: 9.4350. Time: 1652.78\n",
      "<-- Epoch: 619. Average Test loss: 64.5187. Test Reconstruction loss: 56.5807. Test KLD loss: 7.9380. Time: 1653.13\n",
      "<-- Epoch: 620. Average Train loss: 12.5235. Train Reconstruction loss: 3.0895. Train KLD loss: 9.4341. Time: 1654.64\n",
      "<-- Epoch: 620. Average Test loss: 64.1490. Test Reconstruction loss: 56.4066. Test KLD loss: 7.7424. Time: 1654.97\n",
      "<-- Epoch: 621. Average Train loss: 12.3487. Train Reconstruction loss: 3.1467. Train KLD loss: 9.2020. Time: 1656.53\n",
      "<-- Epoch: 621. Average Test loss: 64.0261. Test Reconstruction loss: 56.7459. Test KLD loss: 7.2802. Time: 1656.89\n",
      "<-- Epoch: 622. Average Train loss: 12.4496. Train Reconstruction loss: 3.1978. Train KLD loss: 9.2518. Time: 1658.41\n",
      "<-- Epoch: 622. Average Test loss: 63.2065. Test Reconstruction loss: 55.4107. Test KLD loss: 7.7958. Time: 1658.76\n",
      "<-- Epoch: 623. Average Train loss: 12.4044. Train Reconstruction loss: 3.0778. Train KLD loss: 9.3266. Time: 1660.32\n",
      "<-- Epoch: 623. Average Test loss: 63.4290. Test Reconstruction loss: 56.1446. Test KLD loss: 7.2844. Time: 1660.67\n",
      "<-- Epoch: 624. Average Train loss: 12.2793. Train Reconstruction loss: 3.1447. Train KLD loss: 9.1346. Time: 1662.20\n",
      "<-- Epoch: 624. Average Test loss: 63.2840. Test Reconstruction loss: 55.5131. Test KLD loss: 7.7709. Time: 1662.54\n",
      "<-- Epoch: 625. Average Train loss: 12.5919. Train Reconstruction loss: 3.2756. Train KLD loss: 9.3163. Time: 1664.06\n",
      "<-- Epoch: 625. Average Test loss: 64.5126. Test Reconstruction loss: 56.3793. Test KLD loss: 8.1333. Time: 1664.42\n",
      "<-- Epoch: 626. Average Train loss: 12.5425. Train Reconstruction loss: 3.1626. Train KLD loss: 9.3800. Time: 1665.92\n",
      "<-- Epoch: 626. Average Test loss: 64.1004. Test Reconstruction loss: 56.0804. Test KLD loss: 8.0200. Time: 1666.29\n",
      "<-- Epoch: 627. Average Train loss: 12.2984. Train Reconstruction loss: 3.0848. Train KLD loss: 9.2135. Time: 1667.78\n",
      "<-- Epoch: 627. Average Test loss: 63.9967. Test Reconstruction loss: 56.4851. Test KLD loss: 7.5116. Time: 1668.16\n",
      "<-- Epoch: 628. Average Train loss: 12.6743. Train Reconstruction loss: 3.3169. Train KLD loss: 9.3574. Time: 1669.79\n",
      "<-- Epoch: 628. Average Test loss: 63.8675. Test Reconstruction loss: 55.6791. Test KLD loss: 8.1884. Time: 1670.15\n",
      "<-- Epoch: 629. Average Train loss: 12.1315. Train Reconstruction loss: 2.9502. Train KLD loss: 9.1814. Time: 1671.65\n",
      "<-- Epoch: 629. Average Test loss: 64.1398. Test Reconstruction loss: 56.8908. Test KLD loss: 7.2490. Time: 1672.00\n",
      "<-- Epoch: 630. Average Train loss: 12.4934. Train Reconstruction loss: 3.2901. Train KLD loss: 9.2033. Time: 1673.57\n",
      "<-- Epoch: 630. Average Test loss: 64.0035. Test Reconstruction loss: 56.7099. Test KLD loss: 7.2935. Time: 1673.94\n",
      "<-- Epoch: 631. Average Train loss: 12.4551. Train Reconstruction loss: 3.1335. Train KLD loss: 9.3216. Time: 1675.46\n",
      "<-- Epoch: 631. Average Test loss: 63.8535. Test Reconstruction loss: 56.1532. Test KLD loss: 7.7003. Time: 1675.82\n",
      "<-- Epoch: 632. Average Train loss: 12.2933. Train Reconstruction loss: 3.1362. Train KLD loss: 9.1572. Time: 1677.39\n",
      "<-- Epoch: 632. Average Test loss: 65.1687. Test Reconstruction loss: 57.4603. Test KLD loss: 7.7084. Time: 1677.73\n",
      "<-- Epoch: 633. Average Train loss: 12.2777. Train Reconstruction loss: 3.1295. Train KLD loss: 9.1482. Time: 1679.26\n",
      "<-- Epoch: 633. Average Test loss: 65.0472. Test Reconstruction loss: 57.6365. Test KLD loss: 7.4107. Time: 1679.61\n",
      "<-- Epoch: 634. Average Train loss: 12.3032. Train Reconstruction loss: 3.0466. Train KLD loss: 9.2566. Time: 1681.16\n",
      "<-- Epoch: 634. Average Test loss: 63.8480. Test Reconstruction loss: 56.4505. Test KLD loss: 7.3975. Time: 1681.50\n",
      "<-- Epoch: 635. Average Train loss: 12.3125. Train Reconstruction loss: 3.0487. Train KLD loss: 9.2638. Time: 1683.00\n",
      "<-- Epoch: 635. Average Test loss: 63.7582. Test Reconstruction loss: 56.3580. Test KLD loss: 7.4002. Time: 1683.38\n",
      "<-- Epoch: 636. Average Train loss: 12.2969. Train Reconstruction loss: 3.1253. Train KLD loss: 9.1716. Time: 1684.93\n",
      "<-- Epoch: 636. Average Test loss: 64.0718. Test Reconstruction loss: 56.5830. Test KLD loss: 7.4887. Time: 1685.29\n",
      "<-- Epoch: 637. Average Train loss: 12.2901. Train Reconstruction loss: 2.9701. Train KLD loss: 9.3199. Time: 1686.80\n",
      "<-- Epoch: 637. Average Test loss: 64.4937. Test Reconstruction loss: 57.2373. Test KLD loss: 7.2563. Time: 1687.16\n",
      "<-- Epoch: 638. Average Train loss: 12.3060. Train Reconstruction loss: 3.1086. Train KLD loss: 9.1975. Time: 1688.71\n",
      "<-- Epoch: 638. Average Test loss: 64.1366. Test Reconstruction loss: 56.6700. Test KLD loss: 7.4666. Time: 1689.05\n",
      "<-- Epoch: 639. Average Train loss: 12.4745. Train Reconstruction loss: 3.1800. Train KLD loss: 9.2945. Time: 1690.68\n",
      "<-- Epoch: 639. Average Test loss: 63.8404. Test Reconstruction loss: 55.9542. Test KLD loss: 7.8862. Time: 1691.03\n",
      "<-- Epoch: 640. Average Train loss: 12.3944. Train Reconstruction loss: 3.1158. Train KLD loss: 9.2787. Time: 1692.63\n",
      "<-- Epoch: 640. Average Test loss: 64.6358. Test Reconstruction loss: 57.0834. Test KLD loss: 7.5524. Time: 1693.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 641. Average Train loss: 12.2720. Train Reconstruction loss: 3.1256. Train KLD loss: 9.1464. Time: 1694.55\n",
      "<-- Epoch: 641. Average Test loss: 64.5966. Test Reconstruction loss: 56.9633. Test KLD loss: 7.6333. Time: 1694.89\n",
      "<-- Epoch: 642. Average Train loss: 12.6165. Train Reconstruction loss: 3.1506. Train KLD loss: 9.4660. Time: 1696.47\n",
      "<-- Epoch: 642. Average Test loss: 64.5276. Test Reconstruction loss: 57.2232. Test KLD loss: 7.3044. Time: 1696.82\n",
      "<-- Epoch: 643. Average Train loss: 12.3909. Train Reconstruction loss: 3.0988. Train KLD loss: 9.2921. Time: 1698.37\n",
      "<-- Epoch: 643. Average Test loss: 63.7450. Test Reconstruction loss: 55.9280. Test KLD loss: 7.8171. Time: 1698.72\n",
      "<-- Epoch: 644. Average Train loss: 12.1969. Train Reconstruction loss: 2.9413. Train KLD loss: 9.2556. Time: 1700.40\n",
      "<-- Epoch: 644. Average Test loss: 64.5206. Test Reconstruction loss: 57.1726. Test KLD loss: 7.3480. Time: 1700.74\n",
      "<-- Epoch: 645. Average Train loss: 12.3622. Train Reconstruction loss: 3.2042. Train KLD loss: 9.1580. Time: 1702.29\n",
      "<-- Epoch: 645. Average Test loss: 64.3704. Test Reconstruction loss: 56.8995. Test KLD loss: 7.4708. Time: 1702.64\n",
      "<-- Epoch: 646. Average Train loss: 12.5502. Train Reconstruction loss: 3.2531. Train KLD loss: 9.2971. Time: 1704.25\n",
      "<-- Epoch: 646. Average Test loss: 64.8271. Test Reconstruction loss: 56.7936. Test KLD loss: 8.0335. Time: 1704.60\n",
      "<-- Epoch: 647. Average Train loss: 12.2352. Train Reconstruction loss: 3.0167. Train KLD loss: 9.2185. Time: 1706.19\n",
      "<-- Epoch: 647. Average Test loss: 65.1922. Test Reconstruction loss: 58.0070. Test KLD loss: 7.1852. Time: 1706.54\n",
      "<-- Epoch: 648. Average Train loss: 12.3254. Train Reconstruction loss: 3.0842. Train KLD loss: 9.2412. Time: 1708.14\n",
      "<-- Epoch: 648. Average Test loss: 65.2639. Test Reconstruction loss: 57.8216. Test KLD loss: 7.4422. Time: 1708.49\n",
      "<-- Epoch: 649. Average Train loss: 12.2106. Train Reconstruction loss: 3.0030. Train KLD loss: 9.2076. Time: 1710.13\n",
      "<-- Epoch: 649. Average Test loss: 64.5613. Test Reconstruction loss: 56.6696. Test KLD loss: 7.8916. Time: 1710.65\n",
      "<-- Epoch: 650. Average Train loss: 12.4123. Train Reconstruction loss: 3.0644. Train KLD loss: 9.3479. Time: 1712.35\n",
      "<-- Epoch: 650. Average Test loss: 64.4996. Test Reconstruction loss: 56.8977. Test KLD loss: 7.6019. Time: 1712.64\n",
      "<-- Epoch: 651. Average Train loss: 12.1623. Train Reconstruction loss: 3.0147. Train KLD loss: 9.1475. Time: 1714.04\n",
      "<-- Epoch: 651. Average Test loss: 65.0411. Test Reconstruction loss: 57.2449. Test KLD loss: 7.7962. Time: 1714.50\n",
      "<-- Epoch: 652. Average Train loss: 12.4073. Train Reconstruction loss: 3.0727. Train KLD loss: 9.3346. Time: 1716.71\n",
      "<-- Epoch: 652. Average Test loss: 65.2507. Test Reconstruction loss: 56.9009. Test KLD loss: 8.3498. Time: 1717.27\n",
      "<-- Epoch: 653. Average Train loss: 12.3754. Train Reconstruction loss: 3.1176. Train KLD loss: 9.2579. Time: 1718.90\n",
      "<-- Epoch: 653. Average Test loss: 64.6926. Test Reconstruction loss: 56.9460. Test KLD loss: 7.7466. Time: 1719.23\n",
      "<-- Epoch: 654. Average Train loss: 12.3507. Train Reconstruction loss: 3.0056. Train KLD loss: 9.3451. Time: 1720.60\n",
      "<-- Epoch: 654. Average Test loss: 64.4468. Test Reconstruction loss: 56.7053. Test KLD loss: 7.7416. Time: 1720.94\n",
      "<-- Epoch: 655. Average Train loss: 12.3284. Train Reconstruction loss: 3.0903. Train KLD loss: 9.2381. Time: 1722.35\n",
      "<-- Epoch: 655. Average Test loss: 63.3063. Test Reconstruction loss: 55.4882. Test KLD loss: 7.8181. Time: 1722.67\n",
      "<-- Epoch: 656. Average Train loss: 12.2749. Train Reconstruction loss: 3.1293. Train KLD loss: 9.1456. Time: 1724.18\n",
      "<-- Epoch: 656. Average Test loss: 65.3671. Test Reconstruction loss: 57.7760. Test KLD loss: 7.5912. Time: 1724.49\n",
      "<-- Epoch: 657. Average Train loss: 12.3098. Train Reconstruction loss: 3.0491. Train KLD loss: 9.2608. Time: 1726.48\n",
      "<-- Epoch: 657. Average Test loss: 64.5307. Test Reconstruction loss: 57.1403. Test KLD loss: 7.3904. Time: 1727.06\n",
      "<-- Epoch: 658. Average Train loss: 12.4349. Train Reconstruction loss: 3.1005. Train KLD loss: 9.3344. Time: 1729.05\n",
      "<-- Epoch: 658. Average Test loss: 64.0701. Test Reconstruction loss: 56.1991. Test KLD loss: 7.8710. Time: 1729.40\n",
      "<-- Epoch: 659. Average Train loss: 12.4879. Train Reconstruction loss: 3.1024. Train KLD loss: 9.3854. Time: 1730.87\n",
      "<-- Epoch: 659. Average Test loss: 65.7723. Test Reconstruction loss: 58.1525. Test KLD loss: 7.6198. Time: 1731.23\n",
      "<-- Epoch: 660. Average Train loss: 12.3204. Train Reconstruction loss: 3.1592. Train KLD loss: 9.1612. Time: 1732.69\n",
      "<-- Epoch: 660. Average Test loss: 64.7756. Test Reconstruction loss: 56.9274. Test KLD loss: 7.8482. Time: 1733.03\n",
      "<-- Epoch: 661. Average Train loss: 12.2814. Train Reconstruction loss: 3.0169. Train KLD loss: 9.2644. Time: 1734.57\n",
      "<-- Epoch: 661. Average Test loss: 64.8885. Test Reconstruction loss: 56.9694. Test KLD loss: 7.9191. Time: 1734.89\n",
      "<-- Epoch: 662. Average Train loss: 12.2738. Train Reconstruction loss: 3.0439. Train KLD loss: 9.2298. Time: 1736.32\n",
      "<-- Epoch: 662. Average Test loss: 65.1445. Test Reconstruction loss: 57.5444. Test KLD loss: 7.6001. Time: 1736.62\n",
      "<-- Epoch: 663. Average Train loss: 12.4964. Train Reconstruction loss: 3.1586. Train KLD loss: 9.3378. Time: 1737.97\n",
      "<-- Epoch: 663. Average Test loss: 64.6297. Test Reconstruction loss: 56.6325. Test KLD loss: 7.9972. Time: 1738.28\n",
      "<-- Epoch: 664. Average Train loss: 12.4039. Train Reconstruction loss: 3.0690. Train KLD loss: 9.3349. Time: 1739.62\n",
      "<-- Epoch: 664. Average Test loss: 65.3592. Test Reconstruction loss: 57.7102. Test KLD loss: 7.6490. Time: 1739.92\n",
      "<-- Epoch: 665. Average Train loss: 12.1459. Train Reconstruction loss: 3.0776. Train KLD loss: 9.0684. Time: 1741.27\n",
      "<-- Epoch: 665. Average Test loss: 64.3833. Test Reconstruction loss: 56.8180. Test KLD loss: 7.5654. Time: 1741.56\n",
      "<-- Epoch: 666. Average Train loss: 12.4306. Train Reconstruction loss: 3.1388. Train KLD loss: 9.2918. Time: 1743.01\n",
      "<-- Epoch: 666. Average Test loss: 64.9737. Test Reconstruction loss: 57.5482. Test KLD loss: 7.4255. Time: 1743.43\n",
      "<-- Epoch: 667. Average Train loss: 12.4479. Train Reconstruction loss: 3.0308. Train KLD loss: 9.4171. Time: 1744.86\n",
      "<-- Epoch: 667. Average Test loss: 65.0528. Test Reconstruction loss: 57.6537. Test KLD loss: 7.3991. Time: 1745.22\n",
      "<-- Epoch: 668. Average Train loss: 12.5093. Train Reconstruction loss: 3.1116. Train KLD loss: 9.3977. Time: 1746.60\n",
      "<-- Epoch: 668. Average Test loss: 63.9531. Test Reconstruction loss: 56.4735. Test KLD loss: 7.4796. Time: 1746.91\n",
      "<-- Epoch: 669. Average Train loss: 12.3127. Train Reconstruction loss: 3.0313. Train KLD loss: 9.2814. Time: 1748.42\n",
      "<-- Epoch: 669. Average Test loss: 65.3202. Test Reconstruction loss: 58.0636. Test KLD loss: 7.2566. Time: 1748.72\n",
      "<-- Epoch: 670. Average Train loss: 12.4770. Train Reconstruction loss: 3.0628. Train KLD loss: 9.4142. Time: 1750.11\n",
      "<-- Epoch: 670. Average Test loss: 64.2376. Test Reconstruction loss: 56.4807. Test KLD loss: 7.7569. Time: 1750.44\n",
      "<-- Epoch: 671. Average Train loss: 12.3411. Train Reconstruction loss: 3.0429. Train KLD loss: 9.2982. Time: 1751.83\n",
      "<-- Epoch: 671. Average Test loss: 65.3998. Test Reconstruction loss: 57.8205. Test KLD loss: 7.5793. Time: 1752.14\n",
      "<-- Epoch: 672. Average Train loss: 12.3557. Train Reconstruction loss: 3.0880. Train KLD loss: 9.2677. Time: 1753.54\n",
      "<-- Epoch: 672. Average Test loss: 65.7343. Test Reconstruction loss: 57.9793. Test KLD loss: 7.7549. Time: 1753.84\n",
      "<-- Epoch: 673. Average Train loss: 12.2051. Train Reconstruction loss: 3.0677. Train KLD loss: 9.1373. Time: 1755.32\n",
      "<-- Epoch: 673. Average Test loss: 64.5015. Test Reconstruction loss: 56.5352. Test KLD loss: 7.9663. Time: 1755.65\n",
      "<-- Epoch: 674. Average Train loss: 12.6009. Train Reconstruction loss: 3.1407. Train KLD loss: 9.4602. Time: 1757.10\n",
      "<-- Epoch: 674. Average Test loss: 64.8352. Test Reconstruction loss: 57.5383. Test KLD loss: 7.2968. Time: 1757.47\n",
      "<-- Epoch: 675. Average Train loss: 12.4314. Train Reconstruction loss: 3.1574. Train KLD loss: 9.2740. Time: 1758.93\n",
      "<-- Epoch: 675. Average Test loss: 64.7670. Test Reconstruction loss: 56.9693. Test KLD loss: 7.7976. Time: 1759.28\n",
      "<-- Epoch: 676. Average Train loss: 12.2686. Train Reconstruction loss: 3.0560. Train KLD loss: 9.2126. Time: 1760.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 676. Average Test loss: 65.1941. Test Reconstruction loss: 57.5307. Test KLD loss: 7.6634. Time: 1761.19\n",
      "<-- Epoch: 677. Average Train loss: 12.5517. Train Reconstruction loss: 3.0994. Train KLD loss: 9.4523. Time: 1762.71\n",
      "<-- Epoch: 677. Average Test loss: 65.2230. Test Reconstruction loss: 57.8388. Test KLD loss: 7.3841. Time: 1763.01\n",
      "<-- Epoch: 678. Average Train loss: 12.3122. Train Reconstruction loss: 3.1301. Train KLD loss: 9.1821. Time: 1764.62\n",
      "<-- Epoch: 678. Average Test loss: 65.6571. Test Reconstruction loss: 58.0178. Test KLD loss: 7.6393. Time: 1764.94\n",
      "<-- Epoch: 679. Average Train loss: 12.1330. Train Reconstruction loss: 2.8571. Train KLD loss: 9.2759. Time: 1766.48\n",
      "<-- Epoch: 679. Average Test loss: 64.4690. Test Reconstruction loss: 57.3932. Test KLD loss: 7.0758. Time: 1766.87\n",
      "<-- Epoch: 680. Average Train loss: 12.1975. Train Reconstruction loss: 2.9991. Train KLD loss: 9.1983. Time: 1768.86\n",
      "<-- Epoch: 680. Average Test loss: 64.4706. Test Reconstruction loss: 56.5237. Test KLD loss: 7.9469. Time: 1769.15\n",
      "<-- Epoch: 681. Average Train loss: 12.4392. Train Reconstruction loss: 3.0799. Train KLD loss: 9.3593. Time: 1771.02\n",
      "<-- Epoch: 681. Average Test loss: 65.6072. Test Reconstruction loss: 57.6249. Test KLD loss: 7.9823. Time: 1771.72\n",
      "<-- Epoch: 682. Average Train loss: 12.3177. Train Reconstruction loss: 3.0393. Train KLD loss: 9.2783. Time: 1773.24\n",
      "<-- Epoch: 682. Average Test loss: 65.9085. Test Reconstruction loss: 58.3731. Test KLD loss: 7.5353. Time: 1773.59\n",
      "<-- Epoch: 683. Average Train loss: 12.2958. Train Reconstruction loss: 2.9866. Train KLD loss: 9.3092. Time: 1775.17\n",
      "<-- Epoch: 683. Average Test loss: 65.9129. Test Reconstruction loss: 58.3547. Test KLD loss: 7.5581. Time: 1775.53\n",
      "<-- Epoch: 684. Average Train loss: 12.3608. Train Reconstruction loss: 3.2228. Train KLD loss: 9.1380. Time: 1777.03\n",
      "<-- Epoch: 684. Average Test loss: 65.8963. Test Reconstruction loss: 58.2955. Test KLD loss: 7.6009. Time: 1777.37\n",
      "<-- Epoch: 685. Average Train loss: 12.2509. Train Reconstruction loss: 3.0010. Train KLD loss: 9.2499. Time: 1778.87\n",
      "<-- Epoch: 685. Average Test loss: 64.9531. Test Reconstruction loss: 56.7232. Test KLD loss: 8.2299. Time: 1779.18\n",
      "<-- Epoch: 686. Average Train loss: 12.2547. Train Reconstruction loss: 3.0619. Train KLD loss: 9.1928. Time: 1780.68\n",
      "<-- Epoch: 686. Average Test loss: 64.2394. Test Reconstruction loss: 56.6903. Test KLD loss: 7.5491. Time: 1781.08\n",
      "<-- Epoch: 687. Average Train loss: 12.3211. Train Reconstruction loss: 2.9948. Train KLD loss: 9.3263. Time: 1782.48\n",
      "<-- Epoch: 687. Average Test loss: 65.3129. Test Reconstruction loss: 57.7484. Test KLD loss: 7.5645. Time: 1782.83\n",
      "<-- Epoch: 688. Average Train loss: 12.3656. Train Reconstruction loss: 3.0493. Train KLD loss: 9.3163. Time: 1784.20\n",
      "<-- Epoch: 688. Average Test loss: 65.3999. Test Reconstruction loss: 57.7177. Test KLD loss: 7.6822. Time: 1784.49\n",
      "<-- Epoch: 689. Average Train loss: 12.0833. Train Reconstruction loss: 2.9346. Train KLD loss: 9.1486. Time: 1785.96\n",
      "<-- Epoch: 689. Average Test loss: 65.3019. Test Reconstruction loss: 57.7010. Test KLD loss: 7.6009. Time: 1786.27\n",
      "<-- Epoch: 690. Average Train loss: 12.2776. Train Reconstruction loss: 3.0803. Train KLD loss: 9.1973. Time: 1787.90\n",
      "<-- Epoch: 690. Average Test loss: 65.5438. Test Reconstruction loss: 57.7608. Test KLD loss: 7.7830. Time: 1788.73\n",
      "<-- Epoch: 691. Average Train loss: 12.5387. Train Reconstruction loss: 3.1019. Train KLD loss: 9.4368. Time: 1791.44\n",
      "<-- Epoch: 691. Average Test loss: 65.8539. Test Reconstruction loss: 57.6973. Test KLD loss: 8.1566. Time: 1792.13\n",
      "<-- Epoch: 692. Average Train loss: 12.2252. Train Reconstruction loss: 2.9327. Train KLD loss: 9.2925. Time: 1794.84\n",
      "<-- Epoch: 692. Average Test loss: 65.2613. Test Reconstruction loss: 57.6931. Test KLD loss: 7.5682. Time: 1795.53\n",
      "<-- Epoch: 693. Average Train loss: 12.2383. Train Reconstruction loss: 2.9720. Train KLD loss: 9.2662. Time: 1798.53\n",
      "<-- Epoch: 693. Average Test loss: 64.7934. Test Reconstruction loss: 56.9990. Test KLD loss: 7.7944. Time: 1798.91\n",
      "<-- Epoch: 694. Average Train loss: 12.4680. Train Reconstruction loss: 3.1320. Train KLD loss: 9.3360. Time: 1800.83\n",
      "<-- Epoch: 694. Average Test loss: 64.9086. Test Reconstruction loss: 56.8357. Test KLD loss: 8.0729. Time: 1801.42\n",
      "<-- Epoch: 695. Average Train loss: 12.4158. Train Reconstruction loss: 3.0346. Train KLD loss: 9.3812. Time: 1803.24\n",
      "<-- Epoch: 695. Average Test loss: 65.6390. Test Reconstruction loss: 57.8397. Test KLD loss: 7.7993. Time: 1803.56\n",
      "<-- Epoch: 696. Average Train loss: 12.1608. Train Reconstruction loss: 2.9442. Train KLD loss: 9.2166. Time: 1805.81\n",
      "<-- Epoch: 696. Average Test loss: 65.0666. Test Reconstruction loss: 57.6442. Test KLD loss: 7.4225. Time: 1806.50\n",
      "<-- Epoch: 697. Average Train loss: 12.1128. Train Reconstruction loss: 2.9816. Train KLD loss: 9.1312. Time: 1808.84\n",
      "<-- Epoch: 697. Average Test loss: 64.9529. Test Reconstruction loss: 57.4738. Test KLD loss: 7.4791. Time: 1809.52\n",
      "<-- Epoch: 698. Average Train loss: 12.5257. Train Reconstruction loss: 3.0864. Train KLD loss: 9.4393. Time: 1812.13\n",
      "<-- Epoch: 698. Average Test loss: 65.0726. Test Reconstruction loss: 57.2491. Test KLD loss: 7.8235. Time: 1812.78\n",
      "<-- Epoch: 699. Average Train loss: 12.3565. Train Reconstruction loss: 2.9599. Train KLD loss: 9.3966. Time: 1816.38\n",
      "<-- Epoch: 699. Average Test loss: 65.7119. Test Reconstruction loss: 57.5759. Test KLD loss: 8.1361. Time: 1817.53\n",
      "<-- Epoch: 700. Average Train loss: 12.2189. Train Reconstruction loss: 2.9741. Train KLD loss: 9.2448. Time: 1821.08\n",
      "<-- Epoch: 700. Average Test loss: 65.8606. Test Reconstruction loss: 58.1772. Test KLD loss: 7.6834. Time: 1822.16\n",
      "<-- Epoch: 701. Average Train loss: 12.4079. Train Reconstruction loss: 3.0024. Train KLD loss: 9.4055. Time: 1825.49\n",
      "<-- Epoch: 701. Average Test loss: 65.7690. Test Reconstruction loss: 57.9683. Test KLD loss: 7.8007. Time: 1826.08\n",
      "<-- Epoch: 702. Average Train loss: 12.4016. Train Reconstruction loss: 3.0548. Train KLD loss: 9.3468. Time: 1827.86\n",
      "<-- Epoch: 702. Average Test loss: 64.3566. Test Reconstruction loss: 56.3569. Test KLD loss: 7.9997. Time: 1828.37\n",
      "<-- Epoch: 703. Average Train loss: 12.3750. Train Reconstruction loss: 3.0581. Train KLD loss: 9.3169. Time: 1830.16\n",
      "<-- Epoch: 703. Average Test loss: 65.2537. Test Reconstruction loss: 57.2036. Test KLD loss: 8.0501. Time: 1830.49\n",
      "<-- Epoch: 704. Average Train loss: 12.1889. Train Reconstruction loss: 2.9123. Train KLD loss: 9.2766. Time: 1832.52\n",
      "<-- Epoch: 704. Average Test loss: 65.1254. Test Reconstruction loss: 57.3469. Test KLD loss: 7.7785. Time: 1832.92\n",
      "<-- Epoch: 705. Average Train loss: 12.3035. Train Reconstruction loss: 3.0102. Train KLD loss: 9.2933. Time: 1834.66\n",
      "<-- Epoch: 705. Average Test loss: 64.6962. Test Reconstruction loss: 56.5547. Test KLD loss: 8.1414. Time: 1835.10\n",
      "<-- Epoch: 706. Average Train loss: 12.2807. Train Reconstruction loss: 2.9726. Train KLD loss: 9.3081. Time: 1836.98\n",
      "<-- Epoch: 706. Average Test loss: 64.6997. Test Reconstruction loss: 56.9277. Test KLD loss: 7.7719. Time: 1837.45\n",
      "<-- Epoch: 707. Average Train loss: 12.4020. Train Reconstruction loss: 3.0796. Train KLD loss: 9.3224. Time: 1839.44\n",
      "<-- Epoch: 707. Average Test loss: 64.9801. Test Reconstruction loss: 57.2972. Test KLD loss: 7.6829. Time: 1839.89\n",
      "<-- Epoch: 708. Average Train loss: 12.3181. Train Reconstruction loss: 2.9619. Train KLD loss: 9.3562. Time: 1841.66\n",
      "<-- Epoch: 708. Average Test loss: 64.9666. Test Reconstruction loss: 57.3003. Test KLD loss: 7.6663. Time: 1842.45\n",
      "<-- Epoch: 709. Average Train loss: 12.4703. Train Reconstruction loss: 3.0500. Train KLD loss: 9.4203. Time: 1844.45\n",
      "<-- Epoch: 709. Average Test loss: 65.1380. Test Reconstruction loss: 57.2464. Test KLD loss: 7.8917. Time: 1844.83\n",
      "<-- Epoch: 710. Average Train loss: 12.3025. Train Reconstruction loss: 3.0226. Train KLD loss: 9.2799. Time: 1846.62\n",
      "<-- Epoch: 710. Average Test loss: 65.1850. Test Reconstruction loss: 57.5495. Test KLD loss: 7.6355. Time: 1846.96\n",
      "<-- Epoch: 711. Average Train loss: 12.5604. Train Reconstruction loss: 3.1401. Train KLD loss: 9.4203. Time: 1848.72\n",
      "<-- Epoch: 711. Average Test loss: 64.0459. Test Reconstruction loss: 56.0590. Test KLD loss: 7.9869. Time: 1849.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 712. Average Train loss: 12.2049. Train Reconstruction loss: 2.8924. Train KLD loss: 9.3125. Time: 1851.15\n",
      "<-- Epoch: 712. Average Test loss: 65.1727. Test Reconstruction loss: 57.4900. Test KLD loss: 7.6826. Time: 1851.60\n",
      "<-- Epoch: 713. Average Train loss: 12.2725. Train Reconstruction loss: 3.0520. Train KLD loss: 9.2205. Time: 1853.54\n",
      "<-- Epoch: 713. Average Test loss: 65.4518. Test Reconstruction loss: 58.4052. Test KLD loss: 7.0466. Time: 1854.02\n",
      "<-- Epoch: 714. Average Train loss: 12.2871. Train Reconstruction loss: 2.9687. Train KLD loss: 9.3184. Time: 1856.14\n",
      "<-- Epoch: 714. Average Test loss: 65.4280. Test Reconstruction loss: 57.6305. Test KLD loss: 7.7975. Time: 1856.55\n",
      "<-- Epoch: 715. Average Train loss: 12.2515. Train Reconstruction loss: 3.0016. Train KLD loss: 9.2499. Time: 1858.59\n",
      "<-- Epoch: 715. Average Test loss: 65.1617. Test Reconstruction loss: 57.4813. Test KLD loss: 7.6804. Time: 1859.01\n",
      "<-- Epoch: 716. Average Train loss: 12.4077. Train Reconstruction loss: 3.0871. Train KLD loss: 9.3206. Time: 1860.77\n",
      "<-- Epoch: 716. Average Test loss: 66.1532. Test Reconstruction loss: 58.5817. Test KLD loss: 7.5715. Time: 1861.20\n",
      "<-- Epoch: 717. Average Train loss: 12.1824. Train Reconstruction loss: 3.0230. Train KLD loss: 9.1594. Time: 1863.03\n",
      "<-- Epoch: 717. Average Test loss: 65.1050. Test Reconstruction loss: 57.5998. Test KLD loss: 7.5052. Time: 1863.44\n",
      "<-- Epoch: 718. Average Train loss: 12.3704. Train Reconstruction loss: 3.0450. Train KLD loss: 9.3254. Time: 1865.20\n",
      "<-- Epoch: 718. Average Test loss: 65.8611. Test Reconstruction loss: 57.9866. Test KLD loss: 7.8745. Time: 1865.56\n",
      "<-- Epoch: 719. Average Train loss: 12.3000. Train Reconstruction loss: 2.8997. Train KLD loss: 9.4003. Time: 1867.35\n",
      "<-- Epoch: 719. Average Test loss: 65.0845. Test Reconstruction loss: 57.2078. Test KLD loss: 7.8767. Time: 1867.67\n",
      "<-- Epoch: 720. Average Train loss: 12.5085. Train Reconstruction loss: 3.1334. Train KLD loss: 9.3750. Time: 1869.82\n",
      "<-- Epoch: 720. Average Test loss: 65.2112. Test Reconstruction loss: 57.3749. Test KLD loss: 7.8362. Time: 1870.23\n",
      "<-- Epoch: 721. Average Train loss: 12.4751. Train Reconstruction loss: 2.9934. Train KLD loss: 9.4817. Time: 1871.96\n",
      "<-- Epoch: 721. Average Test loss: 65.4576. Test Reconstruction loss: 57.4359. Test KLD loss: 8.0217. Time: 1872.39\n",
      "<-- Epoch: 722. Average Train loss: 12.2328. Train Reconstruction loss: 2.9645. Train KLD loss: 9.2683. Time: 1874.07\n",
      "<-- Epoch: 722. Average Test loss: 65.6267. Test Reconstruction loss: 57.7290. Test KLD loss: 7.8977. Time: 1874.48\n",
      "<-- Epoch: 723. Average Train loss: 12.4121. Train Reconstruction loss: 3.0174. Train KLD loss: 9.3948. Time: 1876.10\n",
      "<-- Epoch: 723. Average Test loss: 65.1934. Test Reconstruction loss: 57.2908. Test KLD loss: 7.9026. Time: 1876.56\n",
      "<-- Epoch: 724. Average Train loss: 12.4373. Train Reconstruction loss: 3.1087. Train KLD loss: 9.3285. Time: 1878.04\n",
      "<-- Epoch: 724. Average Test loss: 65.6398. Test Reconstruction loss: 57.7802. Test KLD loss: 7.8596. Time: 1878.56\n",
      "<-- Epoch: 725. Average Train loss: 12.2178. Train Reconstruction loss: 2.9765. Train KLD loss: 9.2412. Time: 1880.27\n",
      "<-- Epoch: 725. Average Test loss: 65.8912. Test Reconstruction loss: 58.1379. Test KLD loss: 7.7533. Time: 1880.66\n",
      "<-- Epoch: 726. Average Train loss: 12.3651. Train Reconstruction loss: 3.0428. Train KLD loss: 9.3223. Time: 1882.31\n",
      "<-- Epoch: 726. Average Test loss: 66.0911. Test Reconstruction loss: 58.1160. Test KLD loss: 7.9751. Time: 1882.65\n",
      "<-- Epoch: 727. Average Train loss: 12.1606. Train Reconstruction loss: 2.8623. Train KLD loss: 9.2983. Time: 1884.32\n",
      "<-- Epoch: 727. Average Test loss: 65.9541. Test Reconstruction loss: 58.4436. Test KLD loss: 7.5105. Time: 1884.69\n",
      "<-- Epoch: 728. Average Train loss: 12.3125. Train Reconstruction loss: 3.0241. Train KLD loss: 9.2884. Time: 1886.46\n",
      "<-- Epoch: 728. Average Test loss: 64.8224. Test Reconstruction loss: 56.9354. Test KLD loss: 7.8870. Time: 1886.85\n",
      "<-- Epoch: 729. Average Train loss: 12.2225. Train Reconstruction loss: 3.0979. Train KLD loss: 9.1245. Time: 1888.68\n",
      "<-- Epoch: 729. Average Test loss: 66.1495. Test Reconstruction loss: 57.5581. Test KLD loss: 8.5914. Time: 1889.13\n",
      "<-- Epoch: 730. Average Train loss: 12.4623. Train Reconstruction loss: 2.9397. Train KLD loss: 9.5226. Time: 1890.94\n",
      "<-- Epoch: 730. Average Test loss: 66.2041. Test Reconstruction loss: 58.6716. Test KLD loss: 7.5324. Time: 1891.33\n",
      "<-- Epoch: 731. Average Train loss: 12.3099. Train Reconstruction loss: 2.9935. Train KLD loss: 9.3164. Time: 1893.14\n",
      "<-- Epoch: 731. Average Test loss: 65.4828. Test Reconstruction loss: 57.4405. Test KLD loss: 8.0423. Time: 1893.48\n",
      "<-- Epoch: 732. Average Train loss: 12.3324. Train Reconstruction loss: 3.0299. Train KLD loss: 9.3024. Time: 1895.22\n",
      "<-- Epoch: 732. Average Test loss: 65.4140. Test Reconstruction loss: 57.7949. Test KLD loss: 7.6191. Time: 1895.61\n",
      "<-- Epoch: 733. Average Train loss: 12.2297. Train Reconstruction loss: 2.9790. Train KLD loss: 9.2508. Time: 1898.20\n",
      "<-- Epoch: 733. Average Test loss: 65.7675. Test Reconstruction loss: 58.2309. Test KLD loss: 7.5366. Time: 1898.80\n",
      "<-- Epoch: 734. Average Train loss: 12.2946. Train Reconstruction loss: 3.0195. Train KLD loss: 9.2751. Time: 1901.89\n",
      "<-- Epoch: 734. Average Test loss: 66.0081. Test Reconstruction loss: 58.6352. Test KLD loss: 7.3729. Time: 1902.76\n",
      "<-- Epoch: 735. Average Train loss: 12.0216. Train Reconstruction loss: 2.9358. Train KLD loss: 9.0858. Time: 1905.38\n",
      "<-- Epoch: 735. Average Test loss: 65.0830. Test Reconstruction loss: 57.0376. Test KLD loss: 8.0454. Time: 1905.75\n",
      "<-- Epoch: 736. Average Train loss: 12.5117. Train Reconstruction loss: 3.0352. Train KLD loss: 9.4765. Time: 1907.31\n",
      "<-- Epoch: 736. Average Test loss: 64.9897. Test Reconstruction loss: 56.8057. Test KLD loss: 8.1840. Time: 1907.61\n",
      "<-- Epoch: 737. Average Train loss: 12.5090. Train Reconstruction loss: 3.0245. Train KLD loss: 9.4845. Time: 1909.03\n",
      "<-- Epoch: 737. Average Test loss: 65.8625. Test Reconstruction loss: 57.8470. Test KLD loss: 8.0154. Time: 1909.35\n",
      "<-- Epoch: 738. Average Train loss: 12.3973. Train Reconstruction loss: 2.9875. Train KLD loss: 9.4098. Time: 1910.74\n",
      "<-- Epoch: 738. Average Test loss: 64.7726. Test Reconstruction loss: 56.7425. Test KLD loss: 8.0302. Time: 1911.04\n",
      "<-- Epoch: 739. Average Train loss: 12.2801. Train Reconstruction loss: 3.0352. Train KLD loss: 9.2449. Time: 1912.74\n",
      "<-- Epoch: 739. Average Test loss: 64.9261. Test Reconstruction loss: 56.8320. Test KLD loss: 8.0941. Time: 1913.37\n",
      "<-- Epoch: 740. Average Train loss: 11.9129. Train Reconstruction loss: 2.8516. Train KLD loss: 9.0614. Time: 1915.77\n",
      "<-- Epoch: 740. Average Test loss: 66.3931. Test Reconstruction loss: 58.7170. Test KLD loss: 7.6761. Time: 1916.20\n",
      "<-- Epoch: 741. Average Train loss: 12.3929. Train Reconstruction loss: 3.0392. Train KLD loss: 9.3537. Time: 1918.51\n",
      "<-- Epoch: 741. Average Test loss: 65.6328. Test Reconstruction loss: 57.8035. Test KLD loss: 7.8293. Time: 1918.99\n",
      "<-- Epoch: 742. Average Train loss: 12.1021. Train Reconstruction loss: 2.9189. Train KLD loss: 9.1833. Time: 1921.05\n",
      "<-- Epoch: 742. Average Test loss: 65.7966. Test Reconstruction loss: 58.7755. Test KLD loss: 7.0211. Time: 1921.50\n",
      "<-- Epoch: 743. Average Train loss: 12.3170. Train Reconstruction loss: 3.0296. Train KLD loss: 9.2874. Time: 1923.53\n",
      "<-- Epoch: 743. Average Test loss: 65.7187. Test Reconstruction loss: 57.5314. Test KLD loss: 8.1873. Time: 1924.04\n",
      "<-- Epoch: 744. Average Train loss: 12.2060. Train Reconstruction loss: 2.9316. Train KLD loss: 9.2743. Time: 1926.23\n",
      "<-- Epoch: 744. Average Test loss: 65.6195. Test Reconstruction loss: 57.9787. Test KLD loss: 7.6408. Time: 1926.68\n",
      "<-- Epoch: 745. Average Train loss: 12.3209. Train Reconstruction loss: 2.8970. Train KLD loss: 9.4239. Time: 1928.76\n",
      "<-- Epoch: 745. Average Test loss: 66.0893. Test Reconstruction loss: 57.8739. Test KLD loss: 8.2154. Time: 1929.26\n",
      "<-- Epoch: 746. Average Train loss: 12.1715. Train Reconstruction loss: 2.9262. Train KLD loss: 9.2452. Time: 1931.24\n",
      "<-- Epoch: 746. Average Test loss: 65.1214. Test Reconstruction loss: 57.3886. Test KLD loss: 7.7328. Time: 1931.74\n",
      "<-- Epoch: 747. Average Train loss: 12.0206. Train Reconstruction loss: 2.8700. Train KLD loss: 9.1506. Time: 1933.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 747. Average Test loss: 65.3744. Test Reconstruction loss: 57.5087. Test KLD loss: 7.8657. Time: 1933.91\n",
      "<-- Epoch: 748. Average Train loss: 12.3686. Train Reconstruction loss: 2.9979. Train KLD loss: 9.3708. Time: 1935.75\n",
      "<-- Epoch: 748. Average Test loss: 65.0214. Test Reconstruction loss: 57.2141. Test KLD loss: 7.8073. Time: 1936.14\n",
      "<-- Epoch: 749. Average Train loss: 12.5280. Train Reconstruction loss: 3.0434. Train KLD loss: 9.4847. Time: 1937.53\n",
      "<-- Epoch: 749. Average Test loss: 66.4904. Test Reconstruction loss: 58.3416. Test KLD loss: 8.1488. Time: 1937.82\n",
      "<-- Epoch: 750. Average Train loss: 12.3946. Train Reconstruction loss: 3.0064. Train KLD loss: 9.3882. Time: 1939.27\n",
      "<-- Epoch: 750. Average Test loss: 65.5791. Test Reconstruction loss: 57.7488. Test KLD loss: 7.8303. Time: 1939.58\n",
      "<-- Epoch: 751. Average Train loss: 12.1803. Train Reconstruction loss: 2.9223. Train KLD loss: 9.2580. Time: 1941.19\n",
      "<-- Epoch: 751. Average Test loss: 65.2225. Test Reconstruction loss: 57.5372. Test KLD loss: 7.6853. Time: 1941.58\n",
      "<-- Epoch: 752. Average Train loss: 12.1683. Train Reconstruction loss: 2.8453. Train KLD loss: 9.3231. Time: 1943.13\n",
      "<-- Epoch: 752. Average Test loss: 65.5148. Test Reconstruction loss: 57.7667. Test KLD loss: 7.7481. Time: 1943.52\n",
      "<-- Epoch: 753. Average Train loss: 12.3436. Train Reconstruction loss: 2.9176. Train KLD loss: 9.4260. Time: 1945.27\n",
      "<-- Epoch: 753. Average Test loss: 66.1797. Test Reconstruction loss: 58.7144. Test KLD loss: 7.4653. Time: 1945.56\n",
      "<-- Epoch: 754. Average Train loss: 12.0582. Train Reconstruction loss: 2.8240. Train KLD loss: 9.2343. Time: 1946.94\n",
      "<-- Epoch: 754. Average Test loss: 65.9946. Test Reconstruction loss: 58.6941. Test KLD loss: 7.3005. Time: 1947.29\n",
      "<-- Epoch: 755. Average Train loss: 12.2622. Train Reconstruction loss: 2.9668. Train KLD loss: 9.2954. Time: 1948.81\n",
      "<-- Epoch: 755. Average Test loss: 66.1968. Test Reconstruction loss: 58.2293. Test KLD loss: 7.9675. Time: 1949.16\n",
      "<-- Epoch: 756. Average Train loss: 12.2086. Train Reconstruction loss: 2.9866. Train KLD loss: 9.2220. Time: 1950.60\n",
      "<-- Epoch: 756. Average Test loss: 66.2442. Test Reconstruction loss: 58.4815. Test KLD loss: 7.7627. Time: 1950.96\n",
      "<-- Epoch: 757. Average Train loss: 12.4116. Train Reconstruction loss: 3.0145. Train KLD loss: 9.3971. Time: 1952.40\n",
      "<-- Epoch: 757. Average Test loss: 65.3966. Test Reconstruction loss: 57.3357. Test KLD loss: 8.0609. Time: 1952.73\n",
      "<-- Epoch: 758. Average Train loss: 12.2774. Train Reconstruction loss: 2.9404. Train KLD loss: 9.3370. Time: 1954.24\n",
      "<-- Epoch: 758. Average Test loss: 64.8759. Test Reconstruction loss: 57.0089. Test KLD loss: 7.8670. Time: 1954.56\n",
      "<-- Epoch: 759. Average Train loss: 12.3933. Train Reconstruction loss: 2.9938. Train KLD loss: 9.3994. Time: 1956.03\n",
      "<-- Epoch: 759. Average Test loss: 66.6958. Test Reconstruction loss: 58.7178. Test KLD loss: 7.9779. Time: 1956.34\n",
      "<-- Epoch: 760. Average Train loss: 12.5652. Train Reconstruction loss: 3.0941. Train KLD loss: 9.4711. Time: 1957.80\n",
      "<-- Epoch: 760. Average Test loss: 65.1382. Test Reconstruction loss: 57.4901. Test KLD loss: 7.6481. Time: 1958.14\n",
      "<-- Epoch: 761. Average Train loss: 12.6020. Train Reconstruction loss: 3.0968. Train KLD loss: 9.5052. Time: 1959.57\n",
      "<-- Epoch: 761. Average Test loss: 66.1845. Test Reconstruction loss: 57.9802. Test KLD loss: 8.2043. Time: 1959.86\n",
      "<-- Epoch: 762. Average Train loss: 12.1789. Train Reconstruction loss: 2.8131. Train KLD loss: 9.3658. Time: 1961.28\n",
      "<-- Epoch: 762. Average Test loss: 65.7719. Test Reconstruction loss: 58.0930. Test KLD loss: 7.6788. Time: 1961.58\n",
      "<-- Epoch: 763. Average Train loss: 12.3435. Train Reconstruction loss: 2.9886. Train KLD loss: 9.3550. Time: 1962.95\n",
      "<-- Epoch: 763. Average Test loss: 65.8627. Test Reconstruction loss: 57.6334. Test KLD loss: 8.2294. Time: 1963.25\n",
      "<-- Epoch: 764. Average Train loss: 12.2805. Train Reconstruction loss: 3.0322. Train KLD loss: 9.2484. Time: 1964.62\n",
      "<-- Epoch: 764. Average Test loss: 65.6748. Test Reconstruction loss: 57.2890. Test KLD loss: 8.3858. Time: 1964.91\n",
      "<-- Epoch: 765. Average Train loss: 12.4228. Train Reconstruction loss: 2.8350. Train KLD loss: 9.5878. Time: 1966.34\n",
      "<-- Epoch: 765. Average Test loss: 65.3769. Test Reconstruction loss: 57.2835. Test KLD loss: 8.0933. Time: 1966.63\n",
      "<-- Epoch: 766. Average Train loss: 12.3071. Train Reconstruction loss: 3.0457. Train KLD loss: 9.2614. Time: 1968.02\n",
      "<-- Epoch: 766. Average Test loss: 65.7643. Test Reconstruction loss: 57.8783. Test KLD loss: 7.8860. Time: 1968.34\n",
      "<-- Epoch: 767. Average Train loss: 12.2520. Train Reconstruction loss: 2.8290. Train KLD loss: 9.4231. Time: 1969.75\n",
      "<-- Epoch: 767. Average Test loss: 66.4448. Test Reconstruction loss: 58.4554. Test KLD loss: 7.9894. Time: 1970.04\n",
      "<-- Epoch: 768. Average Train loss: 12.1731. Train Reconstruction loss: 2.8453. Train KLD loss: 9.3278. Time: 1971.50\n",
      "<-- Epoch: 768. Average Test loss: 65.5274. Test Reconstruction loss: 57.7382. Test KLD loss: 7.7892. Time: 1971.80\n",
      "<-- Epoch: 769. Average Train loss: 12.1327. Train Reconstruction loss: 2.8748. Train KLD loss: 9.2579. Time: 1973.18\n",
      "<-- Epoch: 769. Average Test loss: 66.1857. Test Reconstruction loss: 58.1935. Test KLD loss: 7.9922. Time: 1973.47\n",
      "<-- Epoch: 770. Average Train loss: 12.2654. Train Reconstruction loss: 2.9450. Train KLD loss: 9.3204. Time: 1974.89\n",
      "<-- Epoch: 770. Average Test loss: 66.4441. Test Reconstruction loss: 58.7050. Test KLD loss: 7.7392. Time: 1975.29\n",
      "<-- Epoch: 771. Average Train loss: 12.1135. Train Reconstruction loss: 2.8314. Train KLD loss: 9.2820. Time: 1976.71\n",
      "<-- Epoch: 771. Average Test loss: 66.0977. Test Reconstruction loss: 58.1106. Test KLD loss: 7.9871. Time: 1977.01\n",
      "<-- Epoch: 772. Average Train loss: 12.0126. Train Reconstruction loss: 2.8904. Train KLD loss: 9.1222. Time: 1978.50\n",
      "<-- Epoch: 772. Average Test loss: 66.3869. Test Reconstruction loss: 58.7116. Test KLD loss: 7.6753. Time: 1978.81\n",
      "<-- Epoch: 773. Average Train loss: 12.3529. Train Reconstruction loss: 3.0267. Train KLD loss: 9.3261. Time: 1980.23\n",
      "<-- Epoch: 773. Average Test loss: 66.5495. Test Reconstruction loss: 58.3655. Test KLD loss: 8.1840. Time: 1980.53\n",
      "<-- Epoch: 774. Average Train loss: 12.2791. Train Reconstruction loss: 2.8810. Train KLD loss: 9.3981. Time: 1981.96\n",
      "<-- Epoch: 774. Average Test loss: 66.2137. Test Reconstruction loss: 58.1968. Test KLD loss: 8.0169. Time: 1982.28\n",
      "<-- Epoch: 775. Average Train loss: 12.3048. Train Reconstruction loss: 2.9311. Train KLD loss: 9.3737. Time: 1983.78\n",
      "<-- Epoch: 775. Average Test loss: 65.8028. Test Reconstruction loss: 58.3352. Test KLD loss: 7.4676. Time: 1984.16\n",
      "<-- Epoch: 776. Average Train loss: 12.1165. Train Reconstruction loss: 2.8531. Train KLD loss: 9.2635. Time: 1985.60\n",
      "<-- Epoch: 776. Average Test loss: 65.3573. Test Reconstruction loss: 57.4049. Test KLD loss: 7.9523. Time: 1985.91\n",
      "<-- Epoch: 777. Average Train loss: 12.0578. Train Reconstruction loss: 2.8266. Train KLD loss: 9.2313. Time: 1987.34\n",
      "<-- Epoch: 777. Average Test loss: 65.9226. Test Reconstruction loss: 58.3880. Test KLD loss: 7.5346. Time: 1987.64\n",
      "<-- Epoch: 778. Average Train loss: 12.3351. Train Reconstruction loss: 2.9403. Train KLD loss: 9.3948. Time: 1989.05\n",
      "<-- Epoch: 778. Average Test loss: 65.6882. Test Reconstruction loss: 57.9711. Test KLD loss: 7.7172. Time: 1989.37\n",
      "<-- Epoch: 779. Average Train loss: 12.2124. Train Reconstruction loss: 2.9499. Train KLD loss: 9.2625. Time: 1990.93\n",
      "<-- Epoch: 779. Average Test loss: 66.2255. Test Reconstruction loss: 58.3602. Test KLD loss: 7.8653. Time: 1991.27\n",
      "<-- Epoch: 780. Average Train loss: 12.3852. Train Reconstruction loss: 2.9634. Train KLD loss: 9.4218. Time: 1992.82\n",
      "<-- Epoch: 780. Average Test loss: 65.8570. Test Reconstruction loss: 58.5885. Test KLD loss: 7.2684. Time: 1993.19\n",
      "<-- Epoch: 781. Average Train loss: 12.2805. Train Reconstruction loss: 2.8792. Train KLD loss: 9.4013. Time: 1994.69\n",
      "<-- Epoch: 781. Average Test loss: 66.9557. Test Reconstruction loss: 59.3916. Test KLD loss: 7.5641. Time: 1995.00\n",
      "<-- Epoch: 782. Average Train loss: 12.3575. Train Reconstruction loss: 3.0199. Train KLD loss: 9.3376. Time: 1996.48\n",
      "<-- Epoch: 782. Average Test loss: 67.0236. Test Reconstruction loss: 59.2207. Test KLD loss: 7.8028. Time: 1996.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 783. Average Train loss: 11.7990. Train Reconstruction loss: 2.8361. Train KLD loss: 8.9629. Time: 1998.33\n",
      "<-- Epoch: 783. Average Test loss: 65.7736. Test Reconstruction loss: 58.2776. Test KLD loss: 7.4960. Time: 1998.68\n",
      "<-- Epoch: 784. Average Train loss: 12.1282. Train Reconstruction loss: 2.8223. Train KLD loss: 9.3059. Time: 2000.05\n",
      "<-- Epoch: 784. Average Test loss: 66.5627. Test Reconstruction loss: 58.6070. Test KLD loss: 7.9556. Time: 2000.38\n",
      "<-- Epoch: 785. Average Train loss: 12.3479. Train Reconstruction loss: 2.9161. Train KLD loss: 9.4318. Time: 2001.80\n",
      "<-- Epoch: 785. Average Test loss: 65.7860. Test Reconstruction loss: 58.1290. Test KLD loss: 7.6570. Time: 2002.10\n",
      "<-- Epoch: 786. Average Train loss: 12.0007. Train Reconstruction loss: 2.8053. Train KLD loss: 9.1954. Time: 2003.69\n",
      "<-- Epoch: 786. Average Test loss: 66.2126. Test Reconstruction loss: 58.3858. Test KLD loss: 7.8267. Time: 2004.24\n",
      "<-- Epoch: 787. Average Train loss: 12.1716. Train Reconstruction loss: 2.9406. Train KLD loss: 9.2310. Time: 2005.72\n",
      "<-- Epoch: 787. Average Test loss: 66.0715. Test Reconstruction loss: 58.1886. Test KLD loss: 7.8829. Time: 2006.05\n",
      "<-- Epoch: 788. Average Train loss: 12.3307. Train Reconstruction loss: 2.9037. Train KLD loss: 9.4270. Time: 2007.59\n",
      "<-- Epoch: 788. Average Test loss: 65.4686. Test Reconstruction loss: 57.8508. Test KLD loss: 7.6178. Time: 2007.92\n",
      "<-- Epoch: 789. Average Train loss: 12.1732. Train Reconstruction loss: 2.9916. Train KLD loss: 9.1816. Time: 2009.44\n",
      "<-- Epoch: 789. Average Test loss: 65.9375. Test Reconstruction loss: 57.9995. Test KLD loss: 7.9381. Time: 2009.75\n",
      "<-- Epoch: 790. Average Train loss: 12.1548. Train Reconstruction loss: 2.9313. Train KLD loss: 9.2235. Time: 2011.25\n",
      "<-- Epoch: 790. Average Test loss: 66.3305. Test Reconstruction loss: 58.4630. Test KLD loss: 7.8675. Time: 2011.55\n",
      "<-- Epoch: 791. Average Train loss: 12.2427. Train Reconstruction loss: 2.8974. Train KLD loss: 9.3453. Time: 2013.03\n",
      "<-- Epoch: 791. Average Test loss: 65.8311. Test Reconstruction loss: 57.9447. Test KLD loss: 7.8864. Time: 2013.34\n",
      "<-- Epoch: 792. Average Train loss: 12.3139. Train Reconstruction loss: 2.9012. Train KLD loss: 9.4127. Time: 2014.80\n",
      "<-- Epoch: 792. Average Test loss: 65.9672. Test Reconstruction loss: 58.0804. Test KLD loss: 7.8868. Time: 2015.10\n",
      "<-- Epoch: 793. Average Train loss: 12.3730. Train Reconstruction loss: 2.9255. Train KLD loss: 9.4475. Time: 2016.60\n",
      "<-- Epoch: 793. Average Test loss: 64.7009. Test Reconstruction loss: 56.7291. Test KLD loss: 7.9718. Time: 2016.95\n",
      "<-- Epoch: 794. Average Train loss: 12.1811. Train Reconstruction loss: 2.8640. Train KLD loss: 9.3171. Time: 2018.46\n",
      "<-- Epoch: 794. Average Test loss: 65.6231. Test Reconstruction loss: 57.8291. Test KLD loss: 7.7940. Time: 2018.75\n",
      "<-- Epoch: 795. Average Train loss: 12.1052. Train Reconstruction loss: 2.8394. Train KLD loss: 9.2658. Time: 2020.33\n",
      "<-- Epoch: 795. Average Test loss: 66.4918. Test Reconstruction loss: 58.3851. Test KLD loss: 8.1067. Time: 2020.66\n",
      "<-- Epoch: 796. Average Train loss: 12.1963. Train Reconstruction loss: 2.8992. Train KLD loss: 9.2971. Time: 2022.23\n",
      "<-- Epoch: 796. Average Test loss: 66.4806. Test Reconstruction loss: 59.1004. Test KLD loss: 7.3802. Time: 2022.57\n",
      "<-- Epoch: 797. Average Train loss: 12.5851. Train Reconstruction loss: 2.9700. Train KLD loss: 9.6151. Time: 2024.12\n",
      "<-- Epoch: 797. Average Test loss: 66.8269. Test Reconstruction loss: 59.0645. Test KLD loss: 7.7624. Time: 2024.44\n",
      "<-- Epoch: 798. Average Train loss: 12.2530. Train Reconstruction loss: 2.9572. Train KLD loss: 9.2958. Time: 2025.93\n",
      "<-- Epoch: 798. Average Test loss: 65.9813. Test Reconstruction loss: 57.9928. Test KLD loss: 7.9885. Time: 2026.26\n",
      "<-- Epoch: 799. Average Train loss: 12.2955. Train Reconstruction loss: 2.8684. Train KLD loss: 9.4271. Time: 2027.83\n",
      "<-- Epoch: 799. Average Test loss: 66.0603. Test Reconstruction loss: 58.0601. Test KLD loss: 8.0003. Time: 2028.15\n",
      "<-- Epoch: 800. Average Train loss: 12.4319. Train Reconstruction loss: 2.9963. Train KLD loss: 9.4356. Time: 2029.62\n",
      "<-- Epoch: 800. Average Test loss: 66.3242. Test Reconstruction loss: 57.9561. Test KLD loss: 8.3681. Time: 2029.93\n",
      "<-- Epoch: 801. Average Train loss: 11.9982. Train Reconstruction loss: 2.7427. Train KLD loss: 9.2555. Time: 2031.53\n",
      "<-- Epoch: 801. Average Test loss: 67.1511. Test Reconstruction loss: 59.3629. Test KLD loss: 7.7883. Time: 2031.83\n",
      "<-- Epoch: 802. Average Train loss: 12.3782. Train Reconstruction loss: 2.9928. Train KLD loss: 9.3854. Time: 2033.31\n",
      "<-- Epoch: 802. Average Test loss: 66.6213. Test Reconstruction loss: 58.6807. Test KLD loss: 7.9406. Time: 2033.65\n",
      "<-- Epoch: 803. Average Train loss: 12.0614. Train Reconstruction loss: 2.7422. Train KLD loss: 9.3193. Time: 2035.22\n",
      "<-- Epoch: 803. Average Test loss: 66.0808. Test Reconstruction loss: 58.8960. Test KLD loss: 7.1848. Time: 2035.55\n",
      "<-- Epoch: 804. Average Train loss: 12.1874. Train Reconstruction loss: 2.9772. Train KLD loss: 9.2102. Time: 2037.13\n",
      "<-- Epoch: 804. Average Test loss: 66.8161. Test Reconstruction loss: 59.0402. Test KLD loss: 7.7759. Time: 2037.45\n",
      "<-- Epoch: 805. Average Train loss: 12.1769. Train Reconstruction loss: 2.8815. Train KLD loss: 9.2954. Time: 2038.95\n",
      "<-- Epoch: 805. Average Test loss: 67.2672. Test Reconstruction loss: 59.2186. Test KLD loss: 8.0486. Time: 2039.27\n",
      "<-- Epoch: 806. Average Train loss: 12.0029. Train Reconstruction loss: 2.7561. Train KLD loss: 9.2468. Time: 2040.74\n",
      "<-- Epoch: 806. Average Test loss: 66.3098. Test Reconstruction loss: 58.6553. Test KLD loss: 7.6545. Time: 2041.06\n",
      "<-- Epoch: 807. Average Train loss: 12.1527. Train Reconstruction loss: 2.9082. Train KLD loss: 9.2445. Time: 2042.55\n",
      "<-- Epoch: 807. Average Test loss: 65.6745. Test Reconstruction loss: 57.1749. Test KLD loss: 8.4996. Time: 2042.84\n",
      "<-- Epoch: 808. Average Train loss: 12.0200. Train Reconstruction loss: 2.7938. Train KLD loss: 9.2263. Time: 2044.32\n",
      "<-- Epoch: 808. Average Test loss: 66.5119. Test Reconstruction loss: 58.6674. Test KLD loss: 7.8444. Time: 2044.64\n",
      "<-- Epoch: 809. Average Train loss: 12.3670. Train Reconstruction loss: 2.9361. Train KLD loss: 9.4309. Time: 2046.13\n",
      "<-- Epoch: 809. Average Test loss: 66.1255. Test Reconstruction loss: 57.9837. Test KLD loss: 8.1419. Time: 2046.46\n",
      "<-- Epoch: 810. Average Train loss: 12.0589. Train Reconstruction loss: 2.8272. Train KLD loss: 9.2317. Time: 2047.98\n",
      "<-- Epoch: 810. Average Test loss: 66.8399. Test Reconstruction loss: 59.1187. Test KLD loss: 7.7212. Time: 2048.30\n",
      "<-- Epoch: 811. Average Train loss: 12.0944. Train Reconstruction loss: 2.7678. Train KLD loss: 9.3265. Time: 2049.82\n",
      "<-- Epoch: 811. Average Test loss: 65.9847. Test Reconstruction loss: 58.2465. Test KLD loss: 7.7382. Time: 2050.13\n",
      "<-- Epoch: 812. Average Train loss: 11.9553. Train Reconstruction loss: 2.7731. Train KLD loss: 9.1822. Time: 2051.64\n",
      "<-- Epoch: 812. Average Test loss: 65.9462. Test Reconstruction loss: 58.1644. Test KLD loss: 7.7817. Time: 2051.97\n",
      "<-- Epoch: 813. Average Train loss: 12.2487. Train Reconstruction loss: 2.9000. Train KLD loss: 9.3487. Time: 2053.40\n",
      "<-- Epoch: 813. Average Test loss: 66.2835. Test Reconstruction loss: 58.3625. Test KLD loss: 7.9210. Time: 2053.73\n",
      "<-- Epoch: 814. Average Train loss: 12.1638. Train Reconstruction loss: 2.7886. Train KLD loss: 9.3751. Time: 2055.28\n",
      "<-- Epoch: 814. Average Test loss: 66.8591. Test Reconstruction loss: 59.0820. Test KLD loss: 7.7772. Time: 2055.77\n",
      "<-- Epoch: 815. Average Train loss: 12.2253. Train Reconstruction loss: 2.7861. Train KLD loss: 9.4393. Time: 2057.32\n",
      "<-- Epoch: 815. Average Test loss: 67.4407. Test Reconstruction loss: 59.6669. Test KLD loss: 7.7738. Time: 2057.63\n",
      "<-- Epoch: 816. Average Train loss: 12.0431. Train Reconstruction loss: 2.8396. Train KLD loss: 9.2035. Time: 2059.25\n",
      "<-- Epoch: 816. Average Test loss: 67.7428. Test Reconstruction loss: 59.9974. Test KLD loss: 7.7454. Time: 2059.59\n",
      "<-- Epoch: 817. Average Train loss: 12.1066. Train Reconstruction loss: 2.9157. Train KLD loss: 9.1910. Time: 2061.18\n",
      "<-- Epoch: 817. Average Test loss: 66.5960. Test Reconstruction loss: 58.9140. Test KLD loss: 7.6821. Time: 2061.50\n",
      "<-- Epoch: 818. Average Train loss: 12.1051. Train Reconstruction loss: 2.8447. Train KLD loss: 9.2605. Time: 2063.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 818. Average Test loss: 66.8244. Test Reconstruction loss: 59.4766. Test KLD loss: 7.3478. Time: 2063.36\n",
      "<-- Epoch: 819. Average Train loss: 12.1968. Train Reconstruction loss: 2.9474. Train KLD loss: 9.2493. Time: 2064.93\n",
      "<-- Epoch: 819. Average Test loss: 66.4046. Test Reconstruction loss: 58.7360. Test KLD loss: 7.6686. Time: 2065.27\n",
      "<-- Epoch: 820. Average Train loss: 11.9931. Train Reconstruction loss: 2.7238. Train KLD loss: 9.2693. Time: 2066.80\n",
      "<-- Epoch: 820. Average Test loss: 67.2635. Test Reconstruction loss: 59.4023. Test KLD loss: 7.8612. Time: 2067.14\n",
      "<-- Epoch: 821. Average Train loss: 12.2770. Train Reconstruction loss: 2.9370. Train KLD loss: 9.3400. Time: 2068.64\n",
      "<-- Epoch: 821. Average Test loss: 66.7685. Test Reconstruction loss: 59.4158. Test KLD loss: 7.3527. Time: 2068.95\n",
      "<-- Epoch: 822. Average Train loss: 12.3025. Train Reconstruction loss: 2.9371. Train KLD loss: 9.3654. Time: 2070.40\n",
      "<-- Epoch: 822. Average Test loss: 66.1128. Test Reconstruction loss: 58.0546. Test KLD loss: 8.0582. Time: 2070.71\n",
      "<-- Epoch: 823. Average Train loss: 12.1500. Train Reconstruction loss: 2.9018. Train KLD loss: 9.2481. Time: 2072.24\n",
      "<-- Epoch: 823. Average Test loss: 65.3060. Test Reconstruction loss: 57.4608. Test KLD loss: 7.8452. Time: 2072.56\n",
      "<-- Epoch: 824. Average Train loss: 12.0011. Train Reconstruction loss: 2.8534. Train KLD loss: 9.1477. Time: 2074.25\n",
      "<-- Epoch: 824. Average Test loss: 66.0858. Test Reconstruction loss: 58.2033. Test KLD loss: 7.8825. Time: 2074.58\n",
      "<-- Epoch: 825. Average Train loss: 11.9537. Train Reconstruction loss: 2.7323. Train KLD loss: 9.2214. Time: 2076.24\n",
      "<-- Epoch: 825. Average Test loss: 65.8504. Test Reconstruction loss: 58.3239. Test KLD loss: 7.5265. Time: 2076.53\n",
      "<-- Epoch: 826. Average Train loss: 12.1120. Train Reconstruction loss: 2.9796. Train KLD loss: 9.1323. Time: 2078.79\n",
      "<-- Epoch: 826. Average Test loss: 66.7934. Test Reconstruction loss: 58.7929. Test KLD loss: 8.0005. Time: 2079.65\n",
      "<-- Epoch: 827. Average Train loss: 12.0779. Train Reconstruction loss: 2.7401. Train KLD loss: 9.3378. Time: 2082.83\n",
      "<-- Epoch: 827. Average Test loss: 66.9935. Test Reconstruction loss: 59.3485. Test KLD loss: 7.6450. Time: 2083.21\n",
      "<-- Epoch: 828. Average Train loss: 12.0831. Train Reconstruction loss: 2.8261. Train KLD loss: 9.2570. Time: 2084.69\n",
      "<-- Epoch: 828. Average Test loss: 67.0800. Test Reconstruction loss: 59.5349. Test KLD loss: 7.5450. Time: 2085.03\n",
      "<-- Epoch: 829. Average Train loss: 12.3347. Train Reconstruction loss: 2.9108. Train KLD loss: 9.4239. Time: 2086.52\n",
      "<-- Epoch: 829. Average Test loss: 66.9032. Test Reconstruction loss: 59.0185. Test KLD loss: 7.8847. Time: 2086.85\n",
      "<-- Epoch: 830. Average Train loss: 12.2994. Train Reconstruction loss: 2.9136. Train KLD loss: 9.3857. Time: 2088.42\n",
      "<-- Epoch: 830. Average Test loss: 67.8775. Test Reconstruction loss: 60.2399. Test KLD loss: 7.6375. Time: 2088.74\n",
      "<-- Epoch: 831. Average Train loss: 12.0626. Train Reconstruction loss: 2.7591. Train KLD loss: 9.3035. Time: 2090.34\n",
      "<-- Epoch: 831. Average Test loss: 67.5067. Test Reconstruction loss: 60.0696. Test KLD loss: 7.4371. Time: 2090.65\n",
      "<-- Epoch: 832. Average Train loss: 12.6813. Train Reconstruction loss: 3.0386. Train KLD loss: 9.6427. Time: 2092.13\n",
      "<-- Epoch: 832. Average Test loss: 66.4932. Test Reconstruction loss: 58.3317. Test KLD loss: 8.1615. Time: 2092.43\n",
      "<-- Epoch: 833. Average Train loss: 12.2164. Train Reconstruction loss: 2.8908. Train KLD loss: 9.3256. Time: 2093.92\n",
      "<-- Epoch: 833. Average Test loss: 66.7301. Test Reconstruction loss: 58.6470. Test KLD loss: 8.0831. Time: 2094.29\n",
      "<-- Epoch: 834. Average Train loss: 12.0362. Train Reconstruction loss: 2.8240. Train KLD loss: 9.2122. Time: 2095.85\n",
      "<-- Epoch: 834. Average Test loss: 67.2552. Test Reconstruction loss: 59.5323. Test KLD loss: 7.7229. Time: 2096.22\n",
      "<-- Epoch: 835. Average Train loss: 12.0608. Train Reconstruction loss: 2.7543. Train KLD loss: 9.3065. Time: 2097.74\n",
      "<-- Epoch: 835. Average Test loss: 66.9157. Test Reconstruction loss: 59.6678. Test KLD loss: 7.2479. Time: 2098.05\n",
      "<-- Epoch: 836. Average Train loss: 12.1140. Train Reconstruction loss: 2.9674. Train KLD loss: 9.1467. Time: 2099.58\n",
      "<-- Epoch: 836. Average Test loss: 67.0603. Test Reconstruction loss: 59.5524. Test KLD loss: 7.5080. Time: 2099.91\n",
      "<-- Epoch: 837. Average Train loss: 12.2955. Train Reconstruction loss: 2.8994. Train KLD loss: 9.3961. Time: 2101.48\n",
      "<-- Epoch: 837. Average Test loss: 66.1816. Test Reconstruction loss: 58.6550. Test KLD loss: 7.5266. Time: 2101.79\n",
      "<-- Epoch: 838. Average Train loss: 12.1856. Train Reconstruction loss: 2.8755. Train KLD loss: 9.3101. Time: 2103.37\n",
      "<-- Epoch: 838. Average Test loss: 67.2928. Test Reconstruction loss: 59.2643. Test KLD loss: 8.0285. Time: 2103.68\n",
      "<-- Epoch: 839. Average Train loss: 12.0809. Train Reconstruction loss: 2.8201. Train KLD loss: 9.2608. Time: 2105.25\n",
      "<-- Epoch: 839. Average Test loss: 66.7343. Test Reconstruction loss: 58.8314. Test KLD loss: 7.9029. Time: 2105.58\n",
      "<-- Epoch: 840. Average Train loss: 11.9658. Train Reconstruction loss: 2.7780. Train KLD loss: 9.1878. Time: 2107.10\n",
      "<-- Epoch: 840. Average Test loss: 67.2110. Test Reconstruction loss: 59.3682. Test KLD loss: 7.8428. Time: 2107.45\n",
      "<-- Epoch: 841. Average Train loss: 12.1787. Train Reconstruction loss: 2.8707. Train KLD loss: 9.3080. Time: 2109.02\n",
      "<-- Epoch: 841. Average Test loss: 67.0421. Test Reconstruction loss: 59.0448. Test KLD loss: 7.9973. Time: 2109.34\n",
      "<-- Epoch: 842. Average Train loss: 12.1754. Train Reconstruction loss: 2.9143. Train KLD loss: 9.2611. Time: 2110.83\n",
      "<-- Epoch: 842. Average Test loss: 66.6972. Test Reconstruction loss: 58.9276. Test KLD loss: 7.7696. Time: 2111.17\n",
      "<-- Epoch: 843. Average Train loss: 12.1233. Train Reconstruction loss: 2.9006. Train KLD loss: 9.2226. Time: 2112.62\n",
      "<-- Epoch: 843. Average Test loss: 67.1212. Test Reconstruction loss: 59.1430. Test KLD loss: 7.9781. Time: 2112.95\n",
      "<-- Epoch: 844. Average Train loss: 11.9111. Train Reconstruction loss: 2.7387. Train KLD loss: 9.1724. Time: 2114.62\n",
      "<-- Epoch: 844. Average Test loss: 67.0985. Test Reconstruction loss: 59.3544. Test KLD loss: 7.7441. Time: 2114.94\n",
      "<-- Epoch: 845. Average Train loss: 12.1571. Train Reconstruction loss: 2.8974. Train KLD loss: 9.2597. Time: 2116.45\n",
      "<-- Epoch: 845. Average Test loss: 66.4262. Test Reconstruction loss: 58.6768. Test KLD loss: 7.7494. Time: 2116.80\n",
      "<-- Epoch: 846. Average Train loss: 12.0757. Train Reconstruction loss: 2.9152. Train KLD loss: 9.1605. Time: 2118.38\n",
      "<-- Epoch: 846. Average Test loss: 67.6033. Test Reconstruction loss: 59.2307. Test KLD loss: 8.3726. Time: 2118.70\n",
      "<-- Epoch: 847. Average Train loss: 12.0547. Train Reconstruction loss: 2.8027. Train KLD loss: 9.2520. Time: 2120.21\n",
      "<-- Epoch: 847. Average Test loss: 66.5084. Test Reconstruction loss: 59.0072. Test KLD loss: 7.5011. Time: 2120.55\n",
      "<-- Epoch: 848. Average Train loss: 12.3541. Train Reconstruction loss: 2.9780. Train KLD loss: 9.3761. Time: 2122.08\n",
      "<-- Epoch: 848. Average Test loss: 66.2674. Test Reconstruction loss: 58.1810. Test KLD loss: 8.0864. Time: 2122.42\n",
      "<-- Epoch: 849. Average Train loss: 12.1910. Train Reconstruction loss: 2.9418. Train KLD loss: 9.2492. Time: 2123.94\n",
      "<-- Epoch: 849. Average Test loss: 67.1223. Test Reconstruction loss: 59.2088. Test KLD loss: 7.9135. Time: 2124.25\n",
      "<-- Epoch: 850. Average Train loss: 12.0975. Train Reconstruction loss: 2.8449. Train KLD loss: 9.2527. Time: 2125.68\n",
      "<-- Epoch: 850. Average Test loss: 66.6689. Test Reconstruction loss: 58.6761. Test KLD loss: 7.9928. Time: 2125.98\n",
      "<-- Epoch: 851. Average Train loss: 12.1698. Train Reconstruction loss: 2.8382. Train KLD loss: 9.3316. Time: 2127.43\n",
      "<-- Epoch: 851. Average Test loss: 67.6277. Test Reconstruction loss: 60.0953. Test KLD loss: 7.5324. Time: 2127.73\n",
      "<-- Epoch: 852. Average Train loss: 12.1449. Train Reconstruction loss: 2.7701. Train KLD loss: 9.3747. Time: 2129.19\n",
      "<-- Epoch: 852. Average Test loss: 67.3702. Test Reconstruction loss: 59.7762. Test KLD loss: 7.5940. Time: 2129.50\n",
      "<-- Epoch: 853. Average Train loss: 12.0044. Train Reconstruction loss: 2.7599. Train KLD loss: 9.2445. Time: 2130.96\n",
      "<-- Epoch: 853. Average Test loss: 67.7583. Test Reconstruction loss: 59.7485. Test KLD loss: 8.0098. Time: 2131.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 854. Average Train loss: 12.1497. Train Reconstruction loss: 2.8786. Train KLD loss: 9.2710. Time: 2132.70\n",
      "<-- Epoch: 854. Average Test loss: 67.7944. Test Reconstruction loss: 60.0409. Test KLD loss: 7.7534. Time: 2133.00\n",
      "<-- Epoch: 855. Average Train loss: 12.1141. Train Reconstruction loss: 2.8350. Train KLD loss: 9.2791. Time: 2134.47\n",
      "<-- Epoch: 855. Average Test loss: 67.1583. Test Reconstruction loss: 59.8259. Test KLD loss: 7.3324. Time: 2134.77\n",
      "<-- Epoch: 856. Average Train loss: 12.1406. Train Reconstruction loss: 2.8698. Train KLD loss: 9.2708. Time: 2136.22\n",
      "<-- Epoch: 856. Average Test loss: 66.6146. Test Reconstruction loss: 58.6493. Test KLD loss: 7.9654. Time: 2136.52\n",
      "<-- Epoch: 857. Average Train loss: 12.1564. Train Reconstruction loss: 2.9760. Train KLD loss: 9.1804. Time: 2137.95\n",
      "<-- Epoch: 857. Average Test loss: 67.9185. Test Reconstruction loss: 59.6221. Test KLD loss: 8.2964. Time: 2138.26\n",
      "<-- Epoch: 858. Average Train loss: 12.1381. Train Reconstruction loss: 2.7780. Train KLD loss: 9.3601. Time: 2139.70\n",
      "<-- Epoch: 858. Average Test loss: 67.4528. Test Reconstruction loss: 60.0489. Test KLD loss: 7.4039. Time: 2140.00\n",
      "<-- Epoch: 859. Average Train loss: 12.0863. Train Reconstruction loss: 2.8179. Train KLD loss: 9.2685. Time: 2141.51\n",
      "<-- Epoch: 859. Average Test loss: 66.0452. Test Reconstruction loss: 57.8140. Test KLD loss: 8.2312. Time: 2141.81\n",
      "<-- Epoch: 860. Average Train loss: 12.1501. Train Reconstruction loss: 2.8478. Train KLD loss: 9.3023. Time: 2143.36\n",
      "<-- Epoch: 860. Average Test loss: 67.3756. Test Reconstruction loss: 59.6675. Test KLD loss: 7.7081. Time: 2143.70\n",
      "<-- Epoch: 861. Average Train loss: 12.1635. Train Reconstruction loss: 2.8866. Train KLD loss: 9.2769. Time: 2145.30\n",
      "<-- Epoch: 861. Average Test loss: 67.3350. Test Reconstruction loss: 59.4807. Test KLD loss: 7.8543. Time: 2145.61\n",
      "<-- Epoch: 862. Average Train loss: 11.9216. Train Reconstruction loss: 2.8966. Train KLD loss: 9.0250. Time: 2147.14\n",
      "<-- Epoch: 862. Average Test loss: 66.3887. Test Reconstruction loss: 58.5764. Test KLD loss: 7.8123. Time: 2147.46\n",
      "<-- Epoch: 863. Average Train loss: 12.1513. Train Reconstruction loss: 2.8270. Train KLD loss: 9.3244. Time: 2149.03\n",
      "<-- Epoch: 863. Average Test loss: 67.0722. Test Reconstruction loss: 58.7821. Test KLD loss: 8.2901. Time: 2149.37\n",
      "<-- Epoch: 864. Average Train loss: 12.1868. Train Reconstruction loss: 2.8003. Train KLD loss: 9.3865. Time: 2150.89\n",
      "<-- Epoch: 864. Average Test loss: 66.1595. Test Reconstruction loss: 58.7269. Test KLD loss: 7.4326. Time: 2151.25\n",
      "<-- Epoch: 865. Average Train loss: 12.0572. Train Reconstruction loss: 2.8898. Train KLD loss: 9.1674. Time: 2152.86\n",
      "<-- Epoch: 865. Average Test loss: 66.8075. Test Reconstruction loss: 59.0888. Test KLD loss: 7.7187. Time: 2153.22\n",
      "<-- Epoch: 866. Average Train loss: 12.5358. Train Reconstruction loss: 2.9885. Train KLD loss: 9.5474. Time: 2154.77\n",
      "<-- Epoch: 866. Average Test loss: 67.0425. Test Reconstruction loss: 58.8819. Test KLD loss: 8.1606. Time: 2155.09\n",
      "<-- Epoch: 867. Average Train loss: 12.0339. Train Reconstruction loss: 2.7540. Train KLD loss: 9.2799. Time: 2156.67\n",
      "<-- Epoch: 867. Average Test loss: 67.3485. Test Reconstruction loss: 59.2552. Test KLD loss: 8.0933. Time: 2156.98\n",
      "<-- Epoch: 868. Average Train loss: 11.8780. Train Reconstruction loss: 2.6768. Train KLD loss: 9.2012. Time: 2158.53\n",
      "<-- Epoch: 868. Average Test loss: 66.7405. Test Reconstruction loss: 59.1100. Test KLD loss: 7.6306. Time: 2158.87\n",
      "<-- Epoch: 869. Average Train loss: 12.2696. Train Reconstruction loss: 2.8615. Train KLD loss: 9.4081. Time: 2160.47\n",
      "<-- Epoch: 869. Average Test loss: 66.4001. Test Reconstruction loss: 58.6273. Test KLD loss: 7.7728. Time: 2160.77\n",
      "<-- Epoch: 870. Average Train loss: 11.9588. Train Reconstruction loss: 2.7584. Train KLD loss: 9.2003. Time: 2162.34\n",
      "<-- Epoch: 870. Average Test loss: 66.6803. Test Reconstruction loss: 59.0766. Test KLD loss: 7.6037. Time: 2162.67\n",
      "<-- Epoch: 871. Average Train loss: 11.8245. Train Reconstruction loss: 2.7428. Train KLD loss: 9.0817. Time: 2164.24\n",
      "<-- Epoch: 871. Average Test loss: 67.3644. Test Reconstruction loss: 59.4303. Test KLD loss: 7.9341. Time: 2164.58\n",
      "<-- Epoch: 872. Average Train loss: 12.2845. Train Reconstruction loss: 2.9422. Train KLD loss: 9.3423. Time: 2166.18\n",
      "<-- Epoch: 872. Average Test loss: 67.7185. Test Reconstruction loss: 59.2710. Test KLD loss: 8.4475. Time: 2166.53\n",
      "<-- Epoch: 873. Average Train loss: 12.1425. Train Reconstruction loss: 2.8180. Train KLD loss: 9.3245. Time: 2168.23\n",
      "<-- Epoch: 873. Average Test loss: 67.7279. Test Reconstruction loss: 59.6847. Test KLD loss: 8.0432. Time: 2168.58\n",
      "<-- Epoch: 874. Average Train loss: 11.9038. Train Reconstruction loss: 2.7471. Train KLD loss: 9.1568. Time: 2170.42\n",
      "<-- Epoch: 874. Average Test loss: 67.1318. Test Reconstruction loss: 59.1566. Test KLD loss: 7.9751. Time: 2170.75\n",
      "<-- Epoch: 875. Average Train loss: 12.1439. Train Reconstruction loss: 2.8529. Train KLD loss: 9.2909. Time: 2173.60\n",
      "<-- Epoch: 875. Average Test loss: 66.7316. Test Reconstruction loss: 58.3920. Test KLD loss: 8.3395. Time: 2174.26\n",
      "<-- Epoch: 876. Average Train loss: 12.0191. Train Reconstruction loss: 2.7021. Train KLD loss: 9.3170. Time: 2177.09\n",
      "<-- Epoch: 876. Average Test loss: 67.5892. Test Reconstruction loss: 60.2736. Test KLD loss: 7.3156. Time: 2177.68\n",
      "<-- Epoch: 877. Average Train loss: 12.1886. Train Reconstruction loss: 2.8792. Train KLD loss: 9.3094. Time: 2180.47\n",
      "<-- Epoch: 877. Average Test loss: 67.2223. Test Reconstruction loss: 59.2327. Test KLD loss: 7.9896. Time: 2181.05\n",
      "<-- Epoch: 878. Average Train loss: 12.0474. Train Reconstruction loss: 2.7390. Train KLD loss: 9.3084. Time: 2182.88\n",
      "<-- Epoch: 878. Average Test loss: 66.9738. Test Reconstruction loss: 59.4100. Test KLD loss: 7.5639. Time: 2183.31\n",
      "<-- Epoch: 879. Average Train loss: 12.2724. Train Reconstruction loss: 2.8593. Train KLD loss: 9.4130. Time: 2185.37\n",
      "<-- Epoch: 879. Average Test loss: 67.4791. Test Reconstruction loss: 59.3829. Test KLD loss: 8.0962. Time: 2185.77\n",
      "<-- Epoch: 880. Average Train loss: 11.8530. Train Reconstruction loss: 2.7571. Train KLD loss: 9.0959. Time: 2187.42\n",
      "<-- Epoch: 880. Average Test loss: 66.9447. Test Reconstruction loss: 59.4007. Test KLD loss: 7.5440. Time: 2187.72\n",
      "<-- Epoch: 881. Average Train loss: 11.8907. Train Reconstruction loss: 2.9237. Train KLD loss: 8.9670. Time: 2189.51\n",
      "<-- Epoch: 881. Average Test loss: 66.6396. Test Reconstruction loss: 59.0747. Test KLD loss: 7.5649. Time: 2190.02\n",
      "<-- Epoch: 882. Average Train loss: 12.1338. Train Reconstruction loss: 2.8364. Train KLD loss: 9.2974. Time: 2192.29\n",
      "<-- Epoch: 882. Average Test loss: 67.0682. Test Reconstruction loss: 59.3821. Test KLD loss: 7.6860. Time: 2192.63\n",
      "<-- Epoch: 883. Average Train loss: 12.1444. Train Reconstruction loss: 2.8232. Train KLD loss: 9.3212. Time: 2194.34\n",
      "<-- Epoch: 883. Average Test loss: 66.4015. Test Reconstruction loss: 58.4753. Test KLD loss: 7.9263. Time: 2194.70\n",
      "<-- Epoch: 884. Average Train loss: 12.3374. Train Reconstruction loss: 2.8350. Train KLD loss: 9.5024. Time: 2196.53\n",
      "<-- Epoch: 884. Average Test loss: 68.0736. Test Reconstruction loss: 59.3705. Test KLD loss: 8.7031. Time: 2197.50\n",
      "<-- Epoch: 885. Average Train loss: 12.1656. Train Reconstruction loss: 2.8037. Train KLD loss: 9.3619. Time: 2199.81\n",
      "<-- Epoch: 885. Average Test loss: 66.9450. Test Reconstruction loss: 59.1051. Test KLD loss: 7.8400. Time: 2200.18\n",
      "<-- Epoch: 886. Average Train loss: 12.0805. Train Reconstruction loss: 2.8503. Train KLD loss: 9.2302. Time: 2201.99\n",
      "<-- Epoch: 886. Average Test loss: 67.6237. Test Reconstruction loss: 59.5014. Test KLD loss: 8.1223. Time: 2202.33\n",
      "<-- Epoch: 887. Average Train loss: 11.9815. Train Reconstruction loss: 2.7292. Train KLD loss: 9.2524. Time: 2203.95\n",
      "<-- Epoch: 887. Average Test loss: 67.2853. Test Reconstruction loss: 59.4172. Test KLD loss: 7.8681. Time: 2204.34\n",
      "<-- Epoch: 888. Average Train loss: 12.2262. Train Reconstruction loss: 2.8109. Train KLD loss: 9.4154. Time: 2206.27\n",
      "<-- Epoch: 888. Average Test loss: 67.3551. Test Reconstruction loss: 59.2554. Test KLD loss: 8.0997. Time: 2206.61\n",
      "<-- Epoch: 889. Average Train loss: 12.1358. Train Reconstruction loss: 2.8127. Train KLD loss: 9.3232. Time: 2208.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 889. Average Test loss: 66.2784. Test Reconstruction loss: 58.4610. Test KLD loss: 7.8174. Time: 2208.54\n",
      "<-- Epoch: 890. Average Train loss: 11.9505. Train Reconstruction loss: 2.8048. Train KLD loss: 9.1457. Time: 2210.01\n",
      "<-- Epoch: 890. Average Test loss: 66.4350. Test Reconstruction loss: 58.6970. Test KLD loss: 7.7380. Time: 2210.32\n",
      "<-- Epoch: 891. Average Train loss: 12.4822. Train Reconstruction loss: 2.9692. Train KLD loss: 9.5130. Time: 2211.88\n",
      "<-- Epoch: 891. Average Test loss: 67.2792. Test Reconstruction loss: 59.4263. Test KLD loss: 7.8529. Time: 2212.21\n",
      "<-- Epoch: 892. Average Train loss: 12.2844. Train Reconstruction loss: 2.7598. Train KLD loss: 9.5245. Time: 2214.28\n",
      "<-- Epoch: 892. Average Test loss: 67.2295. Test Reconstruction loss: 59.4805. Test KLD loss: 7.7490. Time: 2214.69\n",
      "<-- Epoch: 893. Average Train loss: 12.1739. Train Reconstruction loss: 2.8491. Train KLD loss: 9.3248. Time: 2216.44\n",
      "<-- Epoch: 893. Average Test loss: 68.2269. Test Reconstruction loss: 59.8473. Test KLD loss: 8.3796. Time: 2216.80\n",
      "<-- Epoch: 894. Average Train loss: 12.2108. Train Reconstruction loss: 2.7368. Train KLD loss: 9.4739. Time: 2218.40\n",
      "<-- Epoch: 894. Average Test loss: 67.9796. Test Reconstruction loss: 60.6391. Test KLD loss: 7.3406. Time: 2218.73\n",
      "<-- Epoch: 895. Average Train loss: 12.0465. Train Reconstruction loss: 2.8150. Train KLD loss: 9.2316. Time: 2220.37\n",
      "<-- Epoch: 895. Average Test loss: 67.3268. Test Reconstruction loss: 59.9584. Test KLD loss: 7.3684. Time: 2220.69\n",
      "<-- Epoch: 896. Average Train loss: 12.1289. Train Reconstruction loss: 2.8394. Train KLD loss: 9.2895. Time: 2222.27\n",
      "<-- Epoch: 896. Average Test loss: 68.3037. Test Reconstruction loss: 60.5851. Test KLD loss: 7.7186. Time: 2222.60\n",
      "<-- Epoch: 897. Average Train loss: 12.1687. Train Reconstruction loss: 2.9064. Train KLD loss: 9.2623. Time: 2224.16\n",
      "<-- Epoch: 897. Average Test loss: 67.7713. Test Reconstruction loss: 59.8689. Test KLD loss: 7.9024. Time: 2224.48\n",
      "<-- Epoch: 898. Average Train loss: 12.2857. Train Reconstruction loss: 2.9029. Train KLD loss: 9.3829. Time: 2226.03\n",
      "<-- Epoch: 898. Average Test loss: 67.3393. Test Reconstruction loss: 59.5093. Test KLD loss: 7.8300. Time: 2226.37\n",
      "<-- Epoch: 899. Average Train loss: 12.0244. Train Reconstruction loss: 2.7755. Train KLD loss: 9.2489. Time: 2227.93\n",
      "<-- Epoch: 899. Average Test loss: 67.8426. Test Reconstruction loss: 59.5638. Test KLD loss: 8.2788. Time: 2228.27\n",
      "<-- Epoch: 900. Average Train loss: 12.0221. Train Reconstruction loss: 2.7883. Train KLD loss: 9.2338. Time: 2229.94\n",
      "<-- Epoch: 900. Average Test loss: 66.7396. Test Reconstruction loss: 59.0925. Test KLD loss: 7.6471. Time: 2230.31\n",
      "<-- Epoch: 901. Average Train loss: 12.2091. Train Reconstruction loss: 2.8371. Train KLD loss: 9.3720. Time: 2231.88\n",
      "<-- Epoch: 901. Average Test loss: 68.8368. Test Reconstruction loss: 60.9074. Test KLD loss: 7.9294. Time: 2232.22\n",
      "<-- Epoch: 902. Average Train loss: 12.4261. Train Reconstruction loss: 2.8759. Train KLD loss: 9.5501. Time: 2233.78\n",
      "<-- Epoch: 902. Average Test loss: 69.1724. Test Reconstruction loss: 60.9383. Test KLD loss: 8.2341. Time: 2234.10\n",
      "<-- Epoch: 903. Average Train loss: 12.1953. Train Reconstruction loss: 2.7627. Train KLD loss: 9.4326. Time: 2235.69\n",
      "<-- Epoch: 903. Average Test loss: 67.7768. Test Reconstruction loss: 59.4783. Test KLD loss: 8.2985. Time: 2236.01\n",
      "<-- Epoch: 904. Average Train loss: 12.0702. Train Reconstruction loss: 2.7286. Train KLD loss: 9.3416. Time: 2237.59\n",
      "<-- Epoch: 904. Average Test loss: 66.3453. Test Reconstruction loss: 58.9747. Test KLD loss: 7.3706. Time: 2237.91\n",
      "<-- Epoch: 905. Average Train loss: 12.0125. Train Reconstruction loss: 2.7797. Train KLD loss: 9.2328. Time: 2239.54\n",
      "<-- Epoch: 905. Average Test loss: 67.0673. Test Reconstruction loss: 59.2907. Test KLD loss: 7.7766. Time: 2239.91\n",
      "<-- Epoch: 906. Average Train loss: 12.1725. Train Reconstruction loss: 2.7874. Train KLD loss: 9.3851. Time: 2241.65\n",
      "<-- Epoch: 906. Average Test loss: 66.9136. Test Reconstruction loss: 58.9038. Test KLD loss: 8.0098. Time: 2241.97\n",
      "<-- Epoch: 907. Average Train loss: 11.8726. Train Reconstruction loss: 2.6206. Train KLD loss: 9.2520. Time: 2243.69\n",
      "<-- Epoch: 907. Average Test loss: 67.0992. Test Reconstruction loss: 59.4835. Test KLD loss: 7.6157. Time: 2244.10\n",
      "<-- Epoch: 908. Average Train loss: 12.3276. Train Reconstruction loss: 3.0244. Train KLD loss: 9.3033. Time: 2245.68\n",
      "<-- Epoch: 908. Average Test loss: 67.1049. Test Reconstruction loss: 59.3038. Test KLD loss: 7.8011. Time: 2246.00\n",
      "<-- Epoch: 909. Average Train loss: 12.0845. Train Reconstruction loss: 2.8705. Train KLD loss: 9.2140. Time: 2247.58\n",
      "<-- Epoch: 909. Average Test loss: 66.8945. Test Reconstruction loss: 59.1143. Test KLD loss: 7.7802. Time: 2247.91\n",
      "<-- Epoch: 910. Average Train loss: 11.9275. Train Reconstruction loss: 2.7811. Train KLD loss: 9.1464. Time: 2249.47\n",
      "<-- Epoch: 910. Average Test loss: 66.9342. Test Reconstruction loss: 59.1029. Test KLD loss: 7.8313. Time: 2249.79\n",
      "<-- Epoch: 911. Average Train loss: 11.9236. Train Reconstruction loss: 2.7145. Train KLD loss: 9.2091. Time: 2251.35\n",
      "<-- Epoch: 911. Average Test loss: 66.8746. Test Reconstruction loss: 59.3599. Test KLD loss: 7.5148. Time: 2251.67\n",
      "<-- Epoch: 912. Average Train loss: 11.9969. Train Reconstruction loss: 2.7957. Train KLD loss: 9.2011. Time: 2253.32\n",
      "<-- Epoch: 912. Average Test loss: 67.2599. Test Reconstruction loss: 59.4289. Test KLD loss: 7.8310. Time: 2253.67\n",
      "<-- Epoch: 913. Average Train loss: 11.8603. Train Reconstruction loss: 2.7143. Train KLD loss: 9.1460. Time: 2255.37\n",
      "<-- Epoch: 913. Average Test loss: 66.4550. Test Reconstruction loss: 58.8401. Test KLD loss: 7.6149. Time: 2255.75\n",
      "<-- Epoch: 914. Average Train loss: 12.1051. Train Reconstruction loss: 2.9091. Train KLD loss: 9.1960. Time: 2257.42\n",
      "<-- Epoch: 914. Average Test loss: 67.0508. Test Reconstruction loss: 58.9409. Test KLD loss: 8.1099. Time: 2257.73\n",
      "<-- Epoch: 915. Average Train loss: 12.2627. Train Reconstruction loss: 2.7485. Train KLD loss: 9.5143. Time: 2259.34\n",
      "<-- Epoch: 915. Average Test loss: 67.4782. Test Reconstruction loss: 59.5554. Test KLD loss: 7.9228. Time: 2259.66\n",
      "<-- Epoch: 916. Average Train loss: 12.0481. Train Reconstruction loss: 2.7933. Train KLD loss: 9.2548. Time: 2261.25\n",
      "<-- Epoch: 916. Average Test loss: 66.9992. Test Reconstruction loss: 58.7236. Test KLD loss: 8.2756. Time: 2261.57\n",
      "<-- Epoch: 917. Average Train loss: 12.0523. Train Reconstruction loss: 2.8179. Train KLD loss: 9.2344. Time: 2263.15\n",
      "<-- Epoch: 917. Average Test loss: 67.1366. Test Reconstruction loss: 59.3065. Test KLD loss: 7.8301. Time: 2263.48\n",
      "<-- Epoch: 918. Average Train loss: 11.8172. Train Reconstruction loss: 2.7482. Train KLD loss: 9.0690. Time: 2265.09\n",
      "<-- Epoch: 918. Average Test loss: 68.2813. Test Reconstruction loss: 60.1854. Test KLD loss: 8.0959. Time: 2265.43\n",
      "<-- Epoch: 919. Average Train loss: 12.1450. Train Reconstruction loss: 2.7486. Train KLD loss: 9.3964. Time: 2266.97\n",
      "<-- Epoch: 919. Average Test loss: 67.2889. Test Reconstruction loss: 59.1578. Test KLD loss: 8.1310. Time: 2267.27\n",
      "<-- Epoch: 920. Average Train loss: 12.1850. Train Reconstruction loss: 2.7975. Train KLD loss: 9.3875. Time: 2268.84\n",
      "<-- Epoch: 920. Average Test loss: 66.5953. Test Reconstruction loss: 58.1908. Test KLD loss: 8.4046. Time: 2269.17\n",
      "<-- Epoch: 921. Average Train loss: 11.9081. Train Reconstruction loss: 2.6613. Train KLD loss: 9.2468. Time: 2270.81\n",
      "<-- Epoch: 921. Average Test loss: 68.6513. Test Reconstruction loss: 60.8111. Test KLD loss: 7.8402. Time: 2271.19\n",
      "<-- Epoch: 922. Average Train loss: 12.1753. Train Reconstruction loss: 2.7964. Train KLD loss: 9.3788. Time: 2272.87\n",
      "<-- Epoch: 922. Average Test loss: 66.9831. Test Reconstruction loss: 59.3221. Test KLD loss: 7.6610. Time: 2273.23\n",
      "<-- Epoch: 923. Average Train loss: 12.0968. Train Reconstruction loss: 2.7619. Train KLD loss: 9.3349. Time: 2274.91\n",
      "<-- Epoch: 923. Average Test loss: 67.1527. Test Reconstruction loss: 59.2659. Test KLD loss: 7.8868. Time: 2275.27\n",
      "<-- Epoch: 924. Average Train loss: 12.1740. Train Reconstruction loss: 2.7993. Train KLD loss: 9.3746. Time: 2276.89\n",
      "<-- Epoch: 924. Average Test loss: 66.0594. Test Reconstruction loss: 58.2888. Test KLD loss: 7.7706. Time: 2277.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- Epoch: 925. Average Train loss: 12.1908. Train Reconstruction loss: 2.7838. Train KLD loss: 9.4070. Time: 2278.80\n",
      "<-- Epoch: 925. Average Test loss: 67.2715. Test Reconstruction loss: 59.4574. Test KLD loss: 7.8141. Time: 2279.14\n",
      "<-- Epoch: 926. Average Train loss: 11.9927. Train Reconstruction loss: 2.6969. Train KLD loss: 9.2959. Time: 2280.72\n",
      "<-- Epoch: 926. Average Test loss: 67.6210. Test Reconstruction loss: 59.8153. Test KLD loss: 7.8057. Time: 2281.04\n",
      "<-- Epoch: 927. Average Train loss: 12.0761. Train Reconstruction loss: 2.7837. Train KLD loss: 9.2923. Time: 2282.62\n",
      "<-- Epoch: 927. Average Test loss: 68.4517. Test Reconstruction loss: 60.6620. Test KLD loss: 7.7896. Time: 2282.94\n",
      "<-- Epoch: 928. Average Train loss: 12.0065. Train Reconstruction loss: 2.7240. Train KLD loss: 9.2825. Time: 2284.53\n",
      "<-- Epoch: 928. Average Test loss: 68.5127. Test Reconstruction loss: 60.4817. Test KLD loss: 8.0310. Time: 2284.90\n",
      "<-- Epoch: 929. Average Train loss: 12.0087. Train Reconstruction loss: 2.7288. Train KLD loss: 9.2799. Time: 2286.75\n",
      "<-- Epoch: 929. Average Test loss: 68.1582. Test Reconstruction loss: 60.2958. Test KLD loss: 7.8625. Time: 2287.24\n",
      "<-- Epoch: 930. Average Train loss: 12.1394. Train Reconstruction loss: 2.7838. Train KLD loss: 9.3556. Time: 2288.83\n",
      "<-- Epoch: 930. Average Test loss: 67.3253. Test Reconstruction loss: 59.8181. Test KLD loss: 7.5072. Time: 2289.17\n",
      "<-- Epoch: 931. Average Train loss: 11.8562. Train Reconstruction loss: 2.6791. Train KLD loss: 9.1771. Time: 2290.96\n",
      "<-- Epoch: 931. Average Test loss: 67.0403. Test Reconstruction loss: 59.3485. Test KLD loss: 7.6917. Time: 2291.29\n",
      "<-- Epoch: 932. Average Train loss: 11.8963. Train Reconstruction loss: 2.6577. Train KLD loss: 9.2385. Time: 2292.88\n",
      "<-- Epoch: 932. Average Test loss: 67.5559. Test Reconstruction loss: 60.0375. Test KLD loss: 7.5183. Time: 2293.21\n",
      "<-- Epoch: 933. Average Train loss: 12.1626. Train Reconstruction loss: 2.8190. Train KLD loss: 9.3436. Time: 2294.86\n",
      "<-- Epoch: 933. Average Test loss: 68.3380. Test Reconstruction loss: 60.1976. Test KLD loss: 8.1404. Time: 2295.21\n",
      "<-- Epoch: 934. Average Train loss: 12.0831. Train Reconstruction loss: 2.6793. Train KLD loss: 9.4038. Time: 2296.84\n",
      "<-- Epoch: 934. Average Test loss: 67.5804. Test Reconstruction loss: 59.7120. Test KLD loss: 7.8684. Time: 2297.17\n",
      "<-- Epoch: 935. Average Train loss: 12.1269. Train Reconstruction loss: 2.7582. Train KLD loss: 9.3687. Time: 2298.88\n",
      "<-- Epoch: 935. Average Test loss: 68.1444. Test Reconstruction loss: 60.1365. Test KLD loss: 8.0079. Time: 2299.39\n",
      "<-- Epoch: 936. Average Train loss: 11.9995. Train Reconstruction loss: 2.7492. Train KLD loss: 9.2503. Time: 2301.33\n",
      "<-- Epoch: 936. Average Test loss: 67.9207. Test Reconstruction loss: 60.1270. Test KLD loss: 7.7937. Time: 2301.64\n",
      "<-- Epoch: 937. Average Train loss: 12.1186. Train Reconstruction loss: 2.7873. Train KLD loss: 9.3313. Time: 2303.49\n",
      "<-- Epoch: 937. Average Test loss: 66.9782. Test Reconstruction loss: 59.2366. Test KLD loss: 7.7416. Time: 2304.00\n",
      "<-- Epoch: 938. Average Train loss: 12.1133. Train Reconstruction loss: 2.8288. Train KLD loss: 9.2845. Time: 2306.14\n",
      "<-- Epoch: 938. Average Test loss: 68.0000. Test Reconstruction loss: 60.3029. Test KLD loss: 7.6971. Time: 2306.58\n",
      "<-- Epoch: 939. Average Train loss: 12.1389. Train Reconstruction loss: 2.7275. Train KLD loss: 9.4114. Time: 2308.72\n",
      "<-- Epoch: 939. Average Test loss: 68.5053. Test Reconstruction loss: 60.4992. Test KLD loss: 8.0061. Time: 2309.20\n",
      "<-- Epoch: 940. Average Train loss: 12.2220. Train Reconstruction loss: 2.7600. Train KLD loss: 9.4620. Time: 2311.44\n",
      "<-- Epoch: 940. Average Test loss: 67.0409. Test Reconstruction loss: 59.1932. Test KLD loss: 7.8477. Time: 2311.78\n",
      "<-- Epoch: 941. Average Train loss: 12.2327. Train Reconstruction loss: 2.9053. Train KLD loss: 9.3274. Time: 2313.40\n",
      "<-- Epoch: 941. Average Test loss: 67.5372. Test Reconstruction loss: 59.5775. Test KLD loss: 7.9597. Time: 2313.84\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, train_kld_loss, test_kld_loss, train_recon_loss, test_recon_loss = [], [], [], [], [], []\n",
    "model = VAE(21 * 238, 50, 20, 21)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "start_time = time.time()\n",
    "epochs = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, reconstruction_loss, kld_loss = 0, 0, 0\n",
    "    model.train()\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = model(x)\n",
    "        rloss, kloss = model.NLLoss(recon_x, x), model.KLD(mu, logvar)\n",
    "        loss = rloss + kloss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"Batch {0}: reconstruction loss: {1} kld loss {2}\".format(batch_idx, rloss, kloss))\n",
    "        train_loss += loss.item()\n",
    "        reconstruction_loss += rloss.item()\n",
    "        kld_loss += kloss.item()\n",
    "    kld_loss /= len(train_loader.dataset)\n",
    "    reconstruction_loss /= len(train_loader.dataset)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('<-- Epoch: {0}. Average Train loss: {1:.4f}. Train Reconstruction loss: {2:.4f}. Train KLD loss: {3:.4f}. Time: {4:.2f}'.format(\n",
    "                    epoch, train_loss, reconstruction_loss, kld_loss, time.time() - start_time))\n",
    "    \n",
    "    train_losses.append(train_loss); train_kld_loss.append(kld_loss); train_recon_loss.append(reconstruction_loss)\n",
    "    model.eval()\n",
    "    test_loss, reconstruction_loss, kld_loss = 0, 0, 0\n",
    "    for batch_idx, (x, _) in enumerate(test_loader):\n",
    "        recon_x, mu, logvar = model(x)\n",
    "        rloss, kloss = model.NLLoss(recon_x, x), model.KLD(mu, logvar)\n",
    "        loss = rloss + kloss\n",
    "        test_loss += loss.item()\n",
    "        reconstruction_loss += rloss.item()\n",
    "        kld_loss += kloss.item()\n",
    "    kld_loss /= len(test_loader.dataset)\n",
    "    reconstruction_loss /= len(test_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss); test_kld_loss.append(kld_loss); test_recon_loss.append(reconstruction_loss)\n",
    "    print('<-- Epoch: {0}. Average Test loss: {1:.4f}. Test Reconstruction loss: {2:.4f}. Test KLD loss: {3:.4f}. Time: {4:.2f}'.format(\n",
    "                    epoch, test_loss, reconstruction_loss, kld_loss, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "losses = {\n",
    "    \"train loss\" : train_losses,\n",
    "    \"test loss\" : test_losses,\n",
    "    \"test kld loss\" : test_kld_loss, \n",
    "    \"test reconstruction loss\" : test_recon_loss, \n",
    "    \"train kld loss\" : train_kld_loss,\n",
    "    \"train reconstruction loss\" : train_recon_loss\n",
    "}\n",
    "for loss_name, loss in losses.items():\n",
    "    plt.plot(loss, label = loss_name)\n",
    "    \n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.title(\"training history\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GenerativeVAE(): \n",
    "    \n",
    "    def __init__(self, args):     \n",
    "        \"\"\"\n",
    "        Initializes the VAE to be a generative VAE\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dictionary\n",
    "            defines the hyper-parameters of the neural network\n",
    "        args.name : string \n",
    "            defines the name of the neural network\n",
    "        args.description: string\n",
    "            describes the architecture of the neural network\n",
    "        args.input : int\n",
    "            the size of the input\n",
    "        args.hidden_size : int\n",
    "            the size of the hidden layer\n",
    "        args.latent_dim: int \n",
    "            the size of the latent dimension\n",
    "        args.device : device\n",
    "            the device used: cpu or gpu\n",
    "        args.learning_rate : float\n",
    "            sets the learning rate\n",
    "        args.epochs : int \n",
    "            sets the epoch size \n",
    "        args.beta : float\n",
    "            sets the beta parameter for the KL divergence loss\n",
    "        args.vocabulary : string\n",
    "            all the characters in the context of the problem\n",
    "        \"\"\"\n",
    "        self.name = args[\"name\"]\n",
    "        self.description = args[\"description\"]\n",
    "        self.input = args[\"input\"]\n",
    "        self.hidden_size = args[\"hidden_size\"]\n",
    "        self.latent_dim = args[\"latent_dim\"]\n",
    "        self.device = args[\"device\"]\n",
    "        self.learning_rate = args[\"learning_rate\"]\n",
    "        self.epochs = args[\"epochs\"]\n",
    "        self.beta = args[\"beta\"]\n",
    "        self.all_characters = args[\"vocabulary\"]\n",
    "        self.num_characters = len(self.all_characters)\n",
    "        self.character_to_int = dict(zip(self.all_characters, range(self.num_characters)))\n",
    "        self.int_to_character = dict(zip(range(self.num_characters), self.all_characters))\n",
    "        self.model = VAE(self.input, self.hidden_size, self.latent_dim, self.num_characters)\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.train_loss_history = []\n",
    "        self.test_loss_history = []\n",
    "        \n",
    "    # Reconstruction + KL divergence losses summed over all elements in batch\n",
    "    def elbo_loss(self, recon_x, x, mu, logvar):\n",
    "        \"\"\"\n",
    "        Input: x is the one hot encoded batch_size x (seq_length * len(all_characters)) \n",
    "               recon_x is the unormalized outputs of the decoder in the same shape as x\n",
    "               mu and logvar are the hidden states of size self.hidden_size\n",
    "        Output: elbo_loss\n",
    "        \"\"\"\n",
    "        # get the argmax of each batch_size x seq_length * len(all_characters) matrix. Output is in batch_size x seq_length form\n",
    "        # print(labels)\n",
    "        # reshapes the recon_x vector to be of shape batch_size x len(all_characters) x seq_length so that it fits according to PyTorch's CrossEntropyLoss\n",
    "        # permute is transpose function so at each 1, 2 dimension we take the transpose\n",
    "        # print(recon_x.shape)\n",
    "        # print(reshape_x[0,:,0])\n",
    "        outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        CE = (-1 * outputs * x.view(x.shape[0], -1, len(self.all_characters))).sum()\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        #print(\"log var shape:\", logvar.shape, \"mu shape: \", mu.shape, \"logvar: \", logvar.sum(dim=1))\n",
    "        #print(\"mu: \", mu.sum(dim=1))\n",
    "        #print((1 + logvar - mu.pow(2) - logvar.exp()).shape)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        #print(\"CE Loss: \", CE, \"KLD Loss:\", KLD, file=logger)\n",
    "        return CE + KLD\n",
    "    \n",
    "    def NLLoss(self, recon_x, x):\n",
    "        outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        return  (-1 * outputs * x.view(x.shape[0], -1, len(self.all_characters))).sum()\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        input = recon_x.permute(0, 2, 1)\n",
    "        _, target = x.view(x.shape[0], -1, self.num_characters).max(dim=2)\n",
    "        target = target.long()\n",
    "        return loss(input, target)\n",
    "    \n",
    "    def KLD(self, mu, logvar): \n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    def fit(self, train_dataloader, test_dataloader=None, verbose=True, logger=None, save_model=True):\n",
    "        # amino acid dataset specific checks\n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        three_mutation = get_mutation(wild_type, num_mutations=3, alphabet=self.all_characters)\n",
    "        ten_mutation = get_mutation(wild_type, num_mutations=10, alphabet=self.all_characters)\n",
    "        \n",
    "        if not os.path.isdir(\"./models/{0}\".format(self.name)):\n",
    "            os.mkdir(\"./models/{0}\".format(self.name))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.train_loss_history, self.test_loss_history = [], []\n",
    "        self.reconstruction_loss_history, self.kld_loss_history = [], []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            #train model\n",
    "            self.model.train()\n",
    "            train_loss, reconstruction_loss, kld_loss = 0, 0, 0\n",
    "            for batch_idx, (x, _) in enumerate(train_dataloader):\n",
    "                x = x.to(self.device)\n",
    "                #labels = x.view(x.shape[0], -1, len(self.all_characters)).argmax(dim = 2)\n",
    "                self.optimizer.zero_grad()\n",
    "                recon_x, mu, logvar = self.model(x)\n",
    "                rloss, kloss = self.NLLoss(recon_x, x), self.KLD(mu, logvar)\n",
    "                loss = rloss + kloss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                #print(\"Batch {0}: reconstruction loss: {1} kld loss {2}\".format(batch_idx, rloss, kloss))\n",
    "                train_loss += loss.item()\n",
    "                reconstruction_loss += rloss.item()\n",
    "                kld_loss += kloss.item()\n",
    "            self.train_loss_history.append(train_loss / len(train_dataloader.dataset))\n",
    "            self.reconstruction_loss_history.append(reconstruction_loss / len(train_dataloader.dataset))\n",
    "            self.kld_loss_history.append(kld_loss / len(train_dataloader.dataset))\n",
    "            #evaluate model\n",
    "            self.model.eval()\n",
    "            decoder_outputs, _ = self.sample(num_samples=10, softmax=True)\n",
    "            generated_sequences = [self.sample_tensor_to_string(tensor, softmax=False) for tensor in decoder_outputs]\n",
    "            mismatches = [count_substring_mismatch(wild_type, sequence) for sequence in generated_sequences]\n",
    "            wild_prob, mutation_three_prob, mutation_ten_prob = self.predict_elbo_prob([wild_type]), self.predict_elbo_prob([three_mutation]), self.predict_elbo_prob([ten_mutation])\n",
    "            \n",
    "            if verbose: \n",
    "                print('<====> Epoch: {0}. Average loss: {1:.4f}. Reconstruction loss: {2:.4f}. KLD loss: {3:.4f}. Time: {4:.2f} seconds'.format(\n",
    "                      epoch, self.train_loss_history[-1], self.reconstruction_loss_history[-1], self.kld_loss_history[-1], time.time() - start_time), file = logger)\n",
    "                print(\"Sample generated sequence: {0}\\nAverage mismatches from the wild type: {1}\".format(generated_sequences[0], np.mean(mismatches)), file = logger) \n",
    "                print(\"wild type elbo prob: {0}. 3 mutations elbo prob: {1}. 10 mutations elbo prob: {2}.\" \\\n",
    "                      .format(wild_prob, mutation_three_prob, mutation_ten_prob), file = logger)\n",
    "            if test_dataloader:\n",
    "                test_loss = self.evaluate(test_dataloader, verbose, logger)\n",
    "                self.test_loss_history.append(test_loss)\n",
    "            if epoch % 100 == 0 and save_model:\n",
    "                self.save_model(epoch, train_loss)\n",
    "                print(\"finished saving model\", file=logger)\n",
    "     \n",
    "    def sample_tensor_to_string(self, x, softmax=False):\n",
    "        assert(type(x) == torch.Tensor)\n",
    "        assert(x.shape[0] % self.num_characters == 0 or x.shape[1] % self.num_characters == 0)\n",
    "        x = x.reshape(-1, self.num_characters)\n",
    "        if softmax:\n",
    "            x = F.softmax(x, dim=1)\n",
    "        string = []\n",
    "        for dist in x: \n",
    "            index = torch.multinomial(dist, 1).item()\n",
    "            string.append(self.int_to_character[index])\n",
    "        return \"\".join(string)\n",
    "    \n",
    "    def tensor_to_string(self, x):\n",
    "        \"\"\"\n",
    "        Input: A sequence in tensor format\n",
    "        Output: A sequence in string format\n",
    "        Example: tensor_to_string(torch.tensor([0, 0, 1, 0, 0, 0, 1, 0])) = \"TT\"\n",
    "        tensor_to_string(torch.tensor([0.8, 0.15, 0.05, 0, 0, 0.9, 0.1, 0])) = \"AC\"\n",
    "        note: alphabet is \"ACTG\" in this example\n",
    "        \"\"\"\n",
    "        assert(type(x) == torch.Tensor)\n",
    "        assert(len(x) % self.num_characters == 0)\n",
    "        x = x.reshape(-1, self.num_characters)\n",
    "        _, index = x.max(dim = 1)\n",
    "        return \"\".join([self.int_to_character[i] for i in index.numpy()])\n",
    "        \n",
    "    def predict_elbo_prob(self, sequences, string=True):\n",
    "        \"\"\"\n",
    "        Input: list of sequences in string or one_hot_encoded form\n",
    "        Output: list of the elbo probability for each sequence\n",
    "        Example: predict_elbo_prob([\"ACT\", \"ACG\"]) = [0.2, 0.75]\n",
    "        predict_elbo_prob([[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],  \n",
    "                        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]]) = [0.2, 0.75]\n",
    "        note: alphabet in this example is ACTG and the wild type is probably ACG***\n",
    "        \"\"\"\n",
    "        if string: \n",
    "            sequences = one_hot_encode(sequences, self.all_characters)\n",
    "        if type(sequences) != torch.Tensor:\n",
    "            x = self.to_tensor(sequences)\n",
    "        recon_x, mu, logvar = self.model(x)\n",
    "        return self.elbo_loss(recon_x, x, mu, logvar)\n",
    "    \n",
    "    def evaluate(self, dataloader, verbose=True, logger=None):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        mismatches = []\n",
    "        wild_type_mismatches, wild_type = [], get_wild_type_amino_acid_sequence()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, _) in enumerate(dataloader):\n",
    "                x = x.to(self.device)\n",
    "                recon_x, mu, logvar = self.model(x)\n",
    "                test_loss += self.elbo_loss(recon_x, x, mu, logvar).item()\n",
    "                recon_str, x_str = self.sample_tensor_to_string(recon_x[0], softmax=True), self.tensor_to_string(x[0])\n",
    "                mismatches.append(count_substring_mismatch(x_str, recon_str))\n",
    "                wild_type_mismatches.append(count_substring_mismatch(wild_type, recon_str))\n",
    "        test_loss /= len(dataloader.dataset)\n",
    "        if verbose: \n",
    "            print('Test set loss: {0:.4f} Average Mismatches: {1:.4f} Wild Type Mismatches {2:.4f} <====> \\n'.format(test_loss, np.mean(mismatches), np.mean(wild_type_mismatches)), file=logger)\n",
    "        return test_loss\n",
    "    \n",
    "    def to_tensor(self, x): \n",
    "        assert(type(x) == np.ndarray)\n",
    "        return torch.from_numpy(x).float().to(self.device)\n",
    "    \n",
    "    def decoder(self, z, softmax=False):\n",
    "        \"\"\" Note that the outputs are unnormalized \"\"\"\n",
    "        assert(z.shape[1] == self.latent_dim)\n",
    "        if type(z) != torch.Tensor:\n",
    "            z = self.to_tensor(z)\n",
    "        return self.model.decode(z, softmax=softmax)\n",
    "    \n",
    "    def encoder(self, x, reparameterize=False): \n",
    "        assert(x.shape[1] == self.input)\n",
    "        if type(x) != torch.Tensor:\n",
    "            x = self.to_tensor(x)\n",
    "        mu, log_var = self.model.encode(x)\n",
    "        if reparameterize: \n",
    "            return self.model.reparameterize(mu, log_var), mu, log_var\n",
    "        else: \n",
    "            return mu, log_var\n",
    "        \n",
    "    def sample(self, num_samples = 1, z = None, softmax=True): \n",
    "        if z is None: \n",
    "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "        return self.decoder(z, softmax=softmax), z\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    def save_model(self, epoch=None, loss=None): \n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': loss,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                }, \"./models/{0}/checkpoint_{1}.pt\".format(self.name, epoch))\n",
    "\n",
    "    def show_model(self, logger=None): \n",
    "        print(self.model, file=logger)\n",
    "    \n",
    "    def plot_model(self, save_dir, verbose=False): \n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        one_hot_wild_type = one_hot_encode([wild_type], self.all_characters)\n",
    "        one_hot_tensor_wild_type = self.to_tensor(one_hot_wild_type)\n",
    "        out, _, _ = self.model(one_hot_tensor_wild_type)\n",
    "        graph = make_dot(out)\n",
    "        if save_dir is not None:\n",
    "            graph.format = \"png\"\n",
    "            graph.render(save_dir) \n",
    "        if verbose:\n",
    "            graph.view()\n",
    "            \n",
    "    def print_vars(self):\n",
    "        print(self.__dict__)\n",
    "        \n",
    "    def plot_history(self, save_fig_dir): \n",
    "        plt.figure()\n",
    "        plt.title(\"{0} Training Loss Curve\".format(self.name))\n",
    "        plt.plot(self.train_loss_history, label=\"train\")\n",
    "        if \"test_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.test_loss_history, label=\"validation\")\n",
    "        if \"reconstruction_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.reconstruction_loss_history, label=\"reconstruction_loss\")\n",
    "        if \"kld_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.kld_loss_history, label=\"kld_loss\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        if save_fig_dir:\n",
    "            plt.savefig(save_fig_dir)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_args():\n",
    "    args = {\n",
    "        \"name\" : \"vae_fc5_epochs_100_learning_rate_0.1\",\n",
    "        \"input\" : 21 * 238, \n",
    "        \"hidden_size\" : 50,\n",
    "        \"latent_dim\" : 20,\n",
    "        \"device\" : torch.device(\"cpu\"),\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"epochs\" : 100,\n",
    "        \"beta\" : 1.0,\n",
    "        \"vocabulary\" : get_all_amino_acids(),\n",
    "        \"num_data\" : 1000, \n",
    "        \"batch_size\" : 10\n",
    "    }\n",
    "    args[\"description\"] = \"name: {0}, input size {1}, hidden size {2}, latent_dim {3}, lr {4}, epochs {5}\".format(\n",
    "                args[\"name\"], args[\"input\"], args[\"hidden_size\"], args[\"latent_dim\"], args[\"learning_rate\"], args[\"epochs\"])\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_shuffle_\")\n",
    "args = get_test_args()\n",
    "amino_acid_alphabet = get_all_amino_acids()\n",
    "amino_acid_wild_type = get_wild_type_amino_acid_sequence()\n",
    "one_hot_X_train = one_hot_encode(X_train[:args[\"num_data\"]], amino_acid_alphabet)\n",
    "one_hot_X_test = one_hot_encode(X_test[:args[\"num_data\"]], amino_acid_alphabet)\n",
    "y_train, y_test = y_train[:args[\"num_data\"]], y_test[:args[\"num_data\"]]\n",
    "train_dataset = TensorDataset(torch.from_numpy(one_hot_X_train).float(), torch.from_numpy(y_train.reshape(-1, 1)).float())\n",
    "test_dataset = TensorDataset(torch.from_numpy(one_hot_X_test).float(), torch.from_numpy(y_test.reshape(-1, 1)).float())\n",
    "train_loader, test_loader = DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True), DataLoader(test_dataset, batch_size=args[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====> Epoch: 1. Average loss: 73.8817. Reconstruction loss: 57.8083. KLD loss: 16.0734. Time: 1.07 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTAGKLPVPWPTLVTTLSYGVRCLSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAKVKFEGDTLVNLIELKGTDFIEDGNILGHKLVYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGQVLLPDNHYLSTQSALLKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 85.0\n",
      "wild type elbo prob: 9.28891372680664. 3 mutations elbo prob: 55.8896484375. 10 mutations elbo prob: 107.08012390136719.\n",
      "Test set loss: 35.1311 Average Mismatches: 6.3600 Wild Type Mismatches 2.5400 <====> \n",
      "\n",
      "<====> Epoch: 2. Average loss: 33.3592. Reconstruction loss: 27.0095. KLD loss: 6.3496. Time: 3.49 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHEFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLELDYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 28.2\n",
      "wild type elbo prob: 5.071998596191406. 3 mutations elbo prob: 47.85287094116211. 10 mutations elbo prob: 119.15614318847656.\n",
      "Test set loss: 30.2286 Average Mismatches: 10.0600 Wild Type Mismatches 6.6500 <====> \n",
      "\n",
      "<====> Epoch: 3. Average loss: 28.5232. Reconstruction loss: 25.7784. KLD loss: 2.7448. Time: 5.96 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHRFSVSGEGEGDATYGKLTLKFACLTGKLPVPWPTLVTALSNGMQCFGRYPDHMKQHVFFKSAKPKGYVQERTIFFKDDGNYKARAEVKFEGDTLVNRIELKGINFKEDGNILGHKLEYNYYSHNVYIMADKQKNGIKVYFKIRHNIEDGSVQLADHYQQNAPIGDGPVLLPDNHYLSTQSALSKGPDEKRDHMVLLEFVTASGITHGMDELCK*\n",
      "Average mismatches from the wild type: 17.3\n",
      "wild type elbo prob: 5.908998489379883. 3 mutations elbo prob: 44.99176788330078. 10 mutations elbo prob: 101.82112121582031.\n",
      "Test set loss: 27.8830 Average Mismatches: 8.1600 Wild Type Mismatches 4.6300 <====> \n",
      "\n",
      "<====> Epoch: 4. Average loss: 26.0835. Reconstruction loss: 24.7670. KLD loss: 1.3164. Time: 8.15 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPVLVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKRKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.7\n",
      "wild type elbo prob: 2.1052663326263428. 3 mutations elbo prob: 50.5575065612793. 10 mutations elbo prob: 103.57238006591797.\n",
      "Test set loss: 26.0514 Average Mismatches: 7.3500 Wild Type Mismatches 3.7900 <====> \n",
      "\n",
      "<====> Epoch: 5. Average loss: 24.3194. Reconstruction loss: 24.2023. KLD loss: 0.1171. Time: 10.56 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGH*LEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALGKDPNE*RDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.7\n",
      "wild type elbo prob: 2.5633838176727295. 3 mutations elbo prob: 49.97293472290039. 10 mutations elbo prob: 116.54669952392578.\n",
      "Test set loss: 25.3073 Average Mismatches: 6.9900 Wild Type Mismatches 3.4100 <====> \n",
      "\n",
      "<====> Epoch: 6. Average loss: 24.0045. Reconstruction loss: 23.9814. KLD loss: 0.0231. Time: 12.88 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGVVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKRKNGIKVNFKIRHNNEDGSVQLADHYQQNSPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.0\n",
      "wild type elbo prob: 4.324012756347656. 3 mutations elbo prob: 48.4144287109375. 10 mutations elbo prob: 111.41535186767578.\n",
      "Test set loss: 25.3545 Average Mismatches: 8.0800 Wild Type Mismatches 4.4700 <====> \n",
      "\n",
      "<====> Epoch: 7. Average loss: 23.9365. Reconstruction loss: 23.9183. KLD loss: 0.0183. Time: 15.48 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKLSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPALLPDDHYLSTQSALSKDPIEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.0\n",
      "wild type elbo prob: 3.239420175552368. 3 mutations elbo prob: 50.09583282470703. 10 mutations elbo prob: 112.63365936279297.\n",
      "Test set loss: 25.3908 Average Mismatches: 7.0100 Wild Type Mismatches 3.4000 <====> \n",
      "\n",
      "<====> Epoch: 8. Average loss: 23.9043. Reconstruction loss: 23.8843. KLD loss: 0.0199. Time: 18.44 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVEQDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQGFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMAVKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSTLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.3\n",
      "wild type elbo prob: 4.3731770515441895. 3 mutations elbo prob: 48.35371017456055. 10 mutations elbo prob: 117.70056915283203.\n",
      "Test set loss: 25.1713 Average Mismatches: 7.4500 Wild Type Mismatches 3.9700 <====> \n",
      "\n",
      "<====> Epoch: 9. Average loss: 23.8799. Reconstruction loss: 23.8526. KLD loss: 0.0273. Time: 21.11 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLRFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTILFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKPKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.3\n",
      "wild type elbo prob: 4.656295299530029. 3 mutations elbo prob: 45.9493522644043. 10 mutations elbo prob: 118.5692367553711.\n",
      "Test set loss: 25.2784 Average Mismatches: 7.6700 Wild Type Mismatches 3.7900 <====> \n",
      "\n",
      "<====> Epoch: 10. Average loss: 23.8081. Reconstruction loss: 23.7737. KLD loss: 0.0344. Time: 24.05 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGRLTLKFICSTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNFHIMADKQKNGIKVNFKVRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.6\n",
      "wild type elbo prob: 4.349225044250488. 3 mutations elbo prob: 53.854610443115234. 10 mutations elbo prob: 115.15830993652344.\n",
      "Test set loss: 25.2728 Average Mismatches: 7.7400 Wild Type Mismatches 4.2100 <====> \n",
      "\n",
      "<====> Epoch: 11. Average loss: 23.7903. Reconstruction loss: 23.7513. KLD loss: 0.0390. Time: 26.59 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKEDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKTRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.4\n",
      "wild type elbo prob: 3.459883213043213. 3 mutations elbo prob: 52.13649368286133. 10 mutations elbo prob: 119.81717681884766.\n",
      "Test set loss: 25.3575 Average Mismatches: 7.2200 Wild Type Mismatches 3.8300 <====> \n",
      "\n",
      "<====> Epoch: 12. Average loss: 23.8422. Reconstruction loss: 23.7934. KLD loss: 0.0487. Time: 29.31 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGGATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPDEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.7\n",
      "wild type elbo prob: 2.8165767192840576. 3 mutations elbo prob: 47.96063995361328. 10 mutations elbo prob: 122.35324096679688.\n",
      "Test set loss: 25.2147 Average Mismatches: 7.3900 Wild Type Mismatches 3.7700 <====> \n",
      "\n",
      "<====> Epoch: 13. Average loss: 23.8161. Reconstruction loss: 23.7538. KLD loss: 0.0623. Time: 32.51 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLEFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYRTRAEAKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 6.1\n",
      "wild type elbo prob: 4.567389011383057. 3 mutations elbo prob: 44.93288803100586. 10 mutations elbo prob: 121.37566375732422.\n",
      "Test set loss: 25.3499 Average Mismatches: 7.6600 Wild Type Mismatches 4.0200 <====> \n",
      "\n",
      "<====> Epoch: 14. Average loss: 23.8485. Reconstruction loss: 23.7743. KLD loss: 0.0742. Time: 35.10 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTPVTTLSYGVQCFSRYPDHTKQHDFFKSAVPEGYVQERTIFFKDDGYYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.5\n",
      "wild type elbo prob: 3.6974713802337646. 3 mutations elbo prob: 47.81153106689453. 10 mutations elbo prob: 131.35006713867188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 25.1463 Average Mismatches: 7.2700 Wild Type Mismatches 3.6900 <====> \n",
      "\n",
      "<====> Epoch: 15. Average loss: 23.8565. Reconstruction loss: 23.7537. KLD loss: 0.1028. Time: 37.44 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKISVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEGNYNSHNVYIMADKQKNGIKVNFEIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSRDPNEKRDHMVLLEFVTAAGITHGMGELYK*\n",
      "Average mismatches from the wild type: 4.6\n",
      "wild type elbo prob: 4.0385260581970215. 3 mutations elbo prob: 48.25996398925781. 10 mutations elbo prob: 125.40009307861328.\n",
      "Test set loss: 25.2295 Average Mismatches: 7.6800 Wild Type Mismatches 4.1100 <====> \n",
      "\n",
      "<====> Epoch: 16. Average loss: 23.7837. Reconstruction loss: 23.6572. KLD loss: 0.1265. Time: 40.12 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGEATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSATPEGYVQERAIFFKDDSNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKLKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.1\n",
      "wild type elbo prob: 4.3028764724731445. 3 mutations elbo prob: 47.810211181640625. 10 mutations elbo prob: 131.53146362304688.\n",
      "Test set loss: 25.2619 Average Mismatches: 7.8600 Wild Type Mismatches 4.1300 <====> \n",
      "\n",
      "<====> Epoch: 17. Average loss: 23.7250. Reconstruction loss: 23.5766. KLD loss: 0.1485. Time: 42.92 seconds\n",
      "Sample generated sequence: SKCEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWLTLVTTLSYGVQCFSRYPDHMRQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLSDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.6\n",
      "wild type elbo prob: 3.982697010040283. 3 mutations elbo prob: 51.30224609375. 10 mutations elbo prob: 128.5032196044922.\n",
      "Test set loss: 25.2012 Average Mismatches: 7.7000 Wild Type Mismatches 4.4300 <====> \n",
      "\n",
      "<====> Epoch: 18. Average loss: 23.6762. Reconstruction loss: 23.5014. KLD loss: 0.1748. Time: 45.81 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGGATYGKLTLKFICTTGKLPVPRPTLATTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTILFEDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKLKNGIKVNFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.6\n",
      "wild type elbo prob: 3.6162819862365723. 3 mutations elbo prob: 54.68100357055664. 10 mutations elbo prob: 129.58924865722656.\n",
      "Test set loss: 25.4791 Average Mismatches: 7.5000 Wild Type Mismatches 3.6600 <====> \n",
      "\n",
      "<====> Epoch: 19. Average loss: 23.7304. Reconstruction loss: 23.5370. KLD loss: 0.1935. Time: 48.88 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMGELYK*\n",
      "Average mismatches from the wild type: 2.7\n",
      "wild type elbo prob: 3.3570568561553955. 3 mutations elbo prob: 53.44215774536133. 10 mutations elbo prob: 121.26995086669922.\n",
      "Test set loss: 25.3379 Average Mismatches: 7.2800 Wild Type Mismatches 3.6600 <====> \n",
      "\n",
      "<====> Epoch: 20. Average loss: 23.7435. Reconstruction loss: 23.5180. KLD loss: 0.2255. Time: 51.74 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIVFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRRNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSIDPNEKRDHMVLLACVTAAGITHGTDEQYK*\n",
      "Average mismatches from the wild type: 4.0\n",
      "wild type elbo prob: 3.723428726196289. 3 mutations elbo prob: 46.37910079956055. 10 mutations elbo prob: 119.3782958984375.\n",
      "Test set loss: 25.4668 Average Mismatches: 7.2500 Wild Type Mismatches 3.4900 <====> \n",
      "\n",
      "<====> Epoch: 21. Average loss: 23.7648. Reconstruction loss: 23.5203. KLD loss: 0.2445. Time: 54.49 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTSLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLELVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.9\n",
      "wild type elbo prob: 3.604790449142456. 3 mutations elbo prob: 51.57673645019531. 10 mutations elbo prob: 125.7433853149414.\n",
      "Test set loss: 25.3357 Average Mismatches: 6.9700 Wild Type Mismatches 3.3100 <====> \n",
      "\n",
      "<====> Epoch: 22. Average loss: 23.7305. Reconstruction loss: 23.4845. KLD loss: 0.2460. Time: 57.20 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGRLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAIPEGYVQERTIFFKDDGNYKTRAEVKLEGVTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPANHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.7\n",
      "wild type elbo prob: 4.786020278930664. 3 mutations elbo prob: 51.6734733581543. 10 mutations elbo prob: 124.86592102050781.\n",
      "Test set loss: 25.3458 Average Mismatches: 7.6200 Wild Type Mismatches 4.1400 <====> \n",
      "\n",
      "<====> Epoch: 23. Average loss: 23.7330. Reconstruction loss: 23.4587. KLD loss: 0.2743. Time: 59.86 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRVELKGIDFKEDGNIPGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.2\n",
      "wild type elbo prob: 3.6618614196777344. 3 mutations elbo prob: 56.81057357788086. 10 mutations elbo prob: 116.46322631835938.\n",
      "Test set loss: 25.5050 Average Mismatches: 7.3700 Wild Type Mismatches 4.1400 <====> \n",
      "\n",
      "<====> Epoch: 24. Average loss: 23.6845. Reconstruction loss: 23.3966. KLD loss: 0.2879. Time: 62.15 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGRLPVPWPTLVTTLSYGVQCFSRYPDHMKQHVFFKSAMPEGYVQERPIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNLHNVYIMADKQKSGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDYHYLSTQSALSKDPNEKRDHMVLLEFATAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.3\n",
      "wild type elbo prob: 4.089189052581787. 3 mutations elbo prob: 47.256141662597656. 10 mutations elbo prob: 136.62269592285156.\n",
      "Test set loss: 25.5317 Average Mismatches: 8.0200 Wild Type Mismatches 4.1800 <====> \n",
      "\n",
      "<====> Epoch: 25. Average loss: 23.8006. Reconstruction loss: 23.4146. KLD loss: 0.3861. Time: 64.44 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFGVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSTMPEGYVQERTIFFKDDGNYKTRAEVKFEGNTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGVKVNLKIRHNIEDGSVQLADHYQQDTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.9\n",
      "wild type elbo prob: 5.246309757232666. 3 mutations elbo prob: 56.94076156616211. 10 mutations elbo prob: 142.79222106933594.\n",
      "Test set loss: 25.6277 Average Mismatches: 7.7700 Wild Type Mismatches 4.2600 <====> \n",
      "\n",
      "<====> Epoch: 26. Average loss: 23.7564. Reconstruction loss: 23.4138. KLD loss: 0.3426. Time: 67.10 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKQEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.5\n",
      "wild type elbo prob: 2.870638370513916. 3 mutations elbo prob: 56.90840148925781. 10 mutations elbo prob: 128.30284118652344.\n",
      "Test set loss: 25.8352 Average Mismatches: 6.8700 Wild Type Mismatches 3.2400 <====> \n",
      "\n",
      "<====> Epoch: 27. Average loss: 23.9766. Reconstruction loss: 23.5291. KLD loss: 0.4474. Time: 69.82 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDSLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.2\n",
      "wild type elbo prob: 4.959301471710205. 3 mutations elbo prob: 57.97523880004883. 10 mutations elbo prob: 140.21051025390625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 25.7748 Average Mismatches: 7.2600 Wild Type Mismatches 3.5300 <====> \n",
      "\n",
      "<====> Epoch: 28. Average loss: 23.8092. Reconstruction loss: 23.3999. KLD loss: 0.4092. Time: 72.40 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGGGDATYGKLTLKLICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNGHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.1\n",
      "wild type elbo prob: 3.777080535888672. 3 mutations elbo prob: 55.91792678833008. 10 mutations elbo prob: 138.76052856445312.\n",
      "Test set loss: 25.7151 Average Mismatches: 8.0300 Wild Type Mismatches 4.4600 <====> \n",
      "\n",
      "<====> Epoch: 29. Average loss: 23.6968. Reconstruction loss: 23.2949. KLD loss: 0.4019. Time: 74.98 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVSTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.8\n",
      "wild type elbo prob: 4.853668212890625. 3 mutations elbo prob: 52.592105865478516. 10 mutations elbo prob: 139.1445770263672.\n",
      "Test set loss: 25.4011 Average Mismatches: 7.5500 Wild Type Mismatches 3.9400 <====> \n",
      "\n",
      "<====> Epoch: 30. Average loss: 23.8660. Reconstruction loss: 23.3715. KLD loss: 0.4945. Time: 78.40 seconds\n",
      "Sample generated sequence: SKGEEQFTGVVPNLVELDGDVNGHKFSVSGEGEGDATHGKLTLKSICTTGKLPVPWPTPVPTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDSLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSEQPADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGSTHGMDELYK*\n",
      "Average mismatches from the wild type: 5.8\n",
      "wild type elbo prob: 4.874678611755371. 3 mutations elbo prob: 55.26004409790039. 10 mutations elbo prob: 149.14434814453125.\n",
      "Test set loss: 26.0970 Average Mismatches: 8.1700 Wild Type Mismatches 4.3800 <====> \n",
      "\n",
      "<====> Epoch: 31. Average loss: 23.8650. Reconstruction loss: 23.3533. KLD loss: 0.5118. Time: 81.00 seconds\n",
      "Sample generated sequence: SKGGELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTPKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDYFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIEPKGIDFKEDGNILGHKLEYNYNSHNVDIMADKQRDGIKVFFKIRHNIEDGSVQLADHYQQSTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.0\n",
      "wild type elbo prob: 5.802390098571777. 3 mutations elbo prob: 51.95356369018555. 10 mutations elbo prob: 140.4459991455078.\n",
      "Test set loss: 25.6680 Average Mismatches: 8.6900 Wild Type Mismatches 4.9500 <====> \n",
      "\n",
      "<====> Epoch: 32. Average loss: 23.7362. Reconstruction loss: 23.2322. KLD loss: 0.5040. Time: 85.25 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLRFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKYGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGVDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 3.9093880653381348. 3 mutations elbo prob: 54.3939323425293. 10 mutations elbo prob: 124.7204360961914.\n",
      "Test set loss: 25.5510 Average Mismatches: 7.7400 Wild Type Mismatches 3.9500 <====> \n",
      "\n",
      "<====> Epoch: 33. Average loss: 23.6565. Reconstruction loss: 23.1093. KLD loss: 0.5472. Time: 88.15 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKLICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADEQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVPLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.2\n",
      "wild type elbo prob: 4.594817161560059. 3 mutations elbo prob: 58.94900131225586. 10 mutations elbo prob: 142.3428955078125.\n",
      "Test set loss: 25.9064 Average Mismatches: 7.6600 Wild Type Mismatches 3.9500 <====> \n",
      "\n",
      "<====> Epoch: 34. Average loss: 23.8450. Reconstruction loss: 23.2794. KLD loss: 0.5657. Time: 90.96 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSDEGEGDATYGKLTLKFICTTGKLPMPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKLKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.8\n",
      "wild type elbo prob: 3.7027599811553955. 3 mutations elbo prob: 58.399593353271484. 10 mutations elbo prob: 128.70216369628906.\n",
      "Test set loss: 25.8038 Average Mismatches: 6.9900 Wild Type Mismatches 3.3300 <====> \n",
      "\n",
      "<====> Epoch: 35. Average loss: 23.8732. Reconstruction loss: 23.2344. KLD loss: 0.6388. Time: 93.68 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.9\n",
      "wild type elbo prob: 2.7323386669158936. 3 mutations elbo prob: 54.953880310058594. 10 mutations elbo prob: 143.9630584716797.\n",
      "Test set loss: 25.9576 Average Mismatches: 7.1000 Wild Type Mismatches 3.4400 <====> \n",
      "\n",
      "<====> Epoch: 36. Average loss: 23.7251. Reconstruction loss: 23.0719. KLD loss: 0.6531. Time: 96.76 seconds\n",
      "Sample generated sequence: SKGEELSTGVVPILVELDGDVNGRKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKQEYNYNSHNVYIMADKQKNGTKVNFKIRHNFEDGSVQPADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.6\n",
      "wild type elbo prob: 4.733374118804932. 3 mutations elbo prob: 52.51013946533203. 10 mutations elbo prob: 132.14219665527344.\n",
      "Test set loss: 26.0143 Average Mismatches: 7.6900 Wild Type Mismatches 4.0300 <====> \n",
      "\n",
      "<====> Epoch: 37. Average loss: 23.7663. Reconstruction loss: 23.0593. KLD loss: 0.7070. Time: 99.86 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVHIMADKQKNGIKGNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYRSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.5\n",
      "wild type elbo prob: 3.7621426582336426. 3 mutations elbo prob: 54.222816467285156. 10 mutations elbo prob: 142.138916015625.\n",
      "Test set loss: 26.0937 Average Mismatches: 7.9700 Wild Type Mismatches 4.1800 <====> \n",
      "\n",
      "<====> Epoch: 38. Average loss: 23.8708. Reconstruction loss: 23.1302. KLD loss: 0.7406. Time: 102.58 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFSCTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAVPEGYVQERTTFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNDYIMAGKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLGTQSALSKDPYEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.1\n",
      "wild type elbo prob: 3.411682367324829. 3 mutations elbo prob: 58.30880355834961. 10 mutations elbo prob: 138.39666748046875.\n",
      "Test set loss: 26.2041 Average Mismatches: 7.2100 Wild Type Mismatches 3.3400 <====> \n",
      "\n",
      "<====> Epoch: 39. Average loss: 23.7634. Reconstruction loss: 22.9851. KLD loss: 0.7783. Time: 105.17 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPVGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNCNSHNVYIMADKQKNGIKVNFKIRHNNEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEIVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.2\n",
      "wild type elbo prob: 4.090701580047607. 3 mutations elbo prob: 59.20526885986328. 10 mutations elbo prob: 157.18853759765625.\n",
      "Test set loss: 25.9931 Average Mismatches: 7.0500 Wild Type Mismatches 3.4300 <====> \n",
      "\n",
      "<====> Epoch: 40. Average loss: 23.6192. Reconstruction loss: 22.8221. KLD loss: 0.7971. Time: 107.72 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVFIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDHHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.4\n",
      "wild type elbo prob: 3.911933660507202. 3 mutations elbo prob: 60.59833908081055. 10 mutations elbo prob: 145.95639038085938.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 25.7449 Average Mismatches: 6.7300 Wild Type Mismatches 2.9300 <====> \n",
      "\n",
      "<====> Epoch: 41. Average loss: 23.6911. Reconstruction loss: 22.8886. KLD loss: 0.8025. Time: 110.94 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVLCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.4\n",
      "wild type elbo prob: 3.831681489944458. 3 mutations elbo prob: 59.21205139160156. 10 mutations elbo prob: 150.0297088623047.\n",
      "Test set loss: 25.7949 Average Mismatches: 7.7500 Wild Type Mismatches 3.9400 <====> \n",
      "\n",
      "<====> Epoch: 42. Average loss: 23.6035. Reconstruction loss: 22.8301. KLD loss: 0.7734. Time: 113.86 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNIYIMADKQKNSIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLRPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDEQYK*\n",
      "Average mismatches from the wild type: 3.5\n",
      "wild type elbo prob: 4.064934253692627. 3 mutations elbo prob: 63.4459342956543. 10 mutations elbo prob: 134.33517456054688.\n",
      "Test set loss: 26.1604 Average Mismatches: 8.0400 Wild Type Mismatches 4.5100 <====> \n",
      "\n",
      "<====> Epoch: 43. Average loss: 23.7160. Reconstruction loss: 22.8741. KLD loss: 0.8419. Time: 116.50 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPDGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPDEKRDHMVLLEFVTAAGITHGMDELCK*\n",
      "Average mismatches from the wild type: 3.3\n",
      "wild type elbo prob: 3.5203757286071777. 3 mutations elbo prob: 66.81957244873047. 10 mutations elbo prob: 142.4278106689453.\n",
      "Test set loss: 26.1385 Average Mismatches: 7.0800 Wild Type Mismatches 3.2700 <====> \n",
      "\n",
      "<====> Epoch: 44. Average loss: 23.7877. Reconstruction loss: 22.8986. KLD loss: 0.8891. Time: 119.17 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKGDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.4\n",
      "wild type elbo prob: 3.477918863296509. 3 mutations elbo prob: 62.35408020019531. 10 mutations elbo prob: 150.33717346191406.\n",
      "Test set loss: 26.0139 Average Mismatches: 6.6800 Wild Type Mismatches 3.0300 <====> \n",
      "\n",
      "<====> Epoch: 45. Average loss: 23.5949. Reconstruction loss: 22.7403. KLD loss: 0.8547. Time: 121.90 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILAELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDRMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKANFKIRHNIEDGSVQLADHYQRNAPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHTVLLEFGTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.2\n",
      "wild type elbo prob: 3.820829391479492. 3 mutations elbo prob: 58.80535888671875. 10 mutations elbo prob: 145.3868408203125.\n",
      "Test set loss: 26.2356 Average Mismatches: 7.5000 Wild Type Mismatches 3.9800 <====> \n",
      "\n",
      "<====> Epoch: 46. Average loss: 23.8917. Reconstruction loss: 23.0027. KLD loss: 0.8890. Time: 124.65 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSRDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.8\n",
      "wild type elbo prob: 3.512953519821167. 3 mutations elbo prob: 65.7051773071289. 10 mutations elbo prob: 150.9009246826172.\n",
      "Test set loss: 25.9972 Average Mismatches: 7.7600 Wild Type Mismatches 3.6000 <====> \n",
      "\n",
      "<====> Epoch: 47. Average loss: 23.7819. Reconstruction loss: 22.9463. KLD loss: 0.8356. Time: 127.36 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPTLVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGAKVNFKIRHNIEDGSVQLADHYQQNTPFGDGPVRLPDNHYLSTQSALSKDPNEKRDHMVLLGFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.5\n",
      "wild type elbo prob: 3.093341588973999. 3 mutations elbo prob: 62.16330337524414. 10 mutations elbo prob: 150.1139373779297.\n",
      "Test set loss: 26.0194 Average Mismatches: 6.9200 Wild Type Mismatches 3.3100 <====> \n",
      "\n",
      "<====> Epoch: 48. Average loss: 23.7325. Reconstruction loss: 22.9405. KLD loss: 0.7920. Time: 130.10 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFYKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYVMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.1\n",
      "wild type elbo prob: 3.290011405944824. 3 mutations elbo prob: 63.59705352783203. 10 mutations elbo prob: 163.15538024902344.\n",
      "Test set loss: 26.0268 Average Mismatches: 7.4600 Wild Type Mismatches 3.5900 <====> \n",
      "\n",
      "<====> Epoch: 49. Average loss: 23.6026. Reconstruction loss: 22.7581. KLD loss: 0.8445. Time: 132.87 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHDVYIMADKQKNGIKVNYKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 4.539863586425781. 3 mutations elbo prob: 64.04255676269531. 10 mutations elbo prob: 152.70701599121094.\n",
      "Test set loss: 26.0248 Average Mismatches: 7.6200 Wild Type Mismatches 3.9100 <====> \n",
      "\n",
      "<====> Epoch: 50. Average loss: 23.8078. Reconstruction loss: 22.9056. KLD loss: 0.9023. Time: 135.78 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFFCTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDSLKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSNNDYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 6.2\n",
      "wild type elbo prob: 5.9429779052734375. 3 mutations elbo prob: 66.25952911376953. 10 mutations elbo prob: 139.7319793701172.\n",
      "Test set loss: 26.3208 Average Mismatches: 7.9100 Wild Type Mismatches 3.8500 <====> \n",
      "\n",
      "<====> Epoch: 51. Average loss: 23.6637. Reconstruction loss: 22.7966. KLD loss: 0.8671. Time: 138.49 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTQKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIYFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLAGHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.7\n",
      "wild type elbo prob: 6.352006435394287. 3 mutations elbo prob: 61.64075469970703. 10 mutations elbo prob: 141.3544158935547.\n",
      "Test set loss: 26.0572 Average Mismatches: 8.3400 Wild Type Mismatches 4.3900 <====> \n",
      "\n",
      "<====> Epoch: 52. Average loss: 23.5949. Reconstruction loss: 22.7126. KLD loss: 0.8823. Time: 141.11 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLPEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.3\n",
      "wild type elbo prob: 4.10181999206543. 3 mutations elbo prob: 61.19455337524414. 10 mutations elbo prob: 146.90673828125.\n",
      "Test set loss: 26.4816 Average Mismatches: 7.7700 Wild Type Mismatches 4.2200 <====> \n",
      "\n",
      "<====> Epoch: 53. Average loss: 23.6154. Reconstruction loss: 22.5529. KLD loss: 1.0625. Time: 143.74 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFRDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADERKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGFTHGMDELYK*\n",
      "Average mismatches from the wild type: 3.9\n",
      "wild type elbo prob: 6.272387504577637. 3 mutations elbo prob: 63.73701095581055. 10 mutations elbo prob: 147.2935791015625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 26.4156 Average Mismatches: 7.1600 Wild Type Mismatches 3.7200 <====> \n",
      "\n",
      "<====> Epoch: 54. Average loss: 23.6493. Reconstruction loss: 22.6369. KLD loss: 1.0124. Time: 146.45 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVEPDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.2\n",
      "wild type elbo prob: 3.9399216175079346. 3 mutations elbo prob: 61.01233673095703. 10 mutations elbo prob: 128.1796875.\n",
      "Test set loss: 26.1277 Average Mismatches: 7.8000 Wild Type Mismatches 3.8600 <====> \n",
      "\n",
      "<====> Epoch: 55. Average loss: 23.7194. Reconstruction loss: 22.6970. KLD loss: 1.0224. Time: 149.49 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTPSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVRLPDNHYLSTQSALSKDPNERRDHMVLLEFVTAAGITQGMDELYK*\n",
      "Average mismatches from the wild type: 4.5\n",
      "wild type elbo prob: 3.891166925430298. 3 mutations elbo prob: 55.28847885131836. 10 mutations elbo prob: 150.5682373046875.\n",
      "Test set loss: 26.0941 Average Mismatches: 6.9700 Wild Type Mismatches 3.5200 <====> \n",
      "\n",
      "<====> Epoch: 56. Average loss: 23.6951. Reconstruction loss: 22.5886. KLD loss: 1.1065. Time: 152.22 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVLERTIFFKDDGNYKTRAEVRFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYYSHNVYIMADKQKNGIKVSFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.5\n",
      "wild type elbo prob: 3.647749662399292. 3 mutations elbo prob: 61.92552185058594. 10 mutations elbo prob: 154.44309997558594.\n",
      "Test set loss: 26.3709 Average Mismatches: 7.4100 Wild Type Mismatches 3.5300 <====> \n",
      "\n",
      "<====> Epoch: 57. Average loss: 23.5341. Reconstruction loss: 22.4663. KLD loss: 1.0678. Time: 154.87 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGRLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDLFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 3.711422920227051. 3 mutations elbo prob: 61.96560287475586. 10 mutations elbo prob: 145.22752380371094.\n",
      "Test set loss: 26.5991 Average Mismatches: 7.7400 Wild Type Mismatches 3.8900 <====> \n",
      "\n",
      "<====> Epoch: 58. Average loss: 23.5375. Reconstruction loss: 22.4623. KLD loss: 1.0752. Time: 157.67 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPGGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFEEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.7\n",
      "wild type elbo prob: 4.1283159255981445. 3 mutations elbo prob: 61.98468017578125. 10 mutations elbo prob: 137.8082733154297.\n",
      "Test set loss: 26.5678 Average Mismatches: 6.7200 Wild Type Mismatches 3.3100 <====> \n",
      "\n",
      "<====> Epoch: 59. Average loss: 23.6697. Reconstruction loss: 22.5213. KLD loss: 1.1483. Time: 160.55 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKYSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFCRYPDHVKQHDFFKSAMPEGCVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEGGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALGKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.5\n",
      "wild type elbo prob: 3.6496973037719727. 3 mutations elbo prob: 56.94750213623047. 10 mutations elbo prob: 137.79795837402344.\n",
      "Test set loss: 26.4553 Average Mismatches: 7.6900 Wild Type Mismatches 4.0800 <====> \n",
      "\n",
      "<====> Epoch: 60. Average loss: 23.4693. Reconstruction loss: 22.4315. KLD loss: 1.0378. Time: 163.40 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATHGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSEDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 3.851017951965332. 3 mutations elbo prob: 65.35789489746094. 10 mutations elbo prob: 155.80746459960938.\n",
      "Test set loss: 26.4921 Average Mismatches: 6.9800 Wild Type Mismatches 3.1300 <====> \n",
      "\n",
      "<====> Epoch: 61. Average loss: 23.5991. Reconstruction loss: 22.3334. KLD loss: 1.2657. Time: 166.36 seconds\n",
      "Sample generated sequence: SKSEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVLERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYDSHYVYIMADKQKNGIKANFKIRHNIEDGSEQLADHHQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDEPYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 4.453730583190918. 3 mutations elbo prob: 60.86991500854492. 10 mutations elbo prob: 137.6669921875.\n",
      "Test set loss: 26.8803 Average Mismatches: 7.4100 Wild Type Mismatches 3.8100 <====> \n",
      "\n",
      "<====> Epoch: 62. Average loss: 23.5279. Reconstruction loss: 22.3394. KLD loss: 1.1884. Time: 169.30 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTSLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGSYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNAYIMADKQKNGIKVNFKIRHNNEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGVAHGMDELYK*\n",
      "Average mismatches from the wild type: 5.2\n",
      "wild type elbo prob: 5.11555290222168. 3 mutations elbo prob: 59.370670318603516. 10 mutations elbo prob: 160.27975463867188.\n",
      "Test set loss: 26.6656 Average Mismatches: 7.2200 Wild Type Mismatches 3.8700 <====> \n",
      "\n",
      "<====> Epoch: 63. Average loss: 23.3282. Reconstruction loss: 22.1476. KLD loss: 1.1806. Time: 172.19 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIEPKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQYTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.0\n",
      "wild type elbo prob: 3.460773229598999. 3 mutations elbo prob: 67.6226806640625. 10 mutations elbo prob: 154.49061584472656.\n",
      "Test set loss: 26.2770 Average Mismatches: 6.7200 Wild Type Mismatches 3.0000 <====> \n",
      "\n",
      "<====> Epoch: 64. Average loss: 23.5485. Reconstruction loss: 22.3041. KLD loss: 1.2444. Time: 175.08 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELEGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVDFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.8\n",
      "wild type elbo prob: 4.8584489822387695. 3 mutations elbo prob: 68.64373016357422. 10 mutations elbo prob: 154.53875732421875.\n",
      "Test set loss: 26.6538 Average Mismatches: 6.9300 Wild Type Mismatches 3.0800 <====> \n",
      "\n",
      "<====> Epoch: 65. Average loss: 23.6830. Reconstruction loss: 22.4493. KLD loss: 1.2337. Time: 178.11 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPIQVELDGDVNGHKFSVSGEGVGDATYGKLTLKFICTTGKLPVPWPTLVTTLSFGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTCAEVKFEGDTLVNRIELKGIDFKEDGNTLGHKLEYNYNSHNVYIMADKQKNGIKVNFQIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKGPNEKRDHMVLLEFVTAAGITLGMDELYK*\n",
      "Average mismatches from the wild type: 4.2\n",
      "wild type elbo prob: 3.6198489665985107. 3 mutations elbo prob: 63.28134536743164. 10 mutations elbo prob: 161.13571166992188.\n",
      "Test set loss: 26.4436 Average Mismatches: 7.6600 Wild Type Mismatches 3.9500 <====> \n",
      "\n",
      "<====> Epoch: 66. Average loss: 23.5036. Reconstruction loss: 22.2082. KLD loss: 1.2954. Time: 181.04 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLALKFICTTGKLPVPWPTLVTTLSYGVQCFTRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVEFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIRVNFKIRHNIGDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKREHMVLLEFVTAAGITHGMGELYK*\n",
      "Average mismatches from the wild type: 4.6\n",
      "wild type elbo prob: 3.483664035797119. 3 mutations elbo prob: 61.074180603027344. 10 mutations elbo prob: 155.0093536376953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 26.6104 Average Mismatches: 7.2000 Wild Type Mismatches 3.4600 <====> \n",
      "\n",
      "<====> Epoch: 67. Average loss: 23.4920. Reconstruction loss: 22.2254. KLD loss: 1.2665. Time: 183.98 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVTGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGTDELYK*\n",
      "Average mismatches from the wild type: 4.4\n",
      "wild type elbo prob: 3.754868745803833. 3 mutations elbo prob: 62.79379653930664. 10 mutations elbo prob: 148.32440185546875.\n",
      "Test set loss: 26.7533 Average Mismatches: 7.1000 Wild Type Mismatches 3.2800 <====> \n",
      "\n",
      "<====> Epoch: 68. Average loss: 23.4941. Reconstruction loss: 22.1540. KLD loss: 1.3401. Time: 186.99 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCLSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDYKEDGNILGHKLEYNNNSHNFYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQRNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.0\n",
      "wild type elbo prob: 4.293770790100098. 3 mutations elbo prob: 56.128597259521484. 10 mutations elbo prob: 170.90090942382812.\n",
      "Test set loss: 26.8887 Average Mismatches: 7.5100 Wild Type Mismatches 3.7600 <====> \n",
      "\n",
      "<====> Epoch: 69. Average loss: 23.5235. Reconstruction loss: 22.2273. KLD loss: 1.2962. Time: 189.41 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDYKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGTTHGMDELYK*\n",
      "Average mismatches from the wild type: 3.4\n",
      "wild type elbo prob: 3.4840941429138184. 3 mutations elbo prob: 67.82199096679688. 10 mutations elbo prob: 156.01637268066406.\n",
      "Test set loss: 26.4792 Average Mismatches: 6.8900 Wild Type Mismatches 3.2300 <====> \n",
      "\n",
      "<====> Epoch: 70. Average loss: 23.4637. Reconstruction loss: 22.1761. KLD loss: 1.2876. Time: 191.83 seconds\n",
      "Sample generated sequence: SKGEELFTVVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNAPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.8\n",
      "wild type elbo prob: 4.158506870269775. 3 mutations elbo prob: 72.77432250976562. 10 mutations elbo prob: 163.74998474121094.\n",
      "Test set loss: 26.5291 Average Mismatches: 7.0800 Wild Type Mismatches 3.8600 <====> \n",
      "\n",
      "<====> Epoch: 71. Average loss: 23.2927. Reconstruction loss: 21.9748. KLD loss: 1.3179. Time: 194.76 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.9\n",
      "wild type elbo prob: 4.92126989364624. 3 mutations elbo prob: 69.37393951416016. 10 mutations elbo prob: 151.6128692626953.\n",
      "Test set loss: 27.0123 Average Mismatches: 7.1400 Wild Type Mismatches 3.3800 <====> \n",
      "\n",
      "<====> Epoch: 72. Average loss: 23.5838. Reconstruction loss: 22.1568. KLD loss: 1.4270. Time: 198.29 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTILFKGDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 3.4169769287109375. 3 mutations elbo prob: 67.8554458618164. 10 mutations elbo prob: 151.73667907714844.\n",
      "Test set loss: 26.8754 Average Mismatches: 7.0900 Wild Type Mismatches 3.3900 <====> \n",
      "\n",
      "<====> Epoch: 73. Average loss: 23.3912. Reconstruction loss: 22.0265. KLD loss: 1.3647. Time: 202.01 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVGLDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCSSRYPDHMRQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNTEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.3\n",
      "wild type elbo prob: 3.63956356048584. 3 mutations elbo prob: 64.66709899902344. 10 mutations elbo prob: 170.63221740722656.\n",
      "Test set loss: 26.7884 Average Mismatches: 7.9600 Wild Type Mismatches 3.9900 <====> \n",
      "\n",
      "<====> Epoch: 74. Average loss: 23.4196. Reconstruction loss: 22.0525. KLD loss: 1.3670. Time: 204.99 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHHLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.0\n",
      "wild type elbo prob: 4.370842933654785. 3 mutations elbo prob: 66.6270980834961. 10 mutations elbo prob: 176.86441040039062.\n",
      "Test set loss: 26.5506 Average Mismatches: 7.1500 Wild Type Mismatches 3.4600 <====> \n",
      "\n",
      "<====> Epoch: 75. Average loss: 23.4275. Reconstruction loss: 22.0046. KLD loss: 1.4228. Time: 207.63 seconds\n",
      "Sample generated sequence: SMGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPMPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQECTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDVLYK*\n",
      "Average mismatches from the wild type: 2.7\n",
      "wild type elbo prob: 3.4000601768493652. 3 mutations elbo prob: 68.0330810546875. 10 mutations elbo prob: 151.27853393554688.\n",
      "Test set loss: 26.3270 Average Mismatches: 7.0400 Wild Type Mismatches 3.2300 <====> \n",
      "\n",
      "<====> Epoch: 76. Average loss: 23.3031. Reconstruction loss: 21.9187. KLD loss: 1.3845. Time: 210.15 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRFPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPALLLDNHYLSTQSALSKDPNEERDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.8\n",
      "wild type elbo prob: 4.510151386260986. 3 mutations elbo prob: 72.50736236572266. 10 mutations elbo prob: 152.3066864013672.\n",
      "Test set loss: 26.9132 Average Mismatches: 8.0400 Wild Type Mismatches 4.4400 <====> \n",
      "\n",
      "<====> Epoch: 77. Average loss: 23.4894. Reconstruction loss: 22.0408. KLD loss: 1.4485. Time: 212.87 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYRTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.2\n",
      "wild type elbo prob: 3.895723819732666. 3 mutations elbo prob: 62.94390869140625. 10 mutations elbo prob: 162.82339477539062.\n",
      "Test set loss: 26.4737 Average Mismatches: 7.6500 Wild Type Mismatches 3.6200 <====> \n",
      "\n",
      "<====> Epoch: 78. Average loss: 23.2425. Reconstruction loss: 21.9694. KLD loss: 1.2731. Time: 215.61 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPMGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHIIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLCTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 3.9086556434631348. 3 mutations elbo prob: 70.33516693115234. 10 mutations elbo prob: 156.5741729736328.\n",
      "Test set loss: 26.6459 Average Mismatches: 8.0400 Wild Type Mismatches 4.0700 <====> \n",
      "\n",
      "<====> Epoch: 79. Average loss: 23.1994. Reconstruction loss: 21.7934. KLD loss: 1.4060. Time: 218.23 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGNDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHHLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.3\n",
      "wild type elbo prob: 3.9421629905700684. 3 mutations elbo prob: 74.25557708740234. 10 mutations elbo prob: 152.0438232421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 26.6296 Average Mismatches: 6.7400 Wild Type Mismatches 3.4000 <====> \n",
      "\n",
      "<====> Epoch: 80. Average loss: 23.3836. Reconstruction loss: 21.8843. KLD loss: 1.4993. Time: 220.80 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVGLDGDVNGHKFSVSGEGEGDATYGKLTLRFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQECTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLGYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.8\n",
      "wild type elbo prob: 4.036979675292969. 3 mutations elbo prob: 75.64786529541016. 10 mutations elbo prob: 161.32662963867188.\n",
      "Test set loss: 26.6734 Average Mismatches: 7.1200 Wild Type Mismatches 3.3000 <====> \n",
      "\n",
      "<====> Epoch: 81. Average loss: 23.4513. Reconstruction loss: 21.9319. KLD loss: 1.5194. Time: 223.52 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIKLKGIDFKEDGYILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQHADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.8\n",
      "wild type elbo prob: 3.7774903774261475. 3 mutations elbo prob: 80.1411361694336. 10 mutations elbo prob: 158.7156219482422.\n",
      "Test set loss: 26.6309 Average Mismatches: 7.3700 Wild Type Mismatches 3.7500 <====> \n",
      "\n",
      "<====> Epoch: 82. Average loss: 23.3558. Reconstruction loss: 22.0238. KLD loss: 1.3320. Time: 226.21 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTPSYGVQCFSRYPDHMRQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIEPKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNSKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.5\n",
      "wild type elbo prob: 3.8148927688598633. 3 mutations elbo prob: 62.92423629760742. 10 mutations elbo prob: 162.74786376953125.\n",
      "Test set loss: 27.3051 Average Mismatches: 7.5700 Wild Type Mismatches 3.6900 <====> \n",
      "\n",
      "<====> Epoch: 83. Average loss: 23.2173. Reconstruction loss: 21.8003. KLD loss: 1.4170. Time: 228.90 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKGDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLANHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.9\n",
      "wild type elbo prob: 4.885744571685791. 3 mutations elbo prob: 72.02873992919922. 10 mutations elbo prob: 163.0187530517578.\n",
      "Test set loss: 26.9389 Average Mismatches: 7.7000 Wild Type Mismatches 3.7800 <====> \n",
      "\n",
      "<====> Epoch: 84. Average loss: 23.2196. Reconstruction loss: 21.8428. KLD loss: 1.3768. Time: 231.51 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVLERTIFFKDDGNYKTRAEVKFEGDTLVNRIKLKGIDFKGDGNILGHKREYNYNSHNVYIMADKQKNGIRVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.4\n",
      "wild type elbo prob: 5.363620281219482. 3 mutations elbo prob: 66.33536529541016. 10 mutations elbo prob: 159.3770751953125.\n",
      "Test set loss: 26.5337 Average Mismatches: 6.9100 Wild Type Mismatches 3.5500 <====> \n",
      "\n",
      "<====> Epoch: 85. Average loss: 23.2239. Reconstruction loss: 21.8008. KLD loss: 1.4232. Time: 233.93 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHVFFKSAMPEGYVQERTIFFKDGGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPTGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVSAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.6\n",
      "wild type elbo prob: 4.441314697265625. 3 mutations elbo prob: 59.07759094238281. 10 mutations elbo prob: 149.0371551513672.\n",
      "Test set loss: 26.8858 Average Mismatches: 6.8400 Wild Type Mismatches 3.3300 <====> \n",
      "\n",
      "<====> Epoch: 86. Average loss: 23.3663. Reconstruction loss: 21.8169. KLD loss: 1.5495. Time: 236.50 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMREGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNHNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHTVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.5\n",
      "wild type elbo prob: 4.162743091583252. 3 mutations elbo prob: 69.84838104248047. 10 mutations elbo prob: 164.08004760742188.\n",
      "Test set loss: 27.0701 Average Mismatches: 7.7100 Wild Type Mismatches 3.9300 <====> \n",
      "\n",
      "<====> Epoch: 87. Average loss: 23.3674. Reconstruction loss: 21.9184. KLD loss: 1.4490. Time: 239.21 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPTLVELDGDVNGHKFGVSGEGEGDATYGKLSLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.9\n",
      "wild type elbo prob: 4.181730270385742. 3 mutations elbo prob: 70.77161407470703. 10 mutations elbo prob: 168.20419311523438.\n",
      "Test set loss: 26.6955 Average Mismatches: 7.6900 Wild Type Mismatches 4.2300 <====> \n",
      "\n",
      "<====> Epoch: 88. Average loss: 23.3270. Reconstruction loss: 21.7738. KLD loss: 1.5532. Time: 242.31 seconds\n",
      "Sample generated sequence: SKGEGLFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKDDGNILGHKLEYNYNSHNVYIMADKQKNGIKVDFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.5\n",
      "wild type elbo prob: 4.051512718200684. 3 mutations elbo prob: 69.7686996459961. 10 mutations elbo prob: 157.59576416015625.\n",
      "Test set loss: 26.8559 Average Mismatches: 7.5400 Wild Type Mismatches 3.8100 <====> \n",
      "\n",
      "<====> Epoch: 89. Average loss: 23.2752. Reconstruction loss: 21.7614. KLD loss: 1.5138. Time: 245.10 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKSSVSGEGEGDATYGKLTLKFICTTGKLPVPWPSLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSRNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.3\n",
      "wild type elbo prob: 4.1485161781311035. 3 mutations elbo prob: 83.11884307861328. 10 mutations elbo prob: 172.25559997558594.\n",
      "Test set loss: 27.5407 Average Mismatches: 7.7900 Wild Type Mismatches 4.1800 <====> \n",
      "\n",
      "<====> Epoch: 90. Average loss: 23.4037. Reconstruction loss: 21.7099. KLD loss: 1.6938. Time: 248.18 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIYFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSRNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFATAAGITHGVDELYK*\n",
      "Average mismatches from the wild type: 3.8\n",
      "wild type elbo prob: 4.335397243499756. 3 mutations elbo prob: 65.66612243652344. 10 mutations elbo prob: 176.52561950683594.\n",
      "Test set loss: 28.2027 Average Mismatches: 6.6900 Wild Type Mismatches 3.0800 <====> \n",
      "\n",
      "<====> Epoch: 91. Average loss: 23.3873. Reconstruction loss: 21.7943. KLD loss: 1.5931. Time: 252.55 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKSEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHDIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.5\n",
      "wild type elbo prob: 3.976835012435913. 3 mutations elbo prob: 73.2385025024414. 10 mutations elbo prob: 172.63165283203125.\n",
      "Test set loss: 26.8334 Average Mismatches: 7.2100 Wild Type Mismatches 3.3600 <====> \n",
      "\n",
      "<====> Epoch: 92. Average loss: 23.4473. Reconstruction loss: 21.8472. KLD loss: 1.6000. Time: 255.23 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDAAYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFYKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIVADKQKNGIKVNFKIRHDIEDGSAQLADHYQQNTPIGDGPVLLPDNHYLSTQSAPSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 2.8\n",
      "wild type elbo prob: 3.4317007064819336. 3 mutations elbo prob: 73.30036926269531. 10 mutations elbo prob: 159.06573486328125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 26.8521 Average Mismatches: 7.0200 Wild Type Mismatches 3.3600 <====> \n",
      "\n",
      "<====> Epoch: 93. Average loss: 23.1643. Reconstruction loss: 21.8351. KLD loss: 1.3292. Time: 257.97 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGNKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSAPSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 5.0\n",
      "wild type elbo prob: 3.9945504665374756. 3 mutations elbo prob: 74.71515655517578. 10 mutations elbo prob: 165.08116149902344.\n",
      "Test set loss: 26.9286 Average Mismatches: 7.3500 Wild Type Mismatches 3.7100 <====> \n",
      "\n",
      "<====> Epoch: 94. Average loss: 23.1581. Reconstruction loss: 21.8292. KLD loss: 1.3289. Time: 260.81 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFRDDGNYKTRAEVKFEGDTLVYRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHHQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTVAGITHGMDERYK*\n",
      "Average mismatches from the wild type: 3.3\n",
      "wild type elbo prob: 3.83847713470459. 3 mutations elbo prob: 62.37131118774414. 10 mutations elbo prob: 174.14013671875.\n",
      "Test set loss: 26.7938 Average Mismatches: 7.2300 Wild Type Mismatches 3.4900 <====> \n",
      "\n",
      "<====> Epoch: 95. Average loss: 23.2103. Reconstruction loss: 21.8411. KLD loss: 1.3693. Time: 264.49 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAIPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKKDGNILGHKLEYNYNSHNVYIMADKRRNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNLYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.7\n",
      "wild type elbo prob: 3.4104886054992676. 3 mutations elbo prob: 60.04467010498047. 10 mutations elbo prob: 165.7623291015625.\n",
      "Test set loss: 27.0288 Average Mismatches: 7.2900 Wild Type Mismatches 3.5700 <====> \n",
      "\n",
      "<====> Epoch: 96. Average loss: 23.1614. Reconstruction loss: 21.7537. KLD loss: 1.4077. Time: 267.65 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPFLVELDGDVNGHKFSVSGEGEGDATYGKLTPKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIKLKGIDFKEDGNILGHKLEYNYNSHNVYIVADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.7\n",
      "wild type elbo prob: 4.515517711639404. 3 mutations elbo prob: 64.0812759399414. 10 mutations elbo prob: 158.2915496826172.\n",
      "Test set loss: 27.0545 Average Mismatches: 6.7000 Wild Type Mismatches 3.1700 <====> \n",
      "\n",
      "<====> Epoch: 97. Average loss: 23.4347. Reconstruction loss: 21.9257. KLD loss: 1.5090. Time: 270.44 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSTMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFMIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.0\n",
      "wild type elbo prob: 5.300043106079102. 3 mutations elbo prob: 67.7776107788086. 10 mutations elbo prob: 162.10488891601562.\n",
      "Test set loss: 26.7028 Average Mismatches: 7.6000 Wild Type Mismatches 3.8600 <====> \n",
      "\n",
      "<====> Epoch: 98. Average loss: 23.2745. Reconstruction loss: 21.7960. KLD loss: 1.4785. Time: 273.79 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGELPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLQPDNHYLSTQSALSKDPNEKRDHMVLLEFETAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 4.2\n",
      "wild type elbo prob: 3.7339415550231934. 3 mutations elbo prob: 78.8657455444336. 10 mutations elbo prob: 171.1561737060547.\n",
      "Test set loss: 27.0196 Average Mismatches: 7.1800 Wild Type Mismatches 3.3400 <====> \n",
      "\n",
      "<====> Epoch: 99. Average loss: 23.1947. Reconstruction loss: 21.6975. KLD loss: 1.4973. Time: 276.94 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDAAYGKLTLKFICTTGKLPVPWPSLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.1\n",
      "wild type elbo prob: 5.301534175872803. 3 mutations elbo prob: 64.72650909423828. 10 mutations elbo prob: 174.8242645263672.\n",
      "Test set loss: 26.8214 Average Mismatches: 7.3000 Wild Type Mismatches 3.6100 <====> \n",
      "\n",
      "<====> Epoch: 100. Average loss: 23.1145. Reconstruction loss: 21.6555. KLD loss: 1.4590. Time: 280.38 seconds\n",
      "Sample generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTL*FICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADRQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*\n",
      "Average mismatches from the wild type: 3.5\n",
      "wild type elbo prob: 3.896742105484009. 3 mutations elbo prob: 73.78618621826172. 10 mutations elbo prob: 171.0060272216797.\n",
      "Test set loss: 26.9519 Average Mismatches: 6.9000 Wild Type Mismatches 3.4300 <====> \n",
      "\n",
      "finished saving model\n"
     ]
    }
   ],
   "source": [
    "vae = GenerativeVAE(args)\n",
    "logger = None\n",
    "vae.fit(train_loader, test_loader, True, logger, \"./models/{0}/\".format(vae.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Format '1_training_history' is not supported (supported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a9d493f139b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./logs/vae/{0}_model_architecture\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./logs/vae/{0}_training_history\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-29f3a706f862>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(self, save_fig_dir)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_fig_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_fig_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   2033\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m         \u001b[0;31m# get canvas object and print method for format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2173\u001b[0;31m         \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_canvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2174\u001b[0m         \u001b[0mprint_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'print_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         raise ValueError(\n\u001b[1;32m   2104\u001b[0m             \u001b[0;34m\"Format {!r} is not supported (supported formats: {})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m             .format(fmt, \", \".join(sorted(self.get_supported_filetypes()))))\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m     def print_figure(self, filename, dpi=None, facecolor=None, edgecolor=None,\n",
      "\u001b[0;31mValueError\u001b[0m: Format '1_training_history' is not supported (supported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae.plot_model(\"./logs/vae/{0}_model_architecture\".format(vae.name))\n",
    "vae.plot_history(\"./logs/vae/{0}_training_history\".format(vae.name))\n",
    "vae.show_model(logger)\n",
    "if logger: \n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vae = GenerativeVAE(args)\n",
    "load_vae.load_model(\"./models/{0}/checkpoint_1000.pt\".format(vae.name))\n",
    "for parameter_name, load_weights in load_vae.model.state_dict().items():\n",
    "    vae_weights = vae.model.state_dict()[parameter_name]\n",
    "    assert(torch.all(torch.eq(load_weights, vae_weights)).item())\n",
    "\n",
    "for (x, _) in test_loader:         \n",
    "    x = x.to(load_vae.device)\n",
    "    z, z_mean, z_var = load_vae.encoder(x, reparameterize=True)\n",
    "    z_mean_2, z_var_2 = vae.encoder(x)\n",
    "    assert(torch.all(torch.eq(z_mean, z_mean_2)).item())\n",
    "    assert(torch.all(torch.eq(z_var, z_var_2)).item())\n",
    "    recon_x = load_vae.decoder(z)\n",
    "    recon_x_2 = vae.decoder(z)\n",
    "    loss_1 = vae.elbo_loss(recon_x, x, z_mean, z_var).item()\n",
    "    loss_2 = vae.elbo_loss(recon_x_2, x, z_mean, z_var).item()\n",
    "    np.testing.assert_equal(loss_1, loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 238, 21)\n",
      "finished 0/1000 samples\n",
      "finished 100/1000 samples\n",
      "finished 200/1000 samples\n",
      "finished 300/1000 samples\n",
      "finished 400/1000 samples\n",
      "finished 500/1000 samples\n",
      "finished 600/1000 samples\n",
      "finished 700/1000 samples\n",
      "finished 800/1000 samples\n",
      "finished 900/1000 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "vocabulary = get_all_amino_acids()\n",
    "num_characters = len(get_all_amino_acids())\n",
    "index_to_character = dict(zip(range(num_characters), vocabulary))\n",
    "\n",
    "z = np.random.sample((num_samples, 20))\n",
    "outputs = vae.model.decode(torch.tensor(z).float())\n",
    "outputs = outputs.view(outputs.shape[0], -1, num_characters)\n",
    "outputs = F.softmax(outputs, dim=2)\n",
    "outputs = outputs.detach().numpy()\n",
    "print(outputs.shape)\n",
    "mismatches, all_strings = [], []\n",
    "for i in range(outputs.shape[0]):\n",
    "    string = []\n",
    "    for j in range(outputs.shape[1]):\n",
    "        k = np.random.choice(list(range(num_characters)), p = outputs[i, j])\n",
    "        string.append(index_to_character[k])\n",
    "    all_strings.append(\"\".join(string))\n",
    "    mismatches.append(count_substring_mismatch(wild_type, all_strings[-1]))\n",
    "    if i % 100 == 0:\n",
    "        print(\"finished {0}/{1} samples\".format(i, num_samples))\n",
    "        \n",
    "plt.title(\"number of mismatches\")\n",
    "plt.hist(mismatches, bins=15)\n",
    "plt.xlabel(\"mismatches\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.savefig(\"./logs/vae/{0}_mismatches_from_wild_type\".format(vae.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'counts')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_mismatches = []\n",
    "for amino_acid_seq in X_train[0:1000]:\n",
    "    data_mismatches.append(count_substring_mismatch(amino_acid_seq, wild_type))\n",
    "plt.title(\"number of mismatches\")\n",
    "plt.hist(data_mismatches, bins = 15)\n",
    "plt.xlabel(\"mismatches\")\n",
    "plt.ylabel(\"counts\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "if logger:\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(784, 400, 20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'logs/vae/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    \n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(description='VAE MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.epochs = 2\n",
    "        self.no_cuda = True\n",
    "        self.seed = 1\n",
    "        self.log_interval = 10\n",
    "        \n",
    "\n",
    "args = Args()\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_index(string, alphabet):\n",
    "    return np.array([alphabet.index(s) for s in string])\n",
    "\n",
    "wild_type_index = string_to_index(get_wild_type_amino_acid_sequence(), alphabet = get_all_amino_acids())\n",
    "wild_type_index_tensor = torch.from_numpy(wild_type_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0822, 0.0137, 0.0320, 0.0091, 0.0639, 0.0776, 0.0046, 0.0502, 0.0776,\n",
      "         0.0913, 0.0594, 0.0137, 0.0000, 0.0868, 0.0228, 0.0320, 0.0411, 0.0548,\n",
      "         0.0411, 0.0776, 0.0685]], dtype=torch.float64) tensor([1.0000, 1.0000], dtype=torch.float64)\n",
      "tensor([1.0000, 0.9087], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "normalized_prob = np.random.randint(0, 21, 21)\n",
    "normalized_prob = normalized_prob / normalized_prob.sum()\n",
    "x = torch.tensor([[0] * 15 + [1] + [0] * 5, normalized_prob])\n",
    "wild_type_probs = []\n",
    "for probs, index in zip(x, wild_type_index):\n",
    "    wild_type_probs.append(probs[index])\n",
    "\n",
    "sums = x.sum(dim = 1)\n",
    "print(x, sums)\n",
    "sums = sums - torch.tensor(wild_type_probs)\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(2, 3, 4, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4653, -1.0134,  0.0671, -2.0208, -0.0811],\n",
      "        [-0.5681,  1.4572,  1.2459, -0.1435,  0.7575],\n",
      "        [ 0.2731, -2.1939,  0.1123, -0.6824,  0.4075]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 5)\n",
    "print(x)\n",
    "x.argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 210])\n",
      "torch.Size([2, 10])\n",
      "tensor([-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08,  1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08], dtype=torch.float64)\n",
      "torch.Size([2, 21, 10])\n",
      "tensor([-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08,  1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08], dtype=torch.float64)\n",
      "tensor([ 1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-69d7a6fefe51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_amino_acids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_amino_acids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m             ret = torch._C._nn.nll_loss2d(\n\u001b[0;32m-> 1806\u001b[0;31m                 input, target, weight, reduction_enum, ignore_index)\n\u001b[0m\u001b[1;32m   1807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m             out = torch._C._nn.nll_loss2d(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "length = 10\n",
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "one_hot = one_hot_encode([wild_type[0:length], wild_type[0:length]], get_all_amino_acids())\n",
    "for i in range(one_hot.shape[0]): \n",
    "    for j in range(one_hot.shape[1]): \n",
    "        if not one_hot[i, j]:\n",
    "            one_hot[i, j] = eps\n",
    "        else:\n",
    "            one_hot[i, j] = 1\n",
    "            \n",
    "one_hot_tensor = torch.from_numpy(one_hot)\n",
    "print(one_hot_tensor.shape)\n",
    "labels = one_hot_tensor.view(2, length, len(get_all_amino_acids())).argmax(dim = 2).float()\n",
    "print(labels.shape)\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids()))[0][0])\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1).shape)\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)[0, :, 0])\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)[0, 16])\n",
    "x = one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)\n",
    "z = nn.CrossEntropyLoss(reduction='sum')(x, labels).item()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = -1e8\n",
    "x = torch.tensor(np.array([[1, eps, eps], [eps, 1, eps]])).float()\n",
    "labels = torch.tensor(np.array([0, 1]))\n",
    "print(torch.all(torch.eq(x.argmax(1), labels)).item() == 1)\n",
    "F.cross_entropy(x, labels, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 63)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x if x else eps for x in one_hot[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1489, -1.4456, -3.2613, -3.3038, -0.5574],\n",
       "         [-2.2018, -1.3564, -1.8980, -0.8716, -2.7541],\n",
       "         [-1.0349, -1.3823, -1.8581, -3.3522, -1.5958]],\n",
       "\n",
       "        [[-1.8522, -3.5563, -0.7642, -3.0691, -1.1961],\n",
       "         [-2.2367, -2.4859, -0.9454, -2.5285, -1.0740],\n",
       "         [-1.3448, -2.4309, -1.0460, -2.8123, -1.4270]],\n",
       "\n",
       "        [[-3.8434, -0.5309, -2.8926, -2.6222, -1.3378],\n",
       "         [-2.8145, -2.0604, -0.9137, -1.0996, -2.5432],\n",
       "         [-0.4621, -2.3404, -2.8733, -2.2319, -2.2081]]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1489, -1.4456, -3.2613, -3.3038, -0.5574],\n",
       "         [-2.2018, -1.3564, -1.8980, -0.8716, -2.7541],\n",
       "         [-1.0349, -1.3823, -1.8581, -3.3522, -1.5958]],\n",
       "\n",
       "        [[-1.8522, -3.5563, -0.7642, -3.0691, -1.1961],\n",
       "         [-2.2367, -2.4859, -0.9454, -2.5285, -1.0740],\n",
       "         [-1.3448, -2.4309, -1.0460, -2.8123, -1.4270]],\n",
       "\n",
       "        [[-3.8434, -0.5309, -2.8926, -2.6222, -1.3378],\n",
       "         [-2.8145, -2.0604, -0.9137, -1.0996, -2.5432],\n",
       "         [-0.4621, -2.3404, -2.8733, -2.2319, -2.2081]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = F.log_softmax(x, dim=2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3, 3, 5)\n",
    "x[:, :, 4] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6936)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(z * x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4, 5).permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
