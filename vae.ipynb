{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchviz import make_dot\n",
    "from utils import one_hot_encode, one_hot_decode, get_all_amino_acids, get_wild_type_amino_acid_sequence\n",
    "from utils import load_gfp_data, count_substring_mismatch, get_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    # change architecture later to make it deeper if it's not good enough to capture all data\n",
    "    def __init__(self, input_size, hidden_size, latent_dim, num_characters):\n",
    "        super(VAE, self).__init__() \n",
    "        self.num_characters = num_characters\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc21 = nn.Linear(hidden_size, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_size, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
    "        self.fc5 = nn.Linear(self.num_characters, self.num_characters)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # input should be one hot encoded. shape - (batch_size, alphabet x sequence_length)\n",
    "        h1 = F.elu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z, softmax=False):\n",
    "        batch_size = z.shape[0]\n",
    "        h3 = F.elu(self.fc3(z))\n",
    "        h4 = F.elu(self.fc4(h3)).view(batch_size, -1, self.num_characters) ## may need to add RELU here. \n",
    "        #F.elu(self.fc4(h3)).view(batch_size, -1, self.num_characters)\n",
    "        h5 = self.fc5(h4)\n",
    "        if softmax:\n",
    "            return F.softmax(h5, dim=2)\n",
    "        else:\n",
    "            return h5\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.input_size))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, softmax=False), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeVAE(): \n",
    "    \n",
    "    def __init__(self, args):     \n",
    "        \"\"\"\n",
    "        Initializes the VAE to be a generative VAE\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dictionary\n",
    "            defines the hyper-parameters of the neural network\n",
    "        args.name : string \n",
    "            defines the name of the neural network\n",
    "        args.description: string\n",
    "            describes the architecture of the neural network\n",
    "        args.input : int\n",
    "            the size of the input\n",
    "        args.hidden_size : int\n",
    "            the size of the hidden layer\n",
    "        args.latent_dim: int \n",
    "            the size of the latent dimension\n",
    "        args.device : device\n",
    "            the device used: cpu or gpu\n",
    "        args.learning_rate : float\n",
    "            sets the learning rate\n",
    "        args.epochs : int \n",
    "            sets the epoch size \n",
    "        args.beta : float\n",
    "            sets the beta parameter for the KL divergence loss\n",
    "        args.vocabulary : string\n",
    "            all the characters in the context of the problem\n",
    "        \"\"\"\n",
    "        self.name = args[\"name\"]\n",
    "        self.description = args[\"description\"]\n",
    "        self.input = args[\"input\"]\n",
    "        self.hidden_size = args[\"hidden_size\"]\n",
    "        self.latent_dim = args[\"latent_dim\"]\n",
    "        self.device = args[\"device\"]\n",
    "        self.learning_rate = args[\"learning_rate\"]\n",
    "        self.epochs = args[\"epochs\"]\n",
    "        self.beta = args[\"beta\"]\n",
    "        self.all_characters = args[\"vocabulary\"]\n",
    "        self.num_characters = len(self.all_characters)\n",
    "        self.character_to_int = dict(zip(self.all_characters, range(self.num_characters)))\n",
    "        self.int_to_character = dict(zip(range(self.num_characters), self.all_characters))\n",
    "        self.model = VAE(self.input, self.hidden_size, self.latent_dim, self.num_characters)\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.train_loss_history = []\n",
    "        self.test_loss_history = []\n",
    "        \n",
    "    # Reconstruction + KL divergence losses summed over all elements in batch\n",
    "    def elbo_loss(self, recon_x, x, mu, logvar):\n",
    "        \"\"\"\n",
    "        Input: x is the one hot encoded batch_size x (seq_length * len(all_characters)) \n",
    "               recon_x is the unormalized outputs of the decoder in the same shape as x\n",
    "               mu and logvar are the hidden states of size self.hidden_size\n",
    "        Output: elbo_loss\n",
    "        \"\"\"\n",
    "        # get the argmax of each batch_size x seq_length * len(all_characters) matrix. Output is in batch_size x seq_length form\n",
    "        # print(labels)\n",
    "        # reshapes the recon_x vector to be of shape batch_size x len(all_characters) x seq_length so that it fits according to PyTorch's CrossEntropyLoss\n",
    "        # permute is transpose function so at each 1, 2 dimension we take the transpose\n",
    "        # print(recon_x.shape)\n",
    "        # print(reshape_x[0,:,0])\n",
    "        outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        CE = (-1 * outputs * x.view(x.shape[0], -1, len(self.all_characters))).sum()\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        #print(\"log var shape:\", logvar.shape, \"mu shape: \", mu.shape, \"logvar: \", logvar.sum(dim=1))\n",
    "        #print(\"mu: \", mu.sum(dim=1))\n",
    "        #print((1 + logvar - mu.pow(2) - logvar.exp()).shape)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        #print(\"CE Loss: \", CE, \"KLD Loss:\", KLD, file=logger)\n",
    "        return CE + KLD\n",
    "    \n",
    "    def NLLoss(self, recon_x, x): \n",
    "        outputs = F.log_softmax(recon_x, dim = 2)\n",
    "        return (-1 * outputs * x.view(x.shape[0], -1, len(self.all_characters))).sum()\n",
    "    \n",
    "    def KLD(self, mu, logvar): \n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    def fit(self, train_dataloader, test_dataloader=None, verbose=True, logger=None, save_model=True):\n",
    "        # amino acid dataset specific checks\n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        three_mutation = get_mutation(wild_type, num_mutations=3, alphabet=self.all_characters)\n",
    "        ten_mutation = get_mutation(wild_type, num_mutations=10, alphabet=self.all_characters)\n",
    "        \n",
    "        if not os.path.isdir(\"./models/{0}\".format(self.name)):\n",
    "            os.mkdir(\"./models/{0}\".format(self.name))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.train_loss_history, self.test_loss_history = [], []\n",
    "        self.reconstruction_loss_history, self.kld_loss_history = [], []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            #train model\n",
    "            self.model.train()\n",
    "            train_loss, reconstruction_loss, kld_loss = 0, 0, 0\n",
    "            for batch_idx, (x, _) in enumerate(train_dataloader):\n",
    "                x = x.to(self.device)\n",
    "                #labels = x.view(x.shape[0], -1, len(self.all_characters)).argmax(dim = 2)\n",
    "                self.optimizer.zero_grad()\n",
    "                recon_x, mu, logvar = self.model(x)\n",
    "                rloss, kloss = self.NLLoss(recon_x, x), self.KLD(mu, logvar)\n",
    "                loss = rloss + kloss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                reconstruction_loss += rloss.item()\n",
    "                kld_loss += kloss.item()\n",
    "            self.train_loss_history.append(train_loss / len(train_dataloader.dataset))\n",
    "            self.reconstruction_loss_history.append(reconstruction_loss / len(train_dataloader.dataset))\n",
    "            self.kld_loss_history.append(kld_loss / len(train_dataloader.dataset))\n",
    "            #evaluate model\n",
    "            self.model.eval()\n",
    "            decoder_outputs, _ = self.sample(num_samples=10, softmax=True)\n",
    "            generated_sequences = [self.sample_tensor_to_string(tensor, softmax=False) for tensor in decoder_outputs]\n",
    "            mismatches = [count_substring_mismatch(wild_type, sequence) for sequence in generated_sequences]\n",
    "            wild_prob, mutation_three_prob, mutation_ten_prob = self.predict_elbo_prob([wild_type]), self.predict_elbo_prob([three_mutation]), self.predict_elbo_prob([ten_mutation])\n",
    "            \n",
    "            if verbose: \n",
    "                print('<====> Epoch: {0}. Average loss: {1:.4f}. Reconstruction loss: {2:.2f}. KLD loss: {3:.2f}. Time: {4:.2f} seconds'.format(\n",
    "                      epoch, self.train_loss_history[-1], self.reconstruction_loss_history[-1], self.kld_loss_history[-1], time.time() - start_time), file = logger)\n",
    "                print(\"Sample generated sequence: {0}\\nAverage mismatches from the wild type: {1}\".format(generated_sequences[0], np.mean(mismatches)), file = logger) \n",
    "                print(\"wild type elbo prob: {0}. 3 mutations elbo prob: {1}. 10 mutations elbo prob: {2}.\" \\\n",
    "                      .format(wild_prob, mutation_three_prob, mutation_ten_prob), file = logger)\n",
    "            if test_dataloader:\n",
    "                test_loss = self.evaluate(test_dataloader, verbose, logger)\n",
    "                self.test_loss_history.append(test_loss)\n",
    "            if epoch % 100 == 0 and save_model:\n",
    "                self.save_model(epoch, train_loss)\n",
    "                print(\"finished saving model\", file=logger)\n",
    "     \n",
    "    def sample_tensor_to_string(self, x, softmax=False):\n",
    "        assert(type(x) == torch.Tensor)\n",
    "        assert(x.shape[0] % self.num_characters == 0 or x.shape[1] % self.num_characters == 0)\n",
    "        x = x.reshape(-1, self.num_characters)\n",
    "        if softmax:\n",
    "            x = F.softmax(x, dim=1)\n",
    "        string = []\n",
    "        for dist in x: \n",
    "            index = torch.multinomial(dist, 1).item()\n",
    "            string.append(self.int_to_character[index])\n",
    "        return \"\".join(string)\n",
    "    \n",
    "    def tensor_to_string(self, x):\n",
    "        \"\"\"\n",
    "        Input: A sequence in tensor format\n",
    "        Output: A sequence in string format\n",
    "        Example: tensor_to_string(torch.tensor([0, 0, 1, 0, 0, 0, 1, 0])) = \"TT\"\n",
    "        tensor_to_string(torch.tensor([0.8, 0.15, 0.05, 0, 0, 0.9, 0.1, 0])) = \"AC\"\n",
    "        note: alphabet is \"ACTG\" in this example\n",
    "        \"\"\"\n",
    "        assert(type(x) == torch.Tensor)\n",
    "        assert(len(x) % self.num_characters == 0)\n",
    "        x = x.reshape(-1, self.num_characters)\n",
    "        _, index = x.max(dim = 1)\n",
    "        return \"\".join([self.int_to_character[i] for i in index.numpy()])\n",
    "        \n",
    "    def predict_elbo_prob(self, sequences, string=True):\n",
    "        \"\"\"\n",
    "        Input: list of sequences in string or one_hot_encoded form\n",
    "        Output: list of the elbo probability for each sequence\n",
    "        Example: predict_elbo_prob([\"ACT\", \"ACG\"]) = [0.2, 0.75]\n",
    "        predict_elbo_prob([[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],  \n",
    "                        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]]) = [0.2, 0.75]\n",
    "        note: alphabet in this example is ACTG and the wild type is probably ACG***\n",
    "        \"\"\"\n",
    "        if string: \n",
    "            sequences = one_hot_encode(sequences, self.all_characters)\n",
    "        if type(sequences) != torch.Tensor:\n",
    "            x = self.to_tensor(sequences)\n",
    "        recon_x, mu, logvar = self.model(x)\n",
    "        return self.elbo_loss(recon_x, x, mu, logvar)\n",
    "    \n",
    "    def evaluate(self, dataloader, verbose=True, logger=None):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        mismatches = []\n",
    "        wild_type_mismatches, wild_type = [], get_wild_type_amino_acid_sequence()\n",
    "        with torch.no_grad():\n",
    "            for i, (x, _) in enumerate(dataloader):\n",
    "                x = x.to(self.device)\n",
    "                recon_x, mu, logvar = self.model(x)\n",
    "                test_loss += self.elbo_loss(recon_x, x, mu, logvar).item()\n",
    "                recon_str, x_str = self.sample_tensor_to_string(recon_x[0], softmax=True), self.tensor_to_string(x[0])\n",
    "                mismatches.append(count_substring_mismatch(x_str, recon_str))\n",
    "                wild_type_mismatches.append(count_substring_mismatch(wild_type, recon_str))\n",
    "        test_loss /= len(dataloader.dataset)\n",
    "        if verbose: \n",
    "            print('Test set loss: {0:.4f} Average Mismatches: {1:.4f} Wild Type Mismatches {2:.4f} <====> \\n'.format(test_loss, np.mean(mismatches), np.mean(wild_type_mismatches)), file=logger)\n",
    "        return test_loss\n",
    "    \n",
    "    def to_tensor(self, x): \n",
    "        assert(type(x) == np.ndarray)\n",
    "        return torch.from_numpy(x).float().to(self.device)\n",
    "    \n",
    "    def decoder(self, z, softmax=False):\n",
    "        \"\"\" Note that the outputs are unnormalized \"\"\"\n",
    "        assert(z.shape[1] == self.latent_dim)\n",
    "        if type(z) != torch.Tensor:\n",
    "            z = self.to_tensor(z)\n",
    "        return self.model.decode(z, softmax=softmax)\n",
    "    \n",
    "    def encoder(self, x, reparameterize=False): \n",
    "        assert(x.shape[1] == self.input)\n",
    "        if type(x) != torch.Tensor:\n",
    "            x = self.to_tensor(x)\n",
    "        mu, log_var = self.model.encode(x)\n",
    "        if reparameterize: \n",
    "            return self.model.reparameterize(mu, log_var), mu, log_var\n",
    "        else: \n",
    "            return mu, log_var\n",
    "        \n",
    "    def sample(self, num_samples = 1, z = None, softmax=True): \n",
    "        if z is None: \n",
    "            z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "        return self.decoder(z, softmax=softmax), z\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    def save_model(self, epoch=None, loss=None): \n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': loss,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                }, \"./models/{0}/checkpoint_{1}.pt\".format(self.name, epoch))\n",
    "\n",
    "    def show_model(self, logger=None): \n",
    "        print(self.model, file=logger)\n",
    "    \n",
    "    def plot_model(self, save_dir, verbose=False): \n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        one_hot_wild_type = one_hot_encode([wild_type], self.all_characters)\n",
    "        one_hot_tensor_wild_type = self.to_tensor(one_hot_wild_type)\n",
    "        out, _, _ = self.model(one_hot_tensor_wild_type)\n",
    "        graph = make_dot(out)\n",
    "        if save_dir is not None:\n",
    "            graph.format = \"png\"\n",
    "            graph.render(save_dir) \n",
    "        if verbose:\n",
    "            graph.view()\n",
    "            \n",
    "    def print_vars(self):\n",
    "        print(self.__dict__)\n",
    "        \n",
    "    def plot_history(self, save_fig_dir): \n",
    "        plt.figure()\n",
    "        plt.title(\"{0} Training Loss Curve\".format(self.name))\n",
    "        plt.plot(self.train_loss_history, label=\"train\")\n",
    "        if \"test_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.test_loss_history, label=\"validation\")\n",
    "        if \"reconstruction_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.reconstruction_loss_history, label=\"reconstruction_loss\")\n",
    "        if \"kld_loss_history\" in self.__dict__:\n",
    "            plt.plot(self.kld_loss_history, label=\"kld_loss\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        if save_fig_dir:\n",
    "            plt.savefig(save_fig_dir)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_args():\n",
    "    args = {\n",
    "        \"name\" : \"vae_fc5_epochs_1000\",\n",
    "        \"input\" : 21 * 238, \n",
    "        \"hidden_size\" : 50,\n",
    "        \"latent_dim\" : 20,\n",
    "        \"device\" : torch.device(\"cpu\"),\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"epochs\" : 1000,\n",
    "        \"beta\" : 1.0,\n",
    "        \"vocabulary\" : get_all_amino_acids(),\n",
    "        \"num_data\" : 1000, \n",
    "        \"batch_size\" : 10\n",
    "    }\n",
    "    args[\"description\"] = \"name: {0}, input size {1}, hidden size {2}, latent_dim {3}, lr {4}, epochs {5}\".format(\n",
    "                args[\"name\"], args[\"input\"], args[\"hidden_size\"], args[\"latent_dim\"], args[\"learning_rate\"], args[\"epochs\"])\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_shuffle_\")\n",
    "args = get_test_args()\n",
    "amino_acid_alphabet = get_all_amino_acids()\n",
    "amino_acid_wild_type = get_wild_type_amino_acid_sequence()\n",
    "one_hot_X_train = one_hot_encode(X_train[:args[\"num_data\"]], amino_acid_alphabet)\n",
    "one_hot_X_test = one_hot_encode(X_test[:args[\"num_data\"]], amino_acid_alphabet)\n",
    "y_train, y_test = y_train[:args[\"num_data\"]], y_test[:args[\"num_data\"]]\n",
    "train_dataset = TensorDataset(torch.from_numpy(one_hot_X_train).float(), torch.from_numpy(y_train.reshape(-1, 1)).float())\n",
    "test_dataset = TensorDataset(torch.from_numpy(one_hot_X_test).float(), torch.from_numpy(y_test.reshape(-1, 1)).float())\n",
    "train_loader, test_loader = DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True), DataLoader(test_dataset, batch_size=args[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = GenerativeVAE(args)\n",
    "logger = open(\"./logs/vae/{0}.txt\".format(vae.name), 'w')\n",
    "vae.fit(train_loader, test_loader, True, logger, \"./models/{0}/\".format(vae.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae.plot_model(\"./logs/vae/{0}_model_architecture\".format(vae.name))\n",
    "vae.plot_history(\"./logs/vae/{0}_training_history\".format(vae.name))\n",
    "vae.show_model(logger)\n",
    "if logger: \n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vae = GenerativeVAE(args)\n",
    "load_vae.load_model(\"./models/{0}/checkpoint_1000.pt\".format(vae.name))\n",
    "for parameter_name, load_weights in load_vae.model.state_dict().items():\n",
    "    vae_weights = vae.model.state_dict()[parameter_name]\n",
    "    assert(torch.all(torch.eq(load_weights, vae_weights)).item())\n",
    "\n",
    "for (x, _) in test_loader:         \n",
    "    x = x.to(load_vae.device)\n",
    "    z, z_mean, z_var = load_vae.encoder(x, reparameterize=True)\n",
    "    z_mean_2, z_var_2 = vae.encoder(x)\n",
    "    assert(torch.all(torch.eq(z_mean, z_mean_2)).item())\n",
    "    assert(torch.all(torch.eq(z_var, z_var_2)).item())\n",
    "    recon_x = load_vae.decoder(z)\n",
    "    recon_x_2 = vae.decoder(z)\n",
    "    loss_1 = vae.elbo_loss(recon_x, x, z_mean, z_var).item()\n",
    "    loss_2 = vae.elbo_loss(recon_x_2, x, z_mean, z_var).item()\n",
    "    np.testing.assert_equal(loss_1, loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 238, 21)\n",
      "finished 0/1000 samples\n",
      "finished 100/1000 samples\n",
      "finished 200/1000 samples\n",
      "finished 300/1000 samples\n",
      "finished 400/1000 samples\n",
      "finished 500/1000 samples\n",
      "finished 600/1000 samples\n",
      "finished 700/1000 samples\n",
      "finished 800/1000 samples\n",
      "finished 900/1000 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "vocabulary = get_all_amino_acids()\n",
    "num_characters = len(get_all_amino_acids())\n",
    "index_to_character = dict(zip(range(num_characters), vocabulary))\n",
    "\n",
    "z = np.random.sample((num_samples, 20))\n",
    "outputs = vae.model.decode(torch.tensor(z).float())\n",
    "outputs = outputs.view(outputs.shape[0], -1, num_characters)\n",
    "outputs = F.softmax(outputs, dim=2)\n",
    "outputs = outputs.detach().numpy()\n",
    "print(outputs.shape)\n",
    "mismatches, all_strings = [], []\n",
    "for i in range(outputs.shape[0]):\n",
    "    string = []\n",
    "    for j in range(outputs.shape[1]):\n",
    "        k = np.random.choice(list(range(num_characters)), p = outputs[i, j])\n",
    "        string.append(index_to_character[k])\n",
    "    all_strings.append(\"\".join(string))\n",
    "    mismatches.append(count_substring_mismatch(wild_type, all_strings[-1]))\n",
    "    if i % 100 == 0:\n",
    "        print(\"finished {0}/{1} samples\".format(i, num_samples))\n",
    "        \n",
    "plt.title(\"number of mismatches\")\n",
    "plt.hist(mismatches, bins=15)\n",
    "plt.xlabel(\"mismatches\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.savefig(\"./logs/vae/{0}_mismatches_from_wild_type\".format(vae.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'counts')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_mismatches = []\n",
    "for amino_acid_seq in X_train[0:1000]:\n",
    "    data_mismatches.append(count_substring_mismatch(amino_acid_seq, wild_type))\n",
    "plt.title(\"number of mismatches\")\n",
    "plt.hist(data_mismatches, bins = 15)\n",
    "plt.xlabel(\"mismatches\")\n",
    "plt.ylabel(\"counts\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "if logger:\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(784, 400, 20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'logs/vae/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    \n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(description='VAE MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.epochs = 2\n",
    "        self.no_cuda = True\n",
    "        self.seed = 1\n",
    "        self.log_interval = 10\n",
    "        \n",
    "\n",
    "args = Args()\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_index(string, alphabet):\n",
    "    return np.array([alphabet.index(s) for s in string])\n",
    "\n",
    "wild_type_index = string_to_index(get_wild_type_amino_acid_sequence(), alphabet = get_all_amino_acids())\n",
    "wild_type_index_tensor = torch.from_numpy(wild_type_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0822, 0.0137, 0.0320, 0.0091, 0.0639, 0.0776, 0.0046, 0.0502, 0.0776,\n",
      "         0.0913, 0.0594, 0.0137, 0.0000, 0.0868, 0.0228, 0.0320, 0.0411, 0.0548,\n",
      "         0.0411, 0.0776, 0.0685]], dtype=torch.float64) tensor([1.0000, 1.0000], dtype=torch.float64)\n",
      "tensor([1.0000, 0.9087], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "normalized_prob = np.random.randint(0, 21, 21)\n",
    "normalized_prob = normalized_prob / normalized_prob.sum()\n",
    "x = torch.tensor([[0] * 15 + [1] + [0] * 5, normalized_prob])\n",
    "wild_type_probs = []\n",
    "for probs, index in zip(x, wild_type_index):\n",
    "    wild_type_probs.append(probs[index])\n",
    "\n",
    "sums = x.sum(dim = 1)\n",
    "print(x, sums)\n",
    "sums = sums - torch.tensor(wild_type_probs)\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(2, 3, 4, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4653, -1.0134,  0.0671, -2.0208, -0.0811],\n",
      "        [-0.5681,  1.4572,  1.2459, -0.1435,  0.7575],\n",
      "        [ 0.2731, -2.1939,  0.1123, -0.6824,  0.4075]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 5)\n",
    "print(x)\n",
    "x.argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 210])\n",
      "torch.Size([2, 10])\n",
      "tensor([-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08,  1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08], dtype=torch.float64)\n",
      "torch.Size([2, 21, 10])\n",
      "tensor([-1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08,  1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08], dtype=torch.float64)\n",
      "tensor([ 1.0000e+00, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08,\n",
      "        -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08, -1.0000e+08],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-69d7a6fefe51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_amino_acids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_all_amino_acids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m             ret = torch._C._nn.nll_loss2d(\n\u001b[0;32m-> 1806\u001b[0;31m                 input, target, weight, reduction_enum, ignore_index)\n\u001b[0m\u001b[1;32m   1807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m             out = torch._C._nn.nll_loss2d(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "length = 10\n",
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "one_hot = one_hot_encode([wild_type[0:length], wild_type[0:length]], get_all_amino_acids())\n",
    "for i in range(one_hot.shape[0]): \n",
    "    for j in range(one_hot.shape[1]): \n",
    "        if not one_hot[i, j]:\n",
    "            one_hot[i, j] = eps\n",
    "        else:\n",
    "            one_hot[i, j] = 1\n",
    "            \n",
    "one_hot_tensor = torch.from_numpy(one_hot)\n",
    "print(one_hot_tensor.shape)\n",
    "labels = one_hot_tensor.view(2, length, len(get_all_amino_acids())).argmax(dim = 2).float()\n",
    "print(labels.shape)\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids()))[0][0])\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1).shape)\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)[0, :, 0])\n",
    "print(one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)[0, 16])\n",
    "x = one_hot_tensor.view(2, length, len(get_all_amino_acids())).permute(0, 2, 1)\n",
    "z = nn.CrossEntropyLoss(reduction='sum')(x, labels).item()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = -1e8\n",
    "x = torch.tensor(np.array([[1, eps, eps], [eps, 1, eps]])).float()\n",
    "labels = torch.tensor(np.array([0, 1]))\n",
    "print(torch.all(torch.eq(x.argmax(1), labels)).item() == 1)\n",
    "F.cross_entropy(x, labels, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 63)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x if x else eps for x in one_hot[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1489, -1.4456, -3.2613, -3.3038, -0.5574],\n",
       "         [-2.2018, -1.3564, -1.8980, -0.8716, -2.7541],\n",
       "         [-1.0349, -1.3823, -1.8581, -3.3522, -1.5958]],\n",
       "\n",
       "        [[-1.8522, -3.5563, -0.7642, -3.0691, -1.1961],\n",
       "         [-2.2367, -2.4859, -0.9454, -2.5285, -1.0740],\n",
       "         [-1.3448, -2.4309, -1.0460, -2.8123, -1.4270]],\n",
       "\n",
       "        [[-3.8434, -0.5309, -2.8926, -2.6222, -1.3378],\n",
       "         [-2.8145, -2.0604, -0.9137, -1.0996, -2.5432],\n",
       "         [-0.4621, -2.3404, -2.8733, -2.2319, -2.2081]]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1489, -1.4456, -3.2613, -3.3038, -0.5574],\n",
       "         [-2.2018, -1.3564, -1.8980, -0.8716, -2.7541],\n",
       "         [-1.0349, -1.3823, -1.8581, -3.3522, -1.5958]],\n",
       "\n",
       "        [[-1.8522, -3.5563, -0.7642, -3.0691, -1.1961],\n",
       "         [-2.2367, -2.4859, -0.9454, -2.5285, -1.0740],\n",
       "         [-1.3448, -2.4309, -1.0460, -2.8123, -1.4270]],\n",
       "\n",
       "        [[-3.8434, -0.5309, -2.8926, -2.6222, -1.3378],\n",
       "         [-2.8145, -2.0604, -0.9137, -1.0996, -2.5432],\n",
       "         [-0.4621, -2.3404, -2.8733, -2.2319, -2.2081]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = F.log_softmax(x, dim=2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3, 3, 5)\n",
    "x[:, :, 4] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6936)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(z * x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
