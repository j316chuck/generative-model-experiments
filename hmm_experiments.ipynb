{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import pixiedust\n",
    "import sys\n",
    "\n",
    "from pomegranate import State, DiscreteDistribution, HiddenMarkovModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import load_gfp_data, count_substring_mismatch, get_all_amino_acids, get_wild_type_amino_acid_sequence\n",
    "from hmm import GenerativeHMM, hmm_amino_acid_args\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Finished loading data in 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_\")\n",
    "print(\"Finished loading data in {0:.2f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_type_amino_acid = get_wild_type_amino_acid_sequence()\n",
    "assert(X_train[0] == wild_type_amino_acid)\n",
    "assert(count_substring_mismatch(wild_type_amino_acid, X_train[1000]) == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, length, n = 100, random=True): \n",
    "    if not random: \n",
    "        data = X_train[0:length]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]\n",
    "    return np.array([list(x)[0:length] for x in data])\n",
    "\n",
    "def sample_and_score(hmm, wild_type, n = 100, length = 100, logger = None):\n",
    "    \"\"\"\n",
    "    use the hmm model to sample n sequences of size = length. \n",
    "    then use the wild_type to count how far off the average sample is from the wild_type\n",
    "    \"\"\"\n",
    "    assert(len(wild_type) == length)\n",
    "    samples = hmm.sample(n, length)        \n",
    "    average_diff = np.average([count_substring_mismatch(seq, wild_type) for seq in samples])\n",
    "    print(\"Average difference: {0:.2f}, or {1:.2f} mismatches per letter\".format(average_diff, \n",
    "                                                                 average_diff / length), file = logger)\n",
    "    print(\"Example sequence {0}\".format(samples[np.random.randint(0, n)]), file = logger)\n",
    "    return average_diff\n",
    "\n",
    "small_length, medium_length, large_length = 15, len(wild_type_amino_acid) // 4, len(wild_type_amino_acid)\n",
    "small_X = get_data(X_train, small_length, 100)\n",
    "medium_X = get_data(X_train, medium_length, 100)\n",
    "large_X = get_data(X_train, large_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small diffs: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0]\n",
      "Medium diffs: [2, 0, 0, 0, 3, 2, 1, 0, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 3, 0, 0, 0, 0, 1, 0, 3, 1, 0, 2, 0, 2, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 3, 2, 0, 1, 0, 1, 1, 4]\n",
      "Large diffs: [5, 2, 3, 3, 2, 1, 2, 4, 2, 3, 1, 3, 4, 3, 6, 4, 3, 1, 6, 2, 5, 2, 0, 1, 3, 2, 7, 2, 5, 6, 3, 1, 2, 3, 0, 7, 1, 3, 2, 5, 3, 2, 8, 2, 5, 2, 5, 2, 3, 5, 3, 2, 3, 8, 4, 8, 7, 3, 2, 4, 4, 3, 2, 7, 4, 5, 8, 2, 4, 1, 5, 3, 5, 2, 2, 5, 5, 4, 2, 3, 3, 2, 1, 0, 8, 3, 7, 3, 2, 8, 3, 1, 6, 6, 6, 2, 6, 3, 10, 3]\n"
     ]
    }
   ],
   "source": [
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:small_length]) for i in small_X]\n",
    "print(\"Small diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:medium_length]) for i in medium_X]\n",
    "print(\"Medium diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:large_length]) for i in large_X]\n",
    "print(\"Large diffs:\", diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, length, n = 100, random = True): \n",
    "    \"\"\"\n",
    "    gets n random sequences of size length from the dataset X_train\n",
    "    \"\"\"\n",
    "    if not random: \n",
    "        data = X_train[0:length]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]\n",
    "    return np.array([list(x[0:length]) for x in data])\n",
    "\n",
    "def sample_and_score(hmm, base_str, n = 100, length = 100, logger = None):\n",
    "    \"\"\"\n",
    "    use the hmm model to sample n sequences of size = length. \n",
    "    then use the wild_type to count how far off the average sample is from the wild_type\n",
    "    prints all results in the logger file\n",
    "    \"\"\"\n",
    "    assert(len(base_str) == length)\n",
    "    samples = hmm.sample(n, length)        \n",
    "    average_diff = np.mean([count_substring_mismatch(seq, base_str) for seq in samples])\n",
    "    print(\"Average difference: {0:.2f}, or {1:.2f} mismatches per letter\".format(average_diff, \n",
    "                                                                 average_diff / length), file = logger)\n",
    "    print(\"Example sequence {0}\".format(samples[np.random.randint(0, n)]), file = logger)\n",
    "    return average_diff\n",
    "\n",
    "def train_and_save_hmm(X, args):\n",
    "    start_time = time.time()\n",
    "    hmm = GenerativeHMM(args)\n",
    "    logger = None\n",
    "    hmm.fit(X)\n",
    "    print(\"Finished training in {:.2f} seconds\".format(time.time() - start_time), file = logger)\n",
    "    print(\"HMM Parameters:\", file = logger)\n",
    "    print(hmm.get_args(), file = logger)\n",
    "    sample_and_score(hmm, wild_type_amino_acid[0:args[\"length\"]], 100, args[\"length\"], logger = logger)\n",
    "    wild_type_prob = np.e ** hmm.predict([list(wild_type_amino_acid[0:args[\"length\"]])])\n",
    "    mutation_prob = np.e ** hmm.predict([list(wild_type_amino_acid[0:args[\"length\"] - 3] + \"ACG\")])\n",
    "    print(\"Wild type prob: {0}. Mutation prob: {1}\".format(wild_type_prob, mutation_prob), file = logger)\n",
    "    model_path = \"./models/{0}.json\".format(hmm.name)\n",
    "    hmm.save_model(model_path)\n",
    "    cached_hmm = GenerativeHMM(args)\n",
    "    cached_hmm.load_model(model_path)\n",
    "    try: \n",
    "        for i in get_all_amino_acids():\n",
    "            for j in get_all_amino_acids(): \n",
    "                np.testing.assert_almost_equal(hmm.predict([list(i + j)]), cached_hmm.predict([list(i + j)]))\n",
    "        print(\"Successfully finished training and saving {0} model!\".format(hmm.name), file = logger)\n",
    "        if logger: logger.close()\n",
    "    except:\n",
    "        for i in get_all_amino_acids():\n",
    "            for j in get_all_amino_acids(): \n",
    "                print(hmm.predict([list(i + j)]), cached_hmm.predict([list(i + j)]), file = logger)\n",
    "        print(\"Error in loading {0} hmm\".format(hmm.name), file = logger)\n",
    "        if logger: logger.close()\n",
    "\n",
    "def get_args(parser_args):\n",
    "    args = hmm_amino_acid_args()\n",
    "    args[\"n_jobs\"] = parser_args.n_jobs\n",
    "    args[\"hidden_size\"] = parser_args.hidden_size\n",
    "    args[\"max_iterations\"] = parser_args.max_iterations\n",
    "    args[\"name\"] = parser_args.name\n",
    "    args[\"length\"] = parser_args.length\n",
    "    return args\n",
    "\n",
    "def get_base_args():\n",
    "    base_args = hmm_amino_acid_args()\n",
    "    base_args[\"name\"] = \"hmm_base\"\n",
    "    base_args[\"max_iterations\"] = 100\n",
    "    base_args[\"hidden_size\"] = 20\n",
    "    base_args[\"n_jobs\"] = 10\n",
    "    base_args[\"epochs\"] = 100\n",
    "    base_args[\"pseudo_count\"] = 1\n",
    "    base_args[\"length\"] = 59\n",
    "    base_args[\"vocabulary\"] = get_all_amino_acids()\n",
    "    return base_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GenerativeHMM' object has no attribute 'pseudocount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-4e70e7e23d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_save_hmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_base_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-629cc80fc51d>\u001b[0m in \u001b[0;36mtrain_and_save_hmm\u001b[0;34m(X, args)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerativeHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training in {:.2f} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HMM Parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/generative-model-experiments/hmm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, x_valid, verbose, logger, save_model_path, weights)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             _, hist = self.model.fit(x_train, max_iterations=1, pseudocount=self.pseudocount,\n\u001b[0m\u001b[1;32m     82\u001b[0m                                      n_jobs=self.n_jobs, return_history=True)\n\u001b[1;32m     83\u001b[0m             \u001b[0mtrain_neg_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_log_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GenerativeHMM' object has no attribute 'pseudocount'"
     ]
    }
   ],
   "source": [
    "train_and_save_hmm(small_X, get_base_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 20\n",
      "Epoch 1. Improvement: 27554.374772003037, last log probability: -180638.91089909413. current neg log probability [-153084.5361270911]\n",
      "152.51405102369088\n",
      "152.43382920909707\n",
      "Epoch 2. Improvement: 834.4504665236745, last log probability: -152514.05102369076. current neg log probability [-151679.60055716708]\n",
      "150.21006389214267\n",
      "150.12102479889478\n",
      "Epoch 3. Improvement: 2475.421466125874, last log probability: -150210.0638921414. current neg log probability [-147734.64242601552]\n",
      "143.6503457398613\n",
      "143.5266000626552\n",
      "Epoch 4. Improvement: 6976.518032398832, last log probability: -143650.34573986137. current neg log probability [-136673.82770746254]\n",
      "126.31968784142974\n",
      "126.0810135275985\n",
      "Epoch 5. Improvement: 13496.936220349948, last log probability: -126319.68784143034. current neg log probability [-112822.75162108039]\n",
      "98.0275632508071\n",
      "97.62493345041918\n",
      "Epoch 6. Improvement: 10686.417211129243, last log probability: -98027.56325080719. current neg log probability [-87341.14603967794]\n",
      "80.60614823461398\n",
      "80.2394535728413\n",
      "Epoch 7. Improvement: 5648.644515307329, last log probability: -80606.14823461376. current neg log probability [-74957.50371930643]\n",
      "70.01356846735729\n",
      "69.82866257736443\n",
      "Epoch 8. Improvement: 2647.6019385708787, last log probability: -70013.56846735718. current neg log probability [-67365.9665287863]\n",
      "66.56295411313438\n",
      "66.41064083699303\n",
      "Epoch 9. Improvement: 253.19491547897633, last log probability: -66562.95411313407. current neg log probability [-66309.75919765509]\n",
      "66.1907212052022\n",
      "66.03721580109996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-11f6eb83daf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimprovement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpseudocount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     print(\"Epoch {0}. Improvement: {1}, last log probability: {2}. current neg log probability {3}\".format(\n\u001b[1;32m     11\u001b[0m                         epoch, hist.total_improvement[0], hist.initial_log_probability, hist.log_probabilities))\n",
      "\u001b[0;32mpomegranate/hmm.pyx\u001b[0m in \u001b[0;36mpomegranate.hmm.HiddenMarkovModel.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpomegranate/hmm.pyx\u001b[0m in \u001b[0;36mpomegranate.hmm.HiddenMarkovModel.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = get_base_args()\n",
    "hmm = GenerativeHMM(args)\n",
    "print(hmm.num_characters, hmm.hidden_size)\n",
    "x_train = get_data(X_train, medium_length, 1000)\n",
    "x_valid = get_data(X_train, medium_length, 1000)\n",
    "train_loss_history = []\n",
    "for epoch in range(1, 101):\n",
    "    total_train_loss = 0\n",
    "    improvement, hist = hmm.model.fit(x_train, max_iterations=1, pseudocount=1, n_jobs= hmm.n_jobs, return_history=True)\n",
    "    print(\"Epoch {0}. Improvement: {1}, last log probability: {2}. current neg log probability {3}\".format(\n",
    "                        epoch, hist.total_improvement[0], hist.initial_log_probability, hist.log_probabilities))\n",
    "    print(-sum([hmm.model.log_probability(x_train[i]) for i in range(len(x_train))]) / len(x_train))\n",
    "    print(-sum(hmm.model.log_probability(x_test[i]) for i in range(len(x_test))) / len(x_test))\n",
    "\n",
    "x_test = get_data(X_train, medium_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "3.0381551702700104e-10\n",
      "2.7012103881314226e-22\n",
      "3.0381551702700104e-10\n",
      "3.2320799683723786e-12\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "6.200316694498537e-12\n",
      "0.0\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "7.995145184921112e-12\n",
      "4.797087110952642e-12\n",
      "3.0381551702700104e-10\n",
      "6.52224667018753e-18\n",
      "5.240333403890258e-20\n",
      "3.0688436063333424e-12\n",
      "3.181314314418894e-12\n",
      "6.200316694498537e-12\n",
      "3.0688436063333315e-12\n",
      "3.0381551702700104e-10\n",
      "3.0688436063333424e-12\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "6.242784596445215e-12\n",
      "7.95328578604713e-12\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "9.857028310176642e-14\n",
      "7.995145184921112e-12\n",
      "1.2557819662179663e-13\n",
      "3.824898350852471e-16\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "3.2320799683723786e-12\n",
      "3.2966321329403576e-10\n",
      "0.0\n",
      "0.0\n",
      "3.0688436063333315e-12\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "1.5990290369842122e-12\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "2.34081641808816e-47\n",
      "3.198058073968442e-12\n",
      "6.242784596445215e-12\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "2.4393771093761e-47\n",
      "0.0\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "1.265897987612514e-11\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.100158337010209e-12\n",
      "2.271033434100545e-13\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.198058020060092e-12\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "1.514869633581177e-13\n",
      "3.0381551702700104e-10\n",
      "3.0688436063333533e-12\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "9.594174221905336e-12\n",
      "3.0381551702700104e-10\n",
      "0.0\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n",
      "3.0381551702700104e-10\n"
     ]
    }
   ],
   "source": [
    "from utils import one_hot_encode, one_hot_decode\n",
    "x_encoded = one_hot_encode(x_test, get_all_amino_acids())\n",
    "for i in range(len(x_test)):\n",
    "    z = hmm.model.log_probability(x_test[i])\n",
    "    print(np.e ** z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n10, 100 sequences, 100 iterations, 100 sequences. \\n10, 200, 1e8, 100 sequences, \\n10, 200, 1000, 100 sequences. \\n10, 500, 1000, 100 sequences. \\n10, 200, 1000, 10000 seqeunces. \\n\\n\\n## Fit 3 types.\\n## Fit small data -> large data. \\n## Fit with different hidden sizes 10, 50, 200. \\n## fit until it 1e8, 1e2 iterations\\n## all with more cores 5\\n## record times of all these. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "10, 100 sequences, 100 iterations, 100 sequences. \n",
    "10, 200, 1e8, 100 sequences, \n",
    "10, 200, 1000, 100 sequences. \n",
    "10, 500, 1000, 100 sequences. \n",
    "10, 200, 1000, 10000 seqeunces. \n",
    "\n",
    "\n",
    "## Fit 3 types.\n",
    "## Fit small data -> large data. \n",
    "## Fit with different hidden sizes 10, 50, 200. \n",
    "## fit until it 1e8, 1e2 iterations\n",
    "## all with more cores 5\n",
    "## record times of all these. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = hmm.model.plot()\n",
    "hmm.model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
