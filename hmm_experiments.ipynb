{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to check latest version <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import pixiedust\n",
    "\n",
    "from pomegranate import State, DiscreteDistribution, HiddenMarkovModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "from hmm import GenerativeHMM, hmm_amino_acid_args\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Finished loading data in 3.21 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_\")\n",
    "mutated_df = load_saved_mutated_gfp_data()\n",
    "print(\"Finished loading data in {0:.2f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_type_amino_acid = get_wild_type_amino_acid_sequence()\n",
    "assert(X_train[0] == wild_type_amino_acid)\n",
    "assert(count_substring_mismatch(wild_type_amino_acid, X_train[1000]) == 8)\n",
    "assert(count_substring_mismatch(wild_type_amino_acid, mutated_df[\"mutated_amino_acid_sequence\"].values[0]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, length, n = 100, random=True): \n",
    "    if not random: \n",
    "        data = X_train[0:length]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]\n",
    "    return np.array([list(x)[0:length] for x in data])\n",
    "\n",
    "def sample_and_score(hmm, wild_type, n = 100, length = 100, file = None):\n",
    "    \"\"\"\n",
    "    use the hmm model to sample n sequences of size = length. \n",
    "    then use the wild_type to count how far off the average sample is from the wild_type\n",
    "    \"\"\"\n",
    "    assert(len(wild_type) == length)\n",
    "    samples = hmm.sample(n, length)        \n",
    "    average_diff = np.average([count_substring_mismatch(seq, wild_type) for seq in samples])\n",
    "    print(\"Average difference: {0:.2f}, or {1:.2f} mismatches per letter\".format(average_diff, \n",
    "                                                                 average_diff / length), file = file)\n",
    "    print(\"Example sequence {0}\".format(samples[np.random.randint(0, n)]), file = file)\n",
    "    return average_diff\n",
    "\n",
    "small_length, medium_length, large_length = 15, len(wild_type_amino_acid) // 4, len(wild_type_amino_acid)\n",
    "small_X = get_data(X_train, small_length, 100)\n",
    "medium_X = get_data(X_train, medium_length, 100)\n",
    "large_X = get_data(X_train, large_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small diffs: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Medium diffs: [0, 3, 3, 1, 0, 1, 4, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 3, 1, 1, 1, 0, 1, 0, 1, 4, 1, 0, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 3, 2, 0, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 2, 2, 0, 2, 1, 0, 1, 2, 0, 3, 1, 0]\n",
      "Large diffs: [4, 3, 2, 3, 1, 5, 3, 3, 1, 5, 4, 5, 2, 3, 4, 3, 2, 4, 3, 2, 6, 3, 2, 2, 3, 3, 2, 5, 5, 5, 4, 5, 4, 5, 2, 1, 3, 11, 5, 4, 4, 2, 3, 2, 2, 2, 3, 4, 5, 2, 3, 2, 7, 3, 4, 2, 5, 2, 2, 4, 6, 5, 2, 6, 2, 3, 1, 2, 1, 4, 2, 1, 2, 2, 6, 3, 7, 2, 2, 1, 8, 4, 5, 3, 3, 2, 6, 2, 3, 2, 3, 5, 3, 2, 1, 2, 0, 3, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:small_length]) for i in small_X]\n",
    "print(\"Small diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:medium_length]) for i in medium_X]\n",
    "print(\"Medium diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:large_length]) for i in large_X]\n",
    "print(\"Large diffs:\", diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_hmm(args):\n",
    "    start_time = time.time()\n",
    "    hmm = GenerativeHMM(args)\n",
    "    hmm.fit(small_X)\n",
    "    log_path = \"./logs/{0}.txt\".format(hmm.name)\n",
    "    logger = open(log_path, \"w\")\n",
    "    print(\"Finished training in {:.2f} seconds\".format(time.time() - start_time), file = logger)\n",
    "    print(\"HMM Parameters:\", file = logger)\n",
    "    print(hmm.get_args(), file = logger)\n",
    "    sample_and_score(hmm, wild_type_amino_acid[0:small_length], 100, small_length, file = logger)\n",
    "    model_path = \"./models/{0}.json\".format(hmm.name)\n",
    "    hmm.save_model(model_path)\n",
    "    cached_hmm = GenerativeHMM(args)\n",
    "    cached_hmm.load_model(model_path)\n",
    "    try: \n",
    "        for i in get_all_amino_acids():\n",
    "            for j in get_all_amino_acids(): \n",
    "                np.testing.assert_almost_equal(hmm.predict([list(i + j)]), cached_hmm.predict([list(i + j)]))\n",
    "        print(\"Successfully finished training and saving {0} hmm!\".format(hmm.name), file = logger)\n",
    "        logger.close()\n",
    "    except:\n",
    "        print(\"Error in loading {0} hmm\".format(hmm.name))\n",
    "        logger.close()\n",
    "\n",
    "def get_small_args():\n",
    "    base_args = hmm_amino_acid_args()\n",
    "    base_args[\"name\"] = \"amino_acid_small\"\n",
    "    base_args[\"max_iterations\"] = 100\n",
    "    base_args[\"hidden_size\"] = 50\n",
    "    base_args[\"n_jobs\"] = 5\n",
    "    return base_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Improvement: 1272.6339987469269\tTime (s): 0.1651\n",
      "[2] Improvement: 87.35922020702628\tTime (s): 0.1985\n",
      "[3] Improvement: 162.9487532171006\tTime (s): 0.2252\n",
      "[4] Improvement: 283.4199117419703\tTime (s): 0.2014\n",
      "[5] Improvement: 401.2173105789716\tTime (s): 0.2375\n",
      "[6] Improvement: 660.0943599881184\tTime (s): 0.2318\n",
      "[7] Improvement: 632.2907845468504\tTime (s): 0.2319\n",
      "[8] Improvement: 375.04132737638224\tTime (s): 0.2284\n",
      "[9] Improvement: 251.74877640948654\tTime (s): 0.1704\n",
      "[10] Improvement: 152.5301803204522\tTime (s): 0.2084\n",
      "[11] Improvement: 79.67922144952371\tTime (s): 0.2547\n",
      "[12] Improvement: 47.999740636191376\tTime (s): 0.2205\n",
      "[13] Improvement: 31.80944296712528\tTime (s): 0.1831\n",
      "[14] Improvement: 13.116383630731534\tTime (s): 0.207\n",
      "[15] Improvement: 3.4367271744879417\tTime (s): 0.1779\n",
      "[16] Improvement: 1.1882763113427046\tTime (s): 0.1402\n",
      "[17] Improvement: 0.2543010032409114\tTime (s): 0.1362\n",
      "[18] Improvement: 0.012192319394017659\tTime (s): 0.1333\n",
      "[19] Improvement: 3.2047428106807274e-05\tTime (s): 0.1397\n",
      "[20] Improvement: 1.2972846050729459e-06\tTime (s): 0.1561\n",
      "[21] Improvement: 1.297364462971018e-06\tTime (s): 0.1986\n",
      "[22] Improvement: 1.312626189076127e-06\tTime (s): 0.1534\n",
      "[23] Improvement: 1.330372995766993e-06\tTime (s): 0.1802\n",
      "[24] Improvement: 1.3486627565839626e-06\tTime (s): 0.1316\n",
      "[25] Improvement: 1.3671934269154917e-06\tTime (s): 0.2105\n",
      "[26] Improvement: 1.3859176846153787e-06\tTime (s): 0.1681\n",
      "[27] Improvement: 1.4048275858158377e-06\tTime (s): 0.1719\n",
      "[28] Improvement: 1.4239214962685764e-06\tTime (s): 0.1484\n",
      "[29] Improvement: 1.4431986343765857e-06\tTime (s): 0.1261\n",
      "[30] Improvement: 1.4626583109134117e-06\tTime (s): 0.1198\n",
      "[31] Improvement: 1.482299701649481e-06\tTime (s): 0.1529\n",
      "[32] Improvement: 1.502122039198639e-06\tTime (s): 0.1506\n",
      "[33] Improvement: 1.5221245632801583e-06\tTime (s): 0.1472\n",
      "[34] Improvement: 1.5423060517605336e-06\tTime (s): 0.1972\n",
      "[35] Improvement: 1.5626660072598497e-06\tTime (s): 0.1373\n",
      "[36] Improvement: 1.5832025823669937e-06\tTime (s): 0.1748\n",
      "[37] Improvement: 1.6039156491842732e-06\tTime (s): 0.2027\n",
      "[38] Improvement: 1.6248032324028827e-06\tTime (s): 0.2233\n",
      "[39] Improvement: 1.6458644012118384e-06\tTime (s): 0.2332\n",
      "[40] Improvement: 1.6670978055799424e-06\tTime (s): 0.2038\n",
      "[41] Improvement: 1.6885022446899711e-06\tTime (s): 0.2362\n",
      "[42] Improvement: 1.7100758924470938e-06\tTime (s): 0.2355\n",
      "[43] Improvement: 1.7318176048775058e-06\tTime (s): 0.2196\n",
      "[44] Improvement: 1.7537260248445818e-06\tTime (s): 0.2194\n",
      "[45] Improvement: 1.7757988928224222e-06\tTime (s): 0.2122\n",
      "[46] Improvement: 1.7980354130031628e-06\tTime (s): 0.1967\n",
      "[47] Improvement: 1.8204330771709465e-06\tTime (s): 0.1906\n",
      "[48] Improvement: 1.8429908408279516e-06\tTime (s): 0.2144\n",
      "[49] Improvement: 1.8657065510296889e-06\tTime (s): 0.1209\n",
      "[50] Improvement: 1.8885783106270537e-06\tTime (s): 0.1612\n",
      "[51] Improvement: 1.911604485371754e-06\tTime (s): 0.115\n",
      "[52] Improvement: 1.9347830431115653e-06\tTime (s): 0.0919\n",
      "[53] Improvement: 1.9581120298539645e-06\tTime (s): 0.1008\n",
      "[54] Improvement: 1.9815895839769837e-06\tTime (s): 0.1375\n",
      "[55] Improvement: 2.0052133464787403e-06\tTime (s): 0.1018\n",
      "[56] Improvement: 2.028981747059788e-06\tTime (s): 0.1146\n",
      "[57] Improvement: 2.0528923414531164e-06\tTime (s): 0.144\n",
      "[58] Improvement: 2.0769430975065006e-06\tTime (s): 0.1025\n",
      "[59] Improvement: 2.1011322601793836e-06\tTime (s): 0.1251\n",
      "[60] Improvement: 2.1254569304574034e-06\tTime (s): 0.1103\n",
      "[61] Improvement: 2.1499158862070544e-06\tTime (s): 0.1094\n",
      "[62] Improvement: 2.1745062355194023e-06\tTime (s): 0.1573\n",
      "[63] Improvement: 2.199226408095001e-06\tTime (s): 0.09778\n",
      "[64] Improvement: 2.2240736896605995e-06\tTime (s): 0.1449\n",
      "[65] Improvement: 2.249046403335342e-06\tTime (s): 0.1164\n",
      "[66] Improvement: 2.274142083535935e-06\tTime (s): 0.1353\n",
      "[67] Improvement: 2.29935892548383e-06\tTime (s): 0.148\n",
      "[68] Improvement: 2.324694456490306e-06\tTime (s): 0.1237\n",
      "[69] Improvement: 2.3501468007225412e-06\tTime (s): 0.152\n",
      "[70] Improvement: 2.3757138194469007e-06\tTime (s): 0.1355\n",
      "[71] Improvement: 2.401393714990263e-06\tTime (s): 0.1128\n",
      "[72] Improvement: 2.427184114139891e-06\tTime (s): 0.09304\n",
      "[73] Improvement: 2.453083446596338e-06\tTime (s): 0.09889\n",
      "[74] Improvement: 2.4790895096771237e-06\tTime (s): 0.1112\n",
      "[75] Improvement: 2.5052005909742547e-06\tTime (s): 0.1048\n",
      "[76] Improvement: 2.531414800444054e-06\tTime (s): 0.09181\n",
      "[77] Improvement: 2.557730695684768e-06\tTime (s): 0.08951\n",
      "[78] Improvement: 2.5841461948061806e-06\tTime (s): 0.1742\n",
      "[79] Improvement: 2.610660025936795e-06\tTime (s): 0.1694\n",
      "[80] Improvement: 2.6372703629817806e-06\tTime (s): 0.09804\n",
      "[81] Improvement: 2.663976189865025e-06\tTime (s): 0.2044\n",
      "[82] Improvement: 2.6907758226002443e-06\tTime (s): 0.1685\n",
      "[83] Improvement: 2.7176681456353435e-06\tTime (s): 0.1883\n",
      "[84] Improvement: 2.744651816044552e-06\tTime (s): 0.2176\n",
      "[85] Improvement: 2.771726201444835e-06\tTime (s): 0.1985\n",
      "[86] Improvement: 2.7988897102204646e-06\tTime (s): 0.2165\n",
      "[87] Improvement: 2.8261421647357565e-06\tTime (s): 0.1888\n",
      "[88] Improvement: 2.8534823428572054e-06\tTime (s): 0.229\n",
      "[89] Improvement: 2.88090992484058e-06\tTime (s): 0.2298\n",
      "[90] Improvement: 2.908424299619128e-06\tTime (s): 0.2201\n",
      "[91] Improvement: 2.936025232713746e-06\tTime (s): 0.207\n",
      "[92] Improvement: 2.9637122338499466e-06\tTime (s): 0.2315\n",
      "[93] Improvement: 2.991485480663414e-06\tTime (s): 0.2305\n",
      "[94] Improvement: 3.0193448310456006e-06\tTime (s): 0.2139\n",
      "[95] Improvement: 3.047290768165567e-06\tTime (s): 0.2532\n",
      "[96] Improvement: 3.075323270707031e-06\tTime (s): 0.2103\n",
      "[97] Improvement: 3.1034431628995662e-06\tTime (s): 0.2194\n",
      "[98] Improvement: 3.131650714749412e-06\tTime (s): 0.2277\n",
      "[99] Improvement: 3.1599470560195186e-06\tTime (s): 0.2237\n",
      "[100] Improvement: 3.188333003834032e-06\tTime (s): 0.2002\n",
      "Total Training Improvement: 4456.781115816758\n",
      "Total Training Time (s): 17.4550\n"
     ]
    }
   ],
   "source": [
    "train_and_save_hmm(get_small_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n10, 100 sequences, 100 iterations, 100 sequences. \\n10, 200, 1e8, 100 sequences, \\n10, 200, 1000, 100 sequences. \\n10, 500, 1000, 100 sequences. \\n10, 200, 1000, 10000 seqeunces. \\n\\n\\n## Fit 3 types.\\n## Fit small data -> large data. \\n## Fit with different hidden sizes 10, 50, 200. \\n## fit until it 1e8, 1e2 iterations\\n## all with more cores 5\\n## record times of all these. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "10, 100 sequences, 100 iterations, 100 sequences. \n",
    "10, 200, 1e8, 100 sequences, \n",
    "10, 200, 1000, 100 sequences. \n",
    "10, 500, 1000, 100 sequences. \n",
    "10, 200, 1000, 10000 seqeunces. \n",
    "\n",
    "\n",
    "## Fit 3 types.\n",
    "## Fit small data -> large data. \n",
    "## Fit with different hidden sizes 10, 50, 200. \n",
    "## fit until it 1e8, 1e2 iterations\n",
    "## all with more cores 5\n",
    "## record times of all these. \n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
