{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import pixiedust\n",
    "import sys\n",
    "import ipdb \n",
    "\n",
    "from pomegranate import State, DiscreteDistribution, HiddenMarkovModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import load_gfp_data, count_substring_mismatch, get_all_amino_acids, get_wild_type_amino_acid_sequence\n",
    "from hmm import GenerativeHMM, hmm_amino_acid_args\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Finished loading data in 1.62 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_\")\n",
    "mutated_df = load_saved_mutated_gfp_data()\n",
    "print(\"Finished loading data in {0:.2f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_type_amino_acid = get_wild_type_amino_acid_sequence()\n",
    "assert(X_train[0] == wild_type_amino_acid)\n",
    "assert(count_substring_mismatch(wild_type_amino_acid, X_train[1000]) == 8)\n",
    "assert(count_substring_mismatch(wild_type_amino_acid, mutated_df[\"mutated_amino_acid_sequence\"].values[0]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, length, n = 100, random=True): \n",
    "    if not random: \n",
    "        data = X_train[0:length]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]\n",
    "    return np.array([list(x)[0:length] for x in data])\n",
    "\n",
    "def sample_and_score(hmm, wild_type, n = 100, length = 100, logger = None):\n",
    "    \"\"\"\n",
    "    use the hmm model to sample n sequences of size = length. \n",
    "    then use the wild_type to count how far off the average sample is from the wild_type\n",
    "    \"\"\"\n",
    "    assert(len(wild_type) == length)\n",
    "    samples = hmm.sample(n, length)        \n",
    "    average_diff = np.average([count_substring_mismatch(seq, wild_type) for seq in samples])\n",
    "    print(\"Average difference: {0:.2f}, or {1:.2f} mismatches per letter\".format(average_diff, \n",
    "                                                                 average_diff / length), file = logger)\n",
    "    print(\"Example sequence {0}\".format(samples[np.random.randint(0, n)]), file = logger)\n",
    "    return average_diff\n",
    "\n",
    "small_length, medium_length, large_length = 15, len(wild_type_amino_acid) // 4, len(wild_type_amino_acid)\n",
    "small_X = get_data(X_train, small_length, 100)\n",
    "medium_X = get_data(X_train, medium_length, 100)\n",
    "large_X = get_data(X_train, large_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small diffs: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Medium diffs: [1, 0, 0, 4, 1, 0, 1, 3, 2, 1, 4, 1, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 1, 0, 2, 2, 1, 0, 0, 3, 2, 0, 0, 1, 0, 3, 3, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2]\n",
      "Large diffs: [6, 2, 1, 3, 1, 6, 3, 3, 6, 4, 2, 2, 7, 2, 5, 2, 4, 6, 6, 2, 3, 1, 1, 2, 4, 6, 4, 5, 3, 2, 5, 3, 2, 8, 4, 9, 2, 3, 3, 2, 3, 3, 7, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 7, 3, 4, 8, 4, 5, 5, 2, 7, 4, 8, 5, 5, 4, 6, 5, 4, 2, 3, 5, 2, 1, 8, 6, 5, 6, 5, 2, 2, 2, 3, 2, 3, 2, 2, 4, 6, 7, 3, 3, 1, 3, 1, 2, 3, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:small_length]) for i in small_X]\n",
    "print(\"Small diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:medium_length]) for i in medium_X]\n",
    "print(\"Medium diffs:\", diffs)\n",
    "diffs = [count_substring_mismatch(i, wild_type_amino_acid[0:large_length]) for i in large_X]\n",
    "print(\"Large diffs:\", diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, length, n = 100, random = True): \n",
    "    \"\"\"\n",
    "    gets n random sequences of size length from the dataset X_train\n",
    "    \"\"\"\n",
    "    if not random: \n",
    "        data = X_train[0:length]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]\n",
    "    return np.array([list(x[0:length]) for x in data])\n",
    "\n",
    "def sample_and_score(hmm, base_str, n = 100, length = 100, logger = None):\n",
    "    \"\"\"\n",
    "    use the hmm model to sample n sequences of size = length. \n",
    "    then use the wild_type to count how far off the average sample is from the wild_type\n",
    "    prints all results in the logger file\n",
    "    \"\"\"\n",
    "    assert(len(base_str) == length)\n",
    "    samples = hmm.sample(n, length)        \n",
    "    average_diff = np.mean([count_substring_mismatch(seq, base_str) for seq in samples])\n",
    "    print(\"Average difference: {0:.2f}, or {1:.2f} mismatches per letter\".format(average_diff, \n",
    "                                                                 average_diff / length), file = logger)\n",
    "    print(\"Example sequence {0}\".format(samples[np.random.randint(0, n)]), file = logger)\n",
    "    return average_diff\n",
    "\n",
    "def train_and_save_hmm(X, args):\n",
    "    start_time = time.time()\n",
    "    hmm = GenerativeHMM(args)\n",
    "    logger = None\n",
    "    hmm.fit(X)\n",
    "    print(\"Finished training in {:.2f} seconds\".format(time.time() - start_time), file = logger)\n",
    "    print(\"HMM Parameters:\", file = logger)\n",
    "    print(hmm.get_args(), file = logger)\n",
    "    sample_and_score(hmm, wild_type_amino_acid[0:args[\"length\"]], 100, args[\"length\"], logger = logger)\n",
    "    wild_type_prob = np.e ** hmm.predict([list(wild_type_amino_acid[0:args[\"length\"]])])\n",
    "    mutation_prob = np.e ** hmm.predict([list(wild_type_amino_acid[0:args[\"length\"] - 3] + \"ACG\")])\n",
    "    print(\"Wild type prob: {0}. Mutation prob: {1}\".format(wild_type_prob, mutation_prob), file = logger)\n",
    "    model_path = \"./models/{0}.json\".format(hmm.name)\n",
    "    hmm.save_model(model_path)\n",
    "    cached_hmm = GenerativeHMM(args)\n",
    "    cached_hmm.load_model(model_path)\n",
    "    try: \n",
    "        for i in get_all_amino_acids():\n",
    "            for j in get_all_amino_acids(): \n",
    "                np.testing.assert_almost_equal(hmm.predict([list(i + j)]), cached_hmm.predict([list(i + j)]))\n",
    "        print(\"Successfully finished training and saving {0} model!\".format(hmm.name), file = logger)\n",
    "        if logger: logger.close()\n",
    "    except:\n",
    "        for i in get_all_amino_acids():\n",
    "            for j in get_all_amino_acids(): \n",
    "                print(hmm.predict([list(i + j)]), cached_hmm.predict([list(i + j)]), file = logger)\n",
    "        print(\"Error in loading {0} hmm\".format(hmm.name), file = logger)\n",
    "        if logger: logger.close()\n",
    "\n",
    "def get_args(parser_args):\n",
    "    args = hmm_amino_acid_args()\n",
    "    args[\"n_jobs\"] = parser_args.n_jobs\n",
    "    args[\"hidden_size\"] = parser_args.hidden_size\n",
    "    args[\"max_iterations\"] = parser_args.max_iterations\n",
    "    args[\"name\"] = parser_args.name\n",
    "    args[\"length\"] = parser_args.length\n",
    "    return args\n",
    "\n",
    "def get_base_args():\n",
    "    base_args = hmm_amino_acid_args()\n",
    "    base_args[\"name\"] = \"hmm_base\"\n",
    "    base_args[\"max_iterations\"] = 100\n",
    "    base_args[\"hidden_size\"] = 20\n",
    "    base_args[\"n_jobs\"] = 10\n",
    "    base_args[\"length\"] = 15\n",
    "    return base_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Improvement: 1398.7271447617622\tTime (s): 0.0424\n",
      "[2] Improvement: 100.26230049001333\tTime (s): 0.04371\n",
      "[3] Improvement: 167.0684396539914\tTime (s): 0.04403\n",
      "[4] Improvement: 307.7334251848615\tTime (s): 0.04365\n",
      "[5] Improvement: 503.4235540154327\tTime (s): 0.04374\n",
      "[6] Improvement: 623.5416012330415\tTime (s): 0.04401\n",
      "[7] Improvement: 515.8650776445228\tTime (s): 0.04417\n",
      "[8] Improvement: 313.81438339190197\tTime (s): 0.04363\n",
      "[9] Improvement: 280.9509821049363\tTime (s): 0.04636\n",
      "[10] Improvement: 226.54593051518884\tTime (s): 0.04502\n",
      "[11] Improvement: 65.89640639356455\tTime (s): 0.04528\n",
      "[12] Improvement: 31.125666125417297\tTime (s): 0.04591\n",
      "[13] Improvement: 8.982763983025407\tTime (s): 0.04537\n",
      "[14] Improvement: 0.6497688962727182\tTime (s): 0.04544\n",
      "[15] Improvement: 0.004298003109752813\tTime (s): 0.04541\n",
      "[16] Improvement: 2.1676243022739072e-09\tTime (s): 0.0467\n",
      "[17] Improvement: 0.0\tTime (s): 0.04737\n",
      "Total Training Improvement: 4544.59174239921\n",
      "Total Training Time (s): 0.9058\n",
      "Finished training in 1.02 seconds\n",
      "HMM Parameters:\n",
      "{'name': 'hmm_base', 'hidden_size': 20, 'max_iterations': 100, 'n_jobs': 10, 'batch_size': 5, 'epoch': 2, 'char_to_int': {'*': 0, 'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}, 'build_from_samples': False, 'length': 15}\n",
      "Average difference: 0.12, or 0.01 mismatches per letter\n",
      "Example sequence SKGEELFTGVVPILV\n",
      "Wild type prob: 0.8586353437199998. Mutation prob: 0.0\n",
      "Successfully finished training and saving hmm_base model!\n"
     ]
    }
   ],
   "source": [
    "train_and_save_hmm(small_X, get_base_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n10, 100 sequences, 100 iterations, 100 sequences. \\n10, 200, 1e8, 100 sequences, \\n10, 200, 1000, 100 sequences. \\n10, 500, 1000, 100 sequences. \\n10, 200, 1000, 10000 seqeunces. \\n\\n\\n## Fit 3 types.\\n## Fit small data -> large data. \\n## Fit with different hidden sizes 10, 50, 200. \\n## fit until it 1e8, 1e2 iterations\\n## all with more cores 5\\n## record times of all these. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "10, 100 sequences, 100 iterations, 100 sequences. \n",
    "10, 200, 1e8, 100 sequences, \n",
    "10, 200, 1000, 100 sequences. \n",
    "10, 500, 1000, 100 sequences. \n",
    "10, 200, 1000, 10000 seqeunces. \n",
    "\n",
    "\n",
    "## Fit 3 types.\n",
    "## Fit small data -> large data. \n",
    "## Fit with different hidden sizes 10, 50, 200. \n",
    "## fit until it 1e8, 1e2 iterations\n",
    "## all with more cores 5\n",
    "## record times of all these. \n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
