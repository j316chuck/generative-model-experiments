{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/global/homes/d/dbrookes/design_icml/')\n",
    "import itertools\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras import layers, initializers\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from seqtools import SequenceTools as ST\n",
    "from gfp_gp import SequenceGP\n",
    "from util import AA, AA_IDX\n",
    "from util import build_vae\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gan import WGAN\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from util import one_hot_encode_aa, partition_data, get_balaji_predictions, get_samples, get_argmax\n",
    "from util import convert_idx_array_to_aas, build_pred_vae_model, get_experimental_X_y\n",
    "from util import get_gfp_X_y_aa\n",
    "from losses import neg_log_likelihood\n",
    "import json\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                 steps=10000, epsilon1=10**-5, epsilon2=1, noise_std=10**-5,\n",
    "                 LD=100, verbose=False, adam=False):\n",
    "    L = X_train.shape[1]\n",
    "    \n",
    "    G = vae.decoder_\n",
    "    f = oracles\n",
    "    \n",
    "    sess = K.get_session()\n",
    "    zt = K.tf.Variable(np.random.normal(size=[1, LD]), dtype='float32')\n",
    "    pred_input = K.tf.Variable(np.zeros((1, L, X_train.shape[2])), dtype='float32')\n",
    "    gen_output = G(zt)\n",
    "    prior = tfd.Normal(0, 1)\n",
    "    p_z = prior.log_prob(zt)\n",
    "    predictions = K.tf.reduce_mean([f[i](pred_input)[0, 0] for i in range(len(f))])\n",
    "    update_pred_input = K.tf.assign(pred_input, gen_output)\n",
    "    dfdx = K.tf.gradients(ys=-predictions, xs=pred_input)[0]\n",
    "    dfdz = K.tf.gradients(gen_output, zt, grad_ys=dfdx)[0]\n",
    "    dpz = K.tf.gradients(p_z, zt)[0]\n",
    "    \n",
    "    noise = K.tf.random_normal(shape=[1, LD], stddev=noise_std)\n",
    "    eps1 = K.tf.Variable(epsilon1, trainable=False)\n",
    "    eps2 = K.tf.Variable(epsilon2, trainable=False)\n",
    "    if adam:\n",
    "        optimizer = K.tf.train.AdamOptimizer(learning_rate=epsilon2)\n",
    "        step = dfdz + noise\n",
    "    else:\n",
    "        optimizer = K.tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "        step = eps1 * dpz + eps2 * dfdz + noise\n",
    "    \n",
    "    design_op = optimizer.apply_gradients([(step, zt)])\n",
    "    adam_initializers = [var.initializer for var in K.tf.global_variables() if 'Adam' in var.name or 'beta' in var.name]\n",
    "    sess.run(adam_initializers)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(zt.initializer)\n",
    "    sess.run(eps1.initializer)\n",
    "    sess.run(eps2.initializer)\n",
    "\n",
    "    s = sess.run(K.tf.shape(zt))\n",
    "    sess.run(update_pred_input, {zt: np.random.normal(size=s)})\n",
    "    z_0 = sess.run([zt])\n",
    "    for t in range(steps):\n",
    "        xt0, _, = sess.run([gen_output, design_op], {eps1: epsilon1, eps2:epsilon2})\n",
    "        pred_in, preds = sess.run([update_pred_input, predictions])\n",
    "        xt = get_argmax(xt0)\n",
    "        ft = get_balaji_predictions(oracles, xt)[0][0]\n",
    "        ft0 = get_balaji_predictions(oracles, xt0)[0][0]\n",
    "        x_opt = np.argmax(xt0, axis=-1)\n",
    "        if t % 1000 == 0:\n",
    "            gt_opt = ground_truth.predict(x_opt)[:, 0][0]\n",
    "            print(t, ft, ft0, gt_opt)\n",
    "    oracle_max_seq = convert_idx_array_to_aas(x_opt)\n",
    "    max_dict = {'oracle_max' : ft, \n",
    "                'oracle_max_seq': oracle_max_seq, \n",
    "                'gt_of_oracle_max': gt_opt}\n",
    "    results = np.array([ft, gt_opt])\n",
    "    return results, max_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experimental_gans():\n",
    "    TRAIN_SIZE = 5000\n",
    "    train_size_str = \"%ik\" % (TRAIN_SIZE/1000)\n",
    "    for it in range(1):  # Can only use the first oracle and training set....b/c it can't take an ensemble\n",
    "        RANDOM_STATE = it + 1\n",
    "        X_train, y_train, _  = get_experimental_X_y(random_state=RANDOM_STATE, train_size=TRAIN_SIZE)\n",
    "        \n",
    "        L = X_train.shape[1]\n",
    "        LD=100\n",
    "        gan = WGAN(input_shape=(L, X_train.shape[2],), latent_dim=LD, gumbel=False)\n",
    "\n",
    "        gan.train(X_train,\n",
    "                 batch_size=1000,\n",
    "                 epochs=100,\n",
    "                 verbose=2\n",
    "                 ) \n",
    "\n",
    "        suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "        gan.generator.save_weights(\"models/killoran_gan_geneorator_weights%s.h5\" % suffix)\n",
    "        gan.critic.save_weights(\"models/killoran_gan_critic_weights%s.h5\" % suffix)\n",
    "        gan.combined.save_weights(\"models/killoran_gan_combined_weights%s.h5\" % suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_killoran(killoran=True):\n",
    "    TRAIN_SIZE = 5000\n",
    "    train_size_str = \"%ik\" % (TRAIN_SIZE/1000)\n",
    "    for i in range(2, 3):\n",
    "        RANDOM_STATE = i+1\n",
    "        print(RANDOM_STATE)\n",
    "        num_models = [1, 5, 20][i]\n",
    "        X_train, _, _  = get_experimental_X_y(random_state=RANDOM_STATE, train_size=TRAIN_SIZE)\n",
    "\n",
    "        LD=20\n",
    "        L = X_train.shape[1]\n",
    "        \n",
    "        vae_suffix = '_%s_%i' % (train_size_str, RANDOM_STATE)\n",
    "        \n",
    "        ground_truth = SequenceGP(load=True, load_prefix=\"data/gfp_gp\")\n",
    "        loss = neg_log_likelihood\n",
    "        get_custom_objects().update({\"neg_log_likelihood\": loss})\n",
    "        oracle_suffix = '_%s_%i_%i' % (train_size_str, num_models, RANDOM_STATE)\n",
    "        \n",
    "        \n",
    "        sess = tf.Session(graph=tf.get_default_graph())\n",
    "        K.set_session(sess)\n",
    "        vae = build_vae(latent_dim=20,\n",
    "                  n_tokens=20, \n",
    "                  seq_length=X_train.shape[1],\n",
    "                  enc1_units=50)\n",
    "        vae.encoder_.load_weights(\"models/vae_0_encoder_weights%s.h5\" % vae_suffix)\n",
    "        vae.decoder_.load_weights(\"models/vae_0_decoder_weights%s.h5\"% vae_suffix)\n",
    "        vae.vae_.load_weights(\"models/vae_0_vae_weights%s.h5\"% vae_suffix)\n",
    "        \n",
    "        oracles = [load_model(\"models/oracle_%i%s.h5\" % (i, oracle_suffix)) for i in range(num_models)]\n",
    "        if not killoran:\n",
    "            results, test_max = killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                                   steps=30000, epsilon1=1e-5, epsilon2=1.,  \n",
    "                                   noise_std=1e-5,\n",
    "                                   LD=20, verbose=False, adam=False)\n",
    "            \n",
    "            np.save(\"results/mala_results_%s_%i.npy\" % (train_size_str, RANDOM_STATE), results)\n",
    "            suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "            with open('results/%s_max%s.json'% ('mala', suffix), 'w') as outfile:\n",
    "                json.dump(test_max, outfile)\n",
    "                \n",
    "        else:\n",
    "            results, test_max = killoran_opt(X_train, vae, oracles, ground_truth,\n",
    "                                             steps=10000, epsilon1=0., epsilon2=0.1,  \n",
    "                                             noise_std=1e-6,\n",
    "                                             LD=20, verbose=False, adam=True)\n",
    "            np.save(\"results/killoran_results_%s_%i.npy\" % (train_size_str, RANDOM_STATE), results)\n",
    "            suffix = \"_%s_%i\" % (train_size_str, RANDOM_STATE)\n",
    "            with open('results/%s_max%s.json'% ('killoran', suffix), 'w') as outfile:\n",
    "                json.dump(test_max, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0 3.1676503300666807 3.110014855861664 3.2555060275039045\n",
      "1000 3.1676503300666807 3.1371212363243104 3.2555060275039045\n",
      "2000 3.1676503300666807 3.1422816276550294 3.2555060275039045\n",
      "3000 3.1676503300666807 3.145837903022766 3.2555060275039045\n",
      "4000 3.1676503300666807 3.1484865665435793 3.2555060275039045\n",
      "5000 3.1676503300666807 3.1505558252334596 3.2555060275039045\n",
      "6000 3.1676503300666807 3.152221715450287 3.2555060275039045\n",
      "7000 3.1676503300666807 3.1535950899124146 3.2555060275039045\n",
      "8000 3.1676503300666807 3.154749798774719 3.2555060275039045\n",
      "9000 3.1676503300666807 3.155735766887665 3.2555060275039045\n",
      "10000 3.1676503300666807 3.156596577167511 3.2555060275039045\n",
      "11000 3.1676503300666807 3.157372510433197 3.2555060275039045\n",
      "12000 3.1676503300666807 3.1581042647361754 3.2555060275039045\n",
      "13000 3.1676503300666807 3.1588181853294373 3.2555060275039045\n",
      "14000 3.1676503300666807 3.1595839738845823 3.2555060275039045\n",
      "15000 3.1676503300666807 3.1604606032371523 3.2555060275039045\n",
      "16000 3.1676503300666807 3.1613473296165466 3.2555060275039045\n",
      "17000 3.1676503300666807 3.1621090292930605 3.2555060275039045\n",
      "18000 3.1676503300666807 3.1627668023109434 3.2555060275039045\n",
      "19000 3.1676503300666807 3.1633504986763 3.2555060275039045\n",
      "20000 3.1676503300666807 3.1639045119285583 3.2555060275039045\n",
      "21000 3.1676503300666807 3.1644562125205993 3.2555060275039045\n",
      "22000 3.1676503300666807 3.1651000499725344 3.2555060275039045\n",
      "23000 3.1676503300666807 3.1675822377204894 3.2555060275039045\n",
      "24000 3.180699348449707 3.1746946454048155 3.374807033941531\n",
      "25000 3.180699348449707 3.1767589330673216 3.374807033941531\n",
      "26000 3.180699348449707 3.17836412191391 3.374807033941531\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-32f3c027c644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train_experimental_gans()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_killoran\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkilloran\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-1397397717fe>\u001b[0m in \u001b[0;36mrun_killoran\u001b[0;34m(killoran)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                    \u001b[0mnoise_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                    LD=20, verbose=False, adam=False)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/mala_results_%s_%i.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_size_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2164d0177ba4>\u001b[0m in \u001b[0;36mkilloran_opt\u001b[0;34m(X_train, vae, oracles, ground_truth, steps, epsilon1, epsilon2, noise_std, LD, verbose, adam)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpred_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_pred_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balaji_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mft0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balaji_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/design_icml/util.py\u001b[0m in \u001b[0;36mget_balaji_predictions\u001b[0;34m(preds, Xt)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;31m#         print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myconda2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.conda/envs/myconda2/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myconda2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myconda2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myconda2/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_experimental_gans()\n",
    "run_killoran(killoran=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_killoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyConda2",
   "language": "python",
   "name": "myconda2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
