{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(X):\n",
    "    \"\"\"\n",
    "    Input: X is a list of DNA Sequences represented by the base pairs ACTG. \n",
    "        All DNA Sequences must be the same length\n",
    "    Output: one hot encoded list of dna sequences\n",
    "    Example: one_hot_encode([\"ACT\", \"ACG\"]) = [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], \n",
    "                                                    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]]\n",
    "    \"\"\"\n",
    "    assert(len(X) > 0)\n",
    "    assert(all([len(X[0]) == len(X[i]) for i in range(len(X))]))\n",
    "    alphabet = [\"A\", \"C\", \"T\", \"G\"]\n",
    "    alphabet_size = len(alphabet)\n",
    "    alphabet_dict = dict(zip(alphabet, range(alphabet_size)))\n",
    "    one_hot_matrix = np.zeros((len(X), alphabet_size * len(X[0]))) \n",
    "    for i, dna_sequence in enumerate(X):\n",
    "        for j, base_pair in enumerate(dna_sequence):\n",
    "            index = alphabet_dict[base_pair]\n",
    "            one_hot_matrix[i, alphabet_size * j + index] = 1.0\n",
    "    return one_hot_matrix\n",
    "\n",
    "def one_hot_decode(X): \n",
    "    \"\"\"\n",
    "    Input: X is a one hot encoded list of DNA Sequences represented by the base pairs ACTG. \n",
    "        All DNA Sequences must be the same length\n",
    "    Output: list of dna sequences\n",
    "    Example: one_hot_decode([[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], \n",
    "                            [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]]) = [\"ACT\", \"ACG\"]\n",
    "    \"\"\"\n",
    "    assert(len(X) > 0)\n",
    "    assert(all([len(X[0]) == len(X[i]) for i in range(len(X))]))\n",
    "    alphabet = [\"A\", \"C\", \"T\", \"G\"]\n",
    "    alphabet_size = len(alphabet)\n",
    "    dna_sequences = []\n",
    "    for i, one_hot_sequence in enumerate(X): \n",
    "        dna_sequence = []\n",
    "        for j in range(0, len(one_hot_sequence), 4): \n",
    "            if one_hot_sequence[j]:\n",
    "                dna_sequence.append(\"A\")\n",
    "            elif one_hot_sequence[j + 1]: \n",
    "                dna_sequence.append(\"C\")\n",
    "            elif one_hot_sequence[j + 2]: \n",
    "                dna_sequence.append(\"T\")\n",
    "            elif one_hot_sequence[j + 3]: \n",
    "                dna_sequence.append(\"G\")\n",
    "        dna_sequences.append(\"\".join(dna_sequence))\n",
    "    return np.array(dna_sequences)\n",
    "\n",
    "def normalize(X): \n",
    "    \"\"\" normalize an array \"\"\"\n",
    "    return (X - X.mean()) / X.std()\n",
    "        \n",
    "    \n",
    "def load_gfp_data(gfp_data_path = \"./data/gfp_data.csv\", x_feature = \"nucSequence\", y_feature = \"medianBrightness\", normalize_y = True, test_size = 0.2, shuffle = False):\n",
    "    \"\"\" one hot encodes gfp data into train and test set\"\"\"\n",
    "    df = pd.read_csv(gfp_data_path, index_col = 0)\n",
    "    X = one_hot_encode(df[x_feature].values)\n",
    "    y = df[y_feature].values\n",
    "    if normalize_y: \n",
    "        y = normalize(y)\n",
    "    return train_test_split(X, y, test_size = test_size, shuffle = shuffle)\n",
    " \n",
    "def count_substring_mismatch(s1, s2): \n",
    "    \"\"\" returns the number of misaligned pairs within strings s1 and s2\"\"\"\n",
    "    return sum([i != j for i, j in zip_longest(s1, s2)])\n",
    "   \n",
    "def generate_random_gfp_data_mutations(num_of_mutations_lst, num_per_mutation_count = 1000): \n",
    "    \"\"\"\n",
    "    Input: num_of_mutations_lst is a list defining the count of mutations from the base sequence we want, \n",
    "           num_per_mutation_count is an int defining how many of each mutation count do we want. Often set to the test size\n",
    "    Output: a pandas dataframe comprised of two columns: the number of mutations and the mutation dna sequence\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    total_data_points = len(num_of_mutations_lst) * num_per_mutation_count\n",
    "    assert(total_data_points < 200000)\n",
    "    wild_type_sequence = pd.read_csv(\"./data/gfp_data.csv\")[\"nucSequence\"].values[0]\n",
    "    wild_type_lst = list(wild_type_sequence)\n",
    "    mutation_lst = np.vstack([wild_type_lst] * total_data_points)\n",
    "    mutation_count_lst = np.array([[mutation_count for _ in range(num_per_mutation_count)] for mutation_count in num_of_mutations_lst]).flatten()\n",
    "    \"\"\"\n",
    "    np.testing.assert_array_equal(mutation_lst[0], mutation_lst[1000])\n",
    "    np.testing.assert_array_equal(mutation_lst[0], wild_type_lst)\n",
    "    assert(len(mutation_lst) == total_data_points and len(mutation_count_lst) == len(mutation_lst))\n",
    "    assert(mutation_count_lst[0] == 1 and mutation_count_lst[num_per_mutation_count] == 2 and mutation_count_lst[num_per_mutation_count - 1] == 1)\n",
    "    \"\"\"\n",
    "    bases = \"ACTG\"\n",
    "    index = list(range(0, 4))\n",
    "    base_index_map = dict(zip(bases, index))\n",
    "    index_base_map = dict(zip(index, bases))\n",
    "\n",
    "    for i, mutation_count in enumerate(mutation_count_lst):   \n",
    "        mutation_index = np.random.choice(len(wild_type_sequence), mutation_count, replace = False).tolist()\n",
    "        for j in mutation_index: \n",
    "            k = base_index_map[mutation_lst[i, j]]\n",
    "            new_index = (k + np.random.randint(1, 4)) % 4\n",
    "            mutation_lst[i, j] = index_base_map[new_index] \n",
    "    mutation_sequence_lst = np.array([\"\".join(lst) for lst in mutation_lst])\n",
    "    mutated_df = pd.DataFrame.from_dict({'mutation_count' : mutation_count_lst, 'mutation_sequence' : mutation_sequence_lst})\n",
    "    print(time.time() - start_time)\n",
    "    return mutated_df\n",
    "        \n",
    "def save_gfp_data(X_train, X_test, y_train, y_test): \n",
    "    np.save(\"./data/gfp_x_train.npy\", X_train)\n",
    "    np.save(\"./data/gfp_x_test.npy\", X_test)\n",
    "    np.save(\"./data/gfp_y_train.npy\", y_train)\n",
    "    np.save(\"./data/gfp_y_test.npy\", y_test)\n",
    "    \n",
    "def load_saved_gfp_data(): \n",
    "    X_train = np.load(\"./data/gfp_x_train.npy\")\n",
    "    X_test = np.load(\"./data/gfp_x_test.npy\")\n",
    "    y_train = np.load(\"./data/gfp_y_train.npy\")\n",
    "    y_test = np.load(\"./data/gfp_y_test.npy\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def save_mutated_gfp_data(mutated_df): \n",
    "    mutated_df.to_csv(\"./data/mutated_df.csv\", index = None)\n",
    "    \n",
    "def load_saved_mutated_gfp_data(): \n",
    "    return pd.read_csv(\"./data/mutated_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mutation_df(mutated_df): \n",
    "    for i in range(len(mutated_df)): \n",
    "        assert(mutated_df[\"mutation_count\"].values[i] == count_substring_mismatch(base_sequence, mutated_df[\"mutation_sequence\"].values[i]))\n",
    "    #assert(len(mutated_df) == test_size * len(num_of_mutations_lst))\n",
    "    \n",
    "def test_load_save_mutation_df(mutated_df): \n",
    "    save_mutated_gfp_data(mutated_df)\n",
    "    df_mutated = load_saved_mutated_gfp_data()\n",
    "    np.testing.assert_array_equal(df_mutated.columns, mutated_df.columns)\n",
    "    np.testing.assert_array_equal(df_mutated.index, mutated_df.index)\n",
    "    np.testing.assert_array_equal(df_mutated.values, mutated_df.values)\n",
    "    \n",
    "def test_load_save_gfp_data(X_train, X_test, y_train, y_test):\n",
    "    save_gfp_data(X_train, X_test, y_train, y_test)\n",
    "    train_X, test_X, train_y, test_y = load_saved_gfp_data()\n",
    "    np.testing.assert_array_equal(train_X, X_train)\n",
    "    np.testing.assert_array_equal(test_X, X_test)\n",
    "    np.testing.assert_array_equal(train_y, y_train)\n",
    "    np.testing.assert_array_equal(test_y, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load_save_gfp_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.47991895675659\n"
     ]
    }
   ],
   "source": [
    "num_of_mutations_lst = list(range(1, 10)) + [i * 10 for i in range(1, 6)]\n",
    "test_size = len(X_test)\n",
    "num_per_mutation_count = test_size\n",
    "mutated_df = generate_random_gfp_data_mutations(num_of_mutations_lst=num_of_mutations_lst, num_per_mutation_count=num_per_mutation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mutation_df(mutated_df)\n",
    "test_load_save_mutation_df(mutated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
