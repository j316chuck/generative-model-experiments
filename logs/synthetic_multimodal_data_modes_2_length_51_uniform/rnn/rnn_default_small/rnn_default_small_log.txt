training rnn model.
number of parameters -- 22420.
model args:
**************************************************
save_epochs -- 50
model_type -- rnn
base_log -- logs/synthetic_multimodal_data_modes_2_length_51_uniform/rnn
name -- rnn_default_small
input -- 1020
hidden_size -- 50
latent_dim -- -1
seq_length -- 51
pseudo_count -- 1
n_jobs -- 1
device -- cpu
learning_rate -- 0.001
epochs -- 10
batch_size -- 10
layers -- 1
dataset -- synthetic_multimodal_data_modes_2_length_51_uniform
num_data -- 100
all_characters -- ACDEFGHIKLMNPQRSTVWY
early_stopping -- <early_stopping.EarlyStopping object at 0x118f01c88>
patience -- 10
num_characters -- 20
indexes -- [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
train_loss_history -- []
valid_loss_history -- []
initial_probs_tensor -- []
criterion -- CrossEntropyLoss()
**************************************************
training model on train and validation datasets...
epoch 1, train neg log prob: 147.3452, test neg log probability 145.1107, time: 1.06 sec
epoch 2, train neg log prob: 142.8227, test neg log probability 140.2432, time: 2.07 sec
epoch 3, train neg log prob: 137.4806, test neg log probability 134.3351, time: 3.19 sec
epoch 4, train neg log prob: 131.9871, test neg log probability 129.0083, time: 4.07 sec
epoch 5, train neg log prob: 126.3641, test neg log probability 123.3205, time: 4.84 sec
epoch 6, train neg log prob: 120.1691, test neg log probability 116.7678, time: 5.60 sec
epoch 7, train neg log prob: 113.5328, test neg log probability 110.0688, time: 6.37 sec
epoch 8, train neg log prob: 106.7080, test neg log probability 103.4783, time: 7.13 sec
epoch 9, train neg log prob: 100.0159, test neg log probability 97.3422, time: 7.92 sec
epoch 10, train neg log prob: 93.7081, test neg log probability 91.2550, time: 8.74 sec
**************************************************
evaluating model on test dataset:
total loss: 91.0162
**************************************************
average mismatches per sample: 44.9900
