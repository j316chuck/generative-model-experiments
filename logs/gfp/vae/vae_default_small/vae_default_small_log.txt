Training vae_default_small 
Args:
args -- {'model_type': 'vae', 'base_log': 'logs/gfp/vae/', 'name': 'vae_default_small', 'input': 4998, 'hidden_size': 50, 'latent_dim': 20, 'seq_length': 238, 'pseudo_count': 1, 'n_jobs': 1, 'device': device(type='cpu'), 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 10, 'layers': 1, 'dataset': 'gfp', 'num_data': 100, 'vocabulary': '*ACDEFGHIKLMNPQRSTVWY', 'wild_type': 'SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK*'}
save_epochs -- 50
model_type -- vae
base_log -- logs/gfp/vae/
name -- vae_default_small
input -- 4998
hidden_size -- 50
latent_dim -- 20
device -- cpu
learning_rate -- 0.001
epochs -- 10
all_characters -- *ACDEFGHIKLMNPQRSTVWY
seq_length -- 238
batch_size -- 10
num_characters -- 21
character_to_int -- {'*': 0, 'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}
int_to_character -- {0: '*', 1: 'A', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'P', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'V', 19: 'W', 20: 'Y'}
indexes -- [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
model -- VAE(
  (fc1): Linear(in_features=4998, out_features=50, bias=True)
  (fc21): Linear(in_features=50, out_features=20, bias=True)
  (fc22): Linear(in_features=50, out_features=20, bias=True)
  (fc3): Linear(in_features=20, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=4998, bias=True)
)
optimizer -- Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
train_loss_history -- []
train_recon_loss_history -- []
train_kld_loss_history -- []
valid_loss_history -- []
valid_recon_loss_history -- []
valid_kld_loss_history -- []
**************************************************
training model on train and validation datasets...
--------------------------------------------------
epoch: 1. train loss: 712.2894. train cross entropy loss: 709.2824. train kld loss: 3.0070
time: 0.12 sec. valid loss: 661.6770. valid cross entropy loss: 650.8672, valid kld loss 10.8098
--------------------------------------------------
--------------------------------------------------
epoch: 2. train loss: 547.2715. train cross entropy loss: 512.3722. train kld loss: 34.8993
time: 0.23 sec. valid loss: 382.1397. valid cross entropy loss: 305.2721, valid kld loss 76.8676
--------------------------------------------------
--------------------------------------------------
epoch: 3. train loss: 264.7763. train cross entropy loss: 177.0240. train kld loss: 87.7523
time: 0.33 sec. valid loss: 159.6357. valid cross entropy loss: 89.2595, valid kld loss 70.3762
--------------------------------------------------
--------------------------------------------------
epoch: 4. train loss: 117.2790. train cross entropy loss: 61.5239. train kld loss: 55.7551
time: 0.44 sec. valid loss: 89.8444. valid cross entropy loss: 45.6403, valid kld loss 44.2041
--------------------------------------------------
--------------------------------------------------
epoch: 5. train loss: 74.4698. train cross entropy loss: 36.9438. train kld loss: 37.5259
time: 0.55 sec. valid loss: 68.8779. valid cross entropy loss: 38.3023, valid kld loss 30.5756
--------------------------------------------------
--------------------------------------------------
epoch: 6. train loss: 58.4473. train cross entropy loss: 30.7018. train kld loss: 27.7455
time: 0.66 sec. valid loss: 59.1590. valid cross entropy loss: 34.5074, valid kld loss 24.6517
--------------------------------------------------
--------------------------------------------------
epoch: 7. train loss: 50.8448. train cross entropy loss: 28.1273. train kld loss: 22.7175
time: 0.76 sec. valid loss: 54.4220. valid cross entropy loss: 33.9153, valid kld loss 20.5067
--------------------------------------------------
--------------------------------------------------
epoch: 8. train loss: 47.4377. train cross entropy loss: 27.2809. train kld loss: 20.1568
time: 0.87 sec. valid loss: 52.1220. valid cross entropy loss: 33.5038, valid kld loss 18.6182
--------------------------------------------------
--------------------------------------------------
epoch: 9. train loss: 45.3792. train cross entropy loss: 25.5677. train kld loss: 19.8115
time: 0.99 sec. valid loss: 51.7549. valid cross entropy loss: 35.7130, valid kld loss 16.0419
--------------------------------------------------
--------------------------------------------------
epoch: 10. train loss: 43.9904. train cross entropy loss: 26.2002. train kld loss: 17.7902
time: 1.09 sec. valid loss: 50.7776. valid cross entropy loss: 30.9814, valid kld loss 19.7962
--------------------------------------------------
**************************************************
evaluating model on test dataset:
total loss: 55.5519 cross entropy loss: 35.8150. kld loss: 19.7370
