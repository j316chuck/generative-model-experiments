ctraining rnn model.
number of parameters -- 22420.
model args:
**************************************************
save_epochs -- 50
model_type -- rnn
base_log -- logs/synthetic_multimodal_data_modes_5_length_51_uniform/rnn
name -- rnn_default_small
input -- 1020
hidden_size -- 50
latent_dim -- -1
seq_length -- 51
pseudo_count -- 1
n_jobs -- 1
device -- cpu
learning_rate -- 0.001
epochs -- 10
batch_size -- 10
layers -- 1
dataset -- synthetic_multimodal_data_modes_5_length_51_uniform
num_data -- 100
all_characters -- ACDEFGHIKLMNPQRSTVWY
early_stopping -- <early_stopping.EarlyStopping object at 0x113fb7c18>
patience -- 10
num_characters -- 20
indexes -- [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
train_loss_history -- []
valid_loss_history -- []
initial_probs_tensor -- []
criterion -- CrossEntropyLoss()
**************************************************
training model on train and validation datasets...
epoch 1, train neg log prob: 148.9793, test neg log probability 148.0017, time: 1.55 sec
epoch 2, train neg log prob: 146.1397, test neg log probability 145.2145, time: 2.91 sec
epoch 3, train neg log prob: 142.9000, test neg log probability 141.8494, time: 4.22 sec
epoch 4, train neg log prob: 139.2924, test neg log probability 138.7013, time: 5.40 sec
epoch 5, train neg log prob: 135.6657, test neg log probability 135.3894, time: 6.49 sec
epoch 6, train neg log prob: 131.8532, test neg log probability 132.0829, time: 7.65 sec
epoch 7, train neg log prob: 128.2230, test neg log probability 128.8435, time: 9.13 sec
epoch 8, train neg log prob: 124.5477, test neg log probability 125.3804, time: 10.57 sec
==================================================
Error in running experiment: rnn_default_small
Traceback log: 
==================================================
Traceback (most recent call last):
  File "run_model.py", line 152, in run_experiment
    model.fit(train_dataloader=train_loader, valid_dataloader=valid_loader, verbose=True, logger=logger, save_model=True)
  File "/Users/chuck/Desktop/generative-model-experiments/rnn.py", line 92, in fit
    valid_loss = self.evaluate(valid_dataloader, verbose=False, logger=logger)
  File "/Users/chuck/Desktop/generative-model-experiments/rnn.py", line 113, in evaluate
    output, hidden = self.model(inp[:, c], hidden)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/chuck/Desktop/generative-model-experiments/rnn.py", line 35, in forward
    encoded = self.encoder(input)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/sparse.py", line 118, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py", line 1454, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt
