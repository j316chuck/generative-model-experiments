{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import load_gfp_data, get_all_amino_acids, get_wild_type_amino_acid_sequence, count_substring_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch/blob/master/model.py\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"lstm\", n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input is of shape (batch_size, 1) where each input[x, 0] is the word index\n",
    "        # char RNN so we generate one character at a time. \n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "class GenerativeRNN(): \n",
    "    \n",
    "    def __init__(self, args):     \n",
    "        \"\"\"\n",
    "        Initializes the RNN to be a generative char RNN\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dictionary\n",
    "            defines the hyper-parameters of the neural network\n",
    "        args.name : string \n",
    "            defines the name of the neural network\n",
    "        args.description: string\n",
    "            describes the architecture of the neural network\n",
    "        args.input : int \n",
    "            defines the input/vocabulary size\n",
    "        args.output : int\n",
    "            the number of output layers in the final layer of the neural network\n",
    "        args.layers : int\n",
    "            specifies the number of stacked layers we want in the LSTM\n",
    "        args.hidden_size : int\n",
    "            the size of the hidden layer\n",
    "        args.learning_rate : float\n",
    "            sets the learning rate\n",
    "        args.epochs : int \n",
    "            sets the epoch size \n",
    "        \"\"\"\n",
    "        self.name = args[\"name\"]\n",
    "        self.description = args[\"description\"]\n",
    "        self.input = args[\"input\"]\n",
    "        self.output = args[\"output\"]\n",
    "        self.layers = args[\"layers\"]\n",
    "        self.hidden_size = args[\"hidden_size\"]\n",
    "        self.learning_rate = args[\"learning_rate\"]\n",
    "        self.epochs = args[\"epochs\"]\n",
    "        self.model = RNN(self.input, self.hidden_size, self.output, \"lstm\", self.layers)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.loss_history = []\n",
    "        \n",
    "\n",
    "    def fit(self, dataloader, verbose=True, logger=None, save_model=True):\n",
    "        # amino acid dataset specific checks\n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        three_mutation = \"\".join([int_to_character[np.random.randint(0, num_characters)] if i % 3 == 1 else wild_type[i] for i in range(10)])\n",
    "        ten_mutation = \"\".join([int_to_character[np.random.randint(0, num_characters)] for i in range(10)])\n",
    "        print(wild_type[0:10], three_mutation, ten_mutation)\n",
    "        \n",
    "        if not os.path.isdir(\"./models/{0}\".format(self.name)):\n",
    "            os.mkdir(\"./models/{0}\".format(self.name))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.loss_history = []\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            total_loss = []\n",
    "            for i, (input, target) in enumerate(dataloader):\n",
    "                batch_size, seq_length = input.shape[0], input.shape[1]\n",
    "                hidden = self.model.init_hidden(batch_size)\n",
    "                self.model.zero_grad()\n",
    "                loss = 0\n",
    "                for c in range(seq_length):\n",
    "                    output, hidden = self.model(input[:, c], hidden)\n",
    "                    loss += self.criterion(output.view(batch_size, -1), target[:, c])\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss.append(loss.data[0] / seq_length)\n",
    "            \n",
    "            self.loss_history.append(np.mean(total_loss))\n",
    "            generated_sequence = self.sample(prime_str = \"S\", predict_len = len(wild_type) - 1)\n",
    "            mismatches = count_substring_mismatch(wild_type, generated_sequence)\n",
    "            wild_prob, mutation_three_prob, mutation_ten_prob = self.predict_log_prob(wild_type[1:10]), self.predict_log_prob(three_mutation[1:10]), self.predict_log_prob(ten_mutation[1:10])\n",
    "            \n",
    "            if verbose: \n",
    "                print(\"epoch {0}. loss: {1:.2f}. time: {2:.2f} seconds.\".format(epoch, self.loss_history[-1], time.time() - start_time), file = logger)\n",
    "                print(\"generated sequence: {0}\\n{1} mismatches from the wild type\".format(generated_sequence, mismatches), file = logger) \n",
    "                print(\"wild type log prob: {0}. 3 mutations log prob: {1}. 10 mutations log prob: {2}.\\n\" \\\n",
    "                      .format(wild_prob, mutation_three_prob, mutation_ten_prob), file = logger)\n",
    "            if save_model:\n",
    "                self.save_model(epoch, total_loss)        \n",
    "        \n",
    "        if logger:        \n",
    "            logger.close()\n",
    "\n",
    "    def predict_log_prob(self, sequence, prime_str = \"S\"):\n",
    "        hidden = self.model.init_hidden(1) \n",
    "        prime_input = string_to_tensor(prime_str)\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            _, hidden = self.model(prime_input[p], hidden)\n",
    "        input = prime_input[-1]\n",
    "\n",
    "        log_prob = 0\n",
    "        for char in sequence:\n",
    "            output, hidden = self.model(input.view(1, -1), hidden)\n",
    "            softmax = nn.Softmax(dim = 1)\n",
    "            probs = softmax(output).view(-1)\n",
    "            i = character_to_int[char]\n",
    "            log_prob += np.log(probs[i].item())\n",
    "        return log_prob\n",
    "\n",
    "    def sample(self, predict_len, prime_str = 'S', temperature = 1):\n",
    "        hidden = self.model.init_hidden(1)\n",
    "        prime_input = string_to_tensor(prime_str)\n",
    "        predicted = prime_str\n",
    "\n",
    "        # Use priming string to \"build up\" hidden state\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            output, hidden = self.model(prime_input[p], hidden)\n",
    "        input = prime_input[-1]\n",
    "\n",
    "        for p in range(predict_len):\n",
    "            output, hidden = self.model(input.view(1, -1), hidden)\n",
    "\n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0].item()\n",
    "\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_char = int_to_character[top_i]\n",
    "            predicted += predicted_char\n",
    "            input = string_to_tensor(predicted_char)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(\"./models/{0}/{1}\".format(self.name, model_path))\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    def save_model(self, epoch=None, loss=None): \n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': loss,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                }, \"./models/{0}/checkpoint_{1}.pt\".format(self.name, epoch))\n",
    "\n",
    "    \n",
    "    def show_model(self): \n",
    "        print(self.model)\n",
    "    \n",
    "    def plot_model(self, save_dir, verbose=True): \n",
    "        hidden = self.model.init_hidden(1)\n",
    "        out, _ = self.model(string_to_tensor(\"S\"), hidden)\n",
    "        graph = make_dot(out)\n",
    "        if save_dir is not None:\n",
    "            graph.format = \"png\"\n",
    "            graph.render(save_dir) \n",
    "        if verbose:\n",
    "            graph.view()\n",
    "            \n",
    "    def plot_history(self, save_fig_dir): \n",
    "        plt.figure()\n",
    "        plt.title(\"Training Loss Curve\")\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xticks(range(self.epochs))\n",
    "        if save_fig_dir:\n",
    "            plt.savefig(save_fig_dir)\n",
    "        plt.show()\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = get_all_amino_acids()\n",
    "num_characters = len(all_characters)\n",
    "character_to_int = dict(zip(all_characters, range(num_characters)))\n",
    "int_to_character = dict(zip(range(num_characters), all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for i, c in enumerate(string): \n",
    "        tensor[i] = character_to_int[c]\n",
    "    return tensor\n",
    "\n",
    "def string_to_numpy(string):\n",
    "    arr = np.zeros(len(string))\n",
    "    for i, c in enumerate(string): \n",
    "        arr[i] = character_to_int[c]\n",
    "    return arr\n",
    "    \n",
    "def get_dataloader(X_train, length, n = 100, batch_size = 1, shuffle=True, random=True):\n",
    "    if not random: \n",
    "        data = X_train[0:n]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]        \n",
    "    dataset = np.array([string_to_numpy(x[0:length]) for x in data])\n",
    "    input = torch.from_numpy(dataset[:, :-1]).long()\n",
    "    output = torch.from_numpy(dataset[:, 1:]).long()\n",
    "    tensor_dataset = TensorDataset(input, output)\n",
    "    return DataLoader(tensor_dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "seq_length = len(wild_type)\n",
    "batch_size = 10\n",
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_\")\n",
    "dataloader = get_dataloader(X_train, length=seq_length, n=99, batch_size=batch_size, shuffle=True, random=True)\n",
    "args = {\n",
    "    \"name\" : \"rnn_test_sample\",\n",
    "    \"description\" : \"layers 2, hidden size 200, lr 0.005, epochs 10\",\n",
    "    \"input\" : num_characters,\n",
    "    \"output\" : num_characters,\n",
    "    \"layers\" : 2, \n",
    "    \"hidden_size\" : 200,\n",
    "    \"learning_rate\" : 0.005,\n",
    "    \"epochs\" : 10 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKGEELFTGV SGGETLFAGV HCYRPSRCMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:98: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "rnn = GenerativeRNN(args)\n",
    "logger = open(\"./logs/{0}.txt\".format(args[\"name\"]), \"w\")\n",
    "rnn.fit(dataloader=dataloader, logger=logger)\n",
    "rnn.show_model()\n",
    "rnn.plot_history(\"./logs/{0}_training_history\".format(args[\"name\"]))\n",
    "rnn.plot_model(\"./logs/{0}_model_architecture\".format(args[\"name\"]))\n",
    "temperature_lst = [0.2, 0.8, 1.0, 1.2, 1.8]\n",
    "for temperature in temperature_lst: \n",
    "    generated_sequence = sample(\"S\", seq_length - 1, temperature=temperature)\n",
    "    mismatches = count_substring_mismatch(wild_type, generated_sequence)\n",
    "    print(\"temperature: {0}. generated sequence: {1} with {2} mismatches from the wild type.\".format(temperature, generated_sequence, mismatches)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all_sequences(model, string, base = \"S\", depth = 3): \n",
    "    if depth == 0: \n",
    "        return np.e ** model.predict_log_prob(string, base)\n",
    "    total = 0\n",
    "    for c in all_characters: \n",
    "        total += enumerate_all_sequences(model, string + c, base, depth - 1)\n",
    "    return total\n",
    "\n",
    "for depth in range(1, 4):\n",
    "    for base in \"QRST\":\n",
    "        np.testing.assert_almost_equal(1, enumerate_all_sequences(rnn, \"\", base, depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "load_rnn = GenerativeRNN(args)\n",
    "load_rnn.load_model(\"./checkpoint_{0}.pt\".format(epoch))\n",
    "total_loss = []\n",
    "for i, (input, target) in enumerate(dataloader):\n",
    "    batch_size, seq_length = input.shape[0], input.shape[1]\n",
    "    hidden = load_rnn.model.init_hidden(batch_size)\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        output, hidden = load_rnn.model(input[:, c], hidden)\n",
    "        loss += load_rnn.criterion(output.view(batch_size, -1), target[:, c])\n",
    "    total_loss.append(loss.data[0] / seq_length) \n",
    "print(total_loss)\n",
    "print(torch.load(\"./models/rnn_test_sample/checkpoint_{0}.pt\".format(epoch))[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(prime_str='S', predict_len=seq_length, temperature=1):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = string_to_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp.view(1, -1), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = int_to_character[top_i.item()]\n",
    "        predicted += predicted_char\n",
    "        inp = string_to_tensor(predicted_char)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def predict_log_prob(seq, prime_str=\"S\"):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = string_to_tensor(prime_str)\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    log_prob = 0\n",
    "    for char in seq:\n",
    "        output, hidden = decoder(inp.view(1, -1), hidden)\n",
    "        softmax = nn.Softmax(dim = 1)\n",
    "        probs = softmax(output).view(-1)\n",
    "        i = character_to_int[char]\n",
    "        log_prob += np.log(probs[i].item())\n",
    "    return log_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-8ff032059565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"QRST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate_all_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-210-8ff032059565>\u001b[0m in \u001b[0;36menumerate_all_sequences\u001b[0;34m(string, base, depth)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menumerate_all_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-8ff032059565>\u001b[0m in \u001b[0;36menumerate_all_sequences\u001b[0;34m(string, base, depth)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menumerate_all_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-8ff032059565>\u001b[0m in \u001b[0;36menumerate_all_sequences\u001b[0;34m(string, base, depth)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menumerate_all_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-210-8ff032059565>\u001b[0m in \u001b[0;36menumerate_all_sequences\u001b[0;34m(string, base, depth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menumerate_all_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-162-aa706ab61b26>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seq, prime_str)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharacter_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def enumerate_all_sequences(model, string, base = \"S\", depth = 3): \n",
    "    if depth == 0: \n",
    "        return np.e ** model.predict(string, base)\n",
    "    total = 0\n",
    "    for c in all_characters: \n",
    "        total += enumerate_all_sequences(model, string + c, base, depth - 1)\n",
    "    return total\n",
    "\n",
    "for depth in range(1, 4):\n",
    "    for base in \"QRST\":\n",
    "        np.testing.assert_almost_equal(1, enumerate_all_sequences(model, \"\", base, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKGEELFTGV STGELLFMGV EKGANWIY*I\n",
      "10 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:35: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n",
      "10 237\n",
      "9 237\n"
     ]
    }
   ],
   "source": [
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "three_mutation = \"\".join([int_to_character[np.random.randint(0, num_characters)] if i % 3 == 1 else wild_type[i] for i in range(10)])\n",
    "ten_mutation = \"\".join([int_to_character[np.random.randint(0, num_characters)] for i in range(10)])\n",
    "print(wild_type[0:10], three_mutation, ten_mutation)\n",
    "\n",
    "trial_name = \"rnn_test_sample\"\n",
    "logger = open(\"./logs/{0}.txt\".format(trial_name), \"w\")\n",
    "if not os.path.isdir(\"./models/{0}\".format(trial_name)):\n",
    "    os.mkdir(\"./models/{0}\".format(trial_name))\n",
    "    \n",
    "n_epochs = 10\n",
    "hidden_size = 200\n",
    "n_layers = 2\n",
    "lr = 0.01\n",
    "\n",
    "decoder = RNN(num_characters, hidden_size, num_characters, \"lstm\", n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_time = time.time()\n",
    "all_losses = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss = []\n",
    "    for i, (input, target) in enumerate(dataloader):\n",
    "        batch_size, seq_length = input.shape[0], input.shape[1]\n",
    "        hidden = decoder.init_hidden(batch_size)\n",
    "        loss = 0\n",
    "        for c in range(seq_length - 1):\n",
    "            output, hidden = decoder(input[:, c], hidden)\n",
    "            loss += criterion(output.view(batch_size, -1), target[:, c])\n",
    "        loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        decoder.zero_grad()\n",
    "        total_loss.append(loss.data[0] / (seq_length - 1))\n",
    "    all_losses.append(np.mean(total_loss))\n",
    "    generated_sequence = sample(\"S\", seq_length)\n",
    "    mismatches = count_substring_mismatch(wild_type, generated_sequence)\n",
    "    wild_prob, three_mutations_prob, ten_mutations_prob = np.e ** predict(wild_type[1:10]), np.e ** predict(three_mutation[1:10]), np.e ** predict(ten_mutation[1:10])\n",
    "    print(\"epoch {0}. loss: {1:.2f}. time: {2:.2f} seconds.\".format(epoch, all_losses[-1], time.time() - start_time), file = logger)\n",
    "    print(\"generated sequence: {0}\\n{1} mismatches from the wild type\".format(generated_sequence, mismatches), file = logger) \n",
    "    print(\"wild type probability: {0}. 3 mutations probability: {1}. 10 mutations probability: {2}.\\n\" \\\n",
    "          .format(wild_prob, three_mutations_prob, ten_mutations_prob), file = logger)\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': decoder.state_dict(),\n",
    "                'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                'loss': np.mean(total_loss)\n",
    "            }, \"./models/{0}/checkpoint_{1}.pt\".format(trial_name, epoch))\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNHKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPVGDGPVLLPDNHYLSTQSALSKDPNERRDHMVLLEFVTAAGITHGMDELYK** with 4 mismatches from the wild type\n"
     ]
    }
   ],
   "source": [
    "generated_sequence = sample(\"S\", seq_length, 0.8)\n",
    "print(\"generated sequence: {0} with {1} mismatches from the wild type\".format(generated_sequence, \n",
    "                                                                                 count_substring_mismatch(wild_type, generated_sequence)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK** with 1 mismatches from the wild type\n"
     ]
    }
   ],
   "source": [
    "generated_sequence = sample(\"S\", seq_length, 0.1)\n",
    "print(\"generated sequence: {0} with {1} mismatches from the wild type\".format(generated_sequence, \n",
    "                                                                                 count_substring_mismatch(wild_type, generated_sequence)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: SKGPDFKVSRIGDGHVLLEFVTAAGITHGMDELYK**SERRDHMVLLEFVTAAGITHGMDELYK**NYNKSHNVSHIGFVKTADGILLGIELRYNYNRHNVVIMDGKRKFATRVGLGELKFIGTGLVLPVNWSRIELKGIDLSHKQEYSVRSGEIGGYVQERTIFFKDDGNYKTCGKILGVNGRKEFTAGITHLDEGYPVQRAYYRDHKRQRDFSKSAMPEGYVQERTIFFKDDGDYKT with 224 mismatches from the wild type\n"
     ]
    }
   ],
   "source": [
    "generated_sequence = sample(\"S\", seq_length, 1.4)\n",
    "print(\"generated sequence: {0} with {1} mismatches from the wild type\".format(generated_sequence, \n",
    "                                                                                 count_substring_mismatch(wild_type, generated_sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "n_epochs = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "trial_name = \"rnn_small_sample\"\n",
    "logger = open(\"./logs/{0}.txt\".format(trial_name), \"a\")\n",
    "if not os.path.isdir(\"./models/{0}\".format(trial_name)):\n",
    "    os.mkdir(\"./models/{0}\".format(trial_name))\n",
    "    \n",
    "decoder = RNN(num_characters, hidden_size, num_characters, \"lstm\", n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_time = time.time()\n",
    "all_losses = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss = []\n",
    "    for i, (input, target) in enumerate(dataloader):\n",
    "        hidden = decoder.init_hidden(batch_size)\n",
    "        loss = 0\n",
    "        for c in range(seq_length - 1):\n",
    "            output, hidden = decoder(input[:, c], hidden)\n",
    "            loss += criterion(output.view(batch_size, -1), target[:, c])\n",
    "        loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        decoder.zero_grad()\n",
    "        total_loss.append(loss.data[0] / (seq_length - 1))\n",
    "    print(total_loss, file=logger)\n",
    "    all_losses.append(np.mean(total_loss))\n",
    "    print(\"epoch {0}. loss: {1:.2f}. time: {2:.2f} seconds.\".format(epoch, all_losses[-1], time.time() - start_time), file=logger)\n",
    "    generated_sequence = sample(\"S\", seq_length)\n",
    "    print(\"generated sequence: {0}\\n{1} mismatches from the wild type\".format(generated_sequence, \n",
    "                                                                        count_substring_mismatch(wild_type, generated_sequence)), file=logger)\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'loss': np.mean(total_loss)\n",
    "        }, \"./models/{0}/checkpoint_{1}.pt\".format(trial_name, epoch))\n",
    "    \n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. print to file the epoch the time it took and the loss, print out a generated sample and the mismatches (DONE)\n",
    "2. plot history (DONE)\n",
    "3. save model every epoch, load model at end, plot model architecture (DONE)\n",
    "4. tensorboard going (DONE)\n",
    "5. code it into class (DONE)\n",
    "6. Write tests 10 min \n",
    "7. debug \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeRNN(\n",
       "  (encoder): Embedding(21, 100)\n",
       "  (rnn): LSTM(100, 100)\n",
       "  (decoder): Linear(in_features=100, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(trial_name, epoch):\n",
    "    checkpoint = torch.load(\"./models/{0}/checkpoint_{1}.pt\".format(trial_name, epoch))\n",
    "    decoder = RNN(num_characters, hidden_size, num_characters, \"lstm\", n_layers)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "    decoder.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    decoder_optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    return decoder, decoder_optimizer\n",
    "\n",
    "decoder, decoder_optimizer = load_model(trial_name, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(save_dir, verbose=True):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    out, _ = decoder(string_to_tensor(\"S\"), hidden)\n",
    "    graph = make_dot(out)\n",
    "    if save_dir is not None:\n",
    "        graph.format = \"png\"\n",
    "        graph.render(save_dir) \n",
    "    if verbose:\n",
    "        graph.view()\n",
    "        \n",
    "plot_model(\"./logs/{0}\".format(trial_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss Training Curve\")\n",
    "plt.plot(all_losses)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
