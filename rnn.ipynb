{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import load_gfp_data, get_all_amino_acids, get_wild_type_amino_acid_sequence \n",
    "from utils import count_substring_mismatch, string_to_tensor, string_to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch/blob/master/model.py\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"lstm\", n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input is of shape (batch_size, 1) where each input[x, 0] is the word index\n",
    "        # char RNN so we generate one character at a time. \n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "class GenerativeRNN(): \n",
    "    \n",
    "    def __init__(self, args):     \n",
    "        \"\"\"\n",
    "        Initializes the RNN to be a generative char RNN\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dictionary\n",
    "            defines the hyper-parameters of the neural network\n",
    "        args.name : string \n",
    "            defines the name of the neural network\n",
    "        args.description: string\n",
    "            describes the architecture of the neural network\n",
    "        args.layers : int\n",
    "            specifies the number of stacked layers we want in the LSTM\n",
    "        args.hidden_size : int\n",
    "            the size of the hidden layer\n",
    "        args.learning_rate : float\n",
    "            sets the learning rate\n",
    "        args.epochs : int \n",
    "            sets the epoch size \n",
    "        args.vocabulary : string\n",
    "            all the characters in the context of the problem\n",
    "        \"\"\"\n",
    "        self.name = args[\"name\"]\n",
    "        self.description = args[\"description\"]\n",
    "        self.layers = args[\"layers\"]\n",
    "        self.hidden_size = args[\"hidden_size\"]\n",
    "        self.learning_rate = args[\"learning_rate\"]\n",
    "        self.epochs = args[\"epochs\"]\n",
    "        self.all_characters = args[\"vocabulary\"]\n",
    "        self.num_characters = len(self.all_characters)\n",
    "        self.character_to_int = dict(zip(self.all_characters, range(self.num_characters)))\n",
    "        self.int_to_character = dict(zip(range(self.num_characters), self.all_characters))\n",
    "        self.model = RNN(self.num_characters, self.hidden_size, self.num_characters, \"lstm\", self.layers)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.loss_history = []\n",
    "        \n",
    "\n",
    "    def fit(self, dataloader, verbose=True, logger=None, save_model=True):\n",
    "        # amino acid dataset specific checks\n",
    "        wild_type = get_wild_type_amino_acid_sequence()\n",
    "        three_mutation = \"\".join([self.int_to_character[np.random.randint(0, self.num_characters)] if i % 3 == 1 else wild_type[i] for i in range(10)])\n",
    "        ten_mutation = \"\".join([self.int_to_character[np.random.randint(0, self.num_characters)] for i in range(10)])\n",
    "        print(wild_type[0:10], three_mutation, ten_mutation, file=logger)\n",
    "        \n",
    "        if not os.path.isdir(\"./models/{0}\".format(self.name)):\n",
    "            os.mkdir(\"./models/{0}\".format(self.name))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.loss_history = []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            total_loss = []\n",
    "            for i, (input, target) in enumerate(dataloader):\n",
    "                batch_size, seq_length = input.shape[0], input.shape[1]\n",
    "                hidden = self.model.init_hidden(batch_size)\n",
    "                self.model.zero_grad()\n",
    "                \n",
    "                loss = 0\n",
    "                for c in range(seq_length):\n",
    "                    output, hidden = self.model(input[:, c], hidden)\n",
    "                    loss += self.criterion(output.view(batch_size, -1), target[:, c])\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss.append(loss.item() / seq_length)\n",
    "            \n",
    "            self.loss_history.append(np.mean(total_loss))\n",
    "            generated_sequence = self.sample(predict_len = len(wild_type) - 1, prime_str = \"S\",)\n",
    "            mismatches = count_substring_mismatch(wild_type, generated_sequence)\n",
    "            wild_prob, mutation_three_prob, mutation_ten_prob = self.predict_log_prob(wild_type[1:10]), self.predict_log_prob(three_mutation[1:10]), self.predict_log_prob(ten_mutation[1:10])\n",
    "            \n",
    "            if verbose: \n",
    "                print(\"epoch {0}. loss: {1:.2f}. time: {2:.2f} seconds.\".format(epoch, self.loss_history[-1], time.time() - start_time), file = logger)\n",
    "                print(\"generated sequence: {0}\\n{1} mismatches from the wild type\".format(generated_sequence, mismatches), file = logger) \n",
    "                print(\"wild type log prob: {0}. 3 mutations log prob: {1}. 10 mutations log prob: {2}.\\n\" \\\n",
    "                      .format(wild_prob, mutation_three_prob, mutation_ten_prob), file = logger)\n",
    "            if save_model:\n",
    "                self.save_model(epoch, total_loss)        \n",
    "\n",
    "    def predict_log_prob(self, sequence, prime_str = \"S\"):\n",
    "        hidden = self.model.init_hidden(1) \n",
    "        prime_input = string_to_tensor(prime_str, self.character_to_int)\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            _, hidden = self.model(prime_input[p], hidden)\n",
    "        input = prime_input[-1]\n",
    "\n",
    "        log_prob = 0\n",
    "        for char in sequence:\n",
    "            output, hidden = self.model(input.view(1, -1), hidden)\n",
    "            softmax = nn.Softmax(dim = 1)\n",
    "            probs = softmax(output).view(-1)\n",
    "            i = self.character_to_int[char]\n",
    "            log_prob += np.log(probs[i].item())\n",
    "        return log_prob\n",
    "\n",
    "    def sample(self, predict_len, prime_str = 'S', temperature = 1):\n",
    "        hidden = self.model.init_hidden(1)\n",
    "        prime_input = string_to_tensor(prime_str, self.character_to_int)\n",
    "        predicted = prime_str\n",
    "\n",
    "        # Use priming string to \"build up\" hidden state\n",
    "        for p in range(len(prime_str) - 1):\n",
    "            output, hidden = self.model(prime_input[p], hidden)\n",
    "        input = prime_input[-1]\n",
    "\n",
    "        for p in range(predict_len):\n",
    "            output, hidden = self.model(input.view(1, -1), hidden)\n",
    "\n",
    "            # Sample from the network as a multinomial distribution\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0].item()\n",
    "\n",
    "            # Add predicted character to string and use as next input\n",
    "            predicted_char = self.int_to_character[top_i]\n",
    "            predicted += predicted_char\n",
    "            input = string_to_tensor(predicted_char, self.character_to_int)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(\"./models/{0}/{1}\".format(self.name, model_path))\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    \n",
    "    def save_model(self, epoch=None, loss=None): \n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': loss,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                }, \"./models/{0}/checkpoint_{1}.pt\".format(self.name, epoch))\n",
    "\n",
    "    \n",
    "    def show_model(self): \n",
    "        print(self.model)\n",
    "    \n",
    "    def plot_model(self, save_dir, verbose=True): \n",
    "        hidden = self.model.init_hidden(1)\n",
    "        out, _ = self.model(string_to_tensor(\"S\", self.character_to_int), hidden)\n",
    "        graph = make_dot(out)\n",
    "        if save_dir is not None:\n",
    "            graph.format = \"png\"\n",
    "            graph.render(save_dir) \n",
    "        if verbose:\n",
    "            graph.view()\n",
    "            \n",
    "    def plot_history(self, save_fig_dir): \n",
    "        plt.figure()\n",
    "        plt.title(\"Training Loss Curve\")\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xticks(range(self.epochs))\n",
    "        if save_fig_dir:\n",
    "            plt.savefig(save_fig_dir)\n",
    "        plt.show()\n",
    "    \n",
    "def get_test_args():\n",
    "    args = {\n",
    "        \"name\" : \"rnn_test_sample\",\n",
    "        \"layers\" : 2, \n",
    "        \"hidden_size\" : 200,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"epochs\" : 10,\n",
    "        \"vocabulary\" : get_all_amino_acids(),\n",
    "        \"num_data\" : 100, \n",
    "        \"batch_size\" : 10\n",
    "    }\n",
    "    args[\"description\"] = \"name: {0}, layers {1}, hidden size {2}, lr {3}, epochs {4}\".format(args[\"name\"], \n",
    "                            args[\"layers\"], args[\"hidden_size\"], args[\"learning_rate\"], args[\"epochs\"])\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. print to file the epoch the time it took and the loss, print out a generated sample and the mismatches (DONE)\\n2. plot history (DONE)\\n3. save model every epoch, load model at end, plot model architecture (DONE)\\n4. tensorboard going (DONE)\\n5. code it into class (DONE)\\n6. debug (DONE)\\n7. Write tests 10 min (DONE)\\n8. code it into python file. ** try not to rely on global variables, make everything OOP. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. print to file the epoch the time it took and the loss, print out a generated sample and the mismatches (DONE)\n",
    "2. plot history (DONE)\n",
    "3. save model every epoch, load model at end, plot model architecture (DONE)\n",
    "4. tensorboard going (DONE)\n",
    "5. code it into class (DONE)\n",
    "6. debug (DONE)\n",
    "7. Write tests 10 min (DONE)\n",
    "8. code it into python file. ** try not to rely on global variables, make everything OOP. \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(X_train, length, character_to_int, n = 100, batch_size = 1, shuffle=True, random=True):\n",
    "    if not random: \n",
    "        data = X_train[0:n]\n",
    "    else: \n",
    "        indexes = np.random.choice(len(X_train), n)\n",
    "        data = X_train[indexes]        \n",
    "    dataset = np.array([string_to_numpy(x[0:length], character_to_int) for x in data])\n",
    "    input = torch.from_numpy(dataset[:, :-1]).long()\n",
    "    output = torch.from_numpy(dataset[:, 1:]).long()\n",
    "    tensor_dataset = TensorDataset(input, output)\n",
    "    return DataLoader(tensor_dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "\n",
    "wild_type = get_wild_type_amino_acid_sequence()\n",
    "seq_length = len(wild_type)\n",
    "batch_size = 10\n",
    "X_train, X_test, y_train, y_test = load_gfp_data(\"./data/gfp_amino_acid_\")\n",
    "char_to_int = dict(zip(get_all_amino_acids(), range(len(get_all_amino_acids()))))\n",
    "dataloader = get_dataloader(X_train, length=seq_length, character_to_int=char_to_int, n=99, batch_size=batch_size, shuffle=True, random=True)\n",
    "args = get_test_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKGEELFTGV SDGERLFNGV FQMSYEPYKT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:99: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (encoder): Embedding(21, 200)\n",
      "  (rnn): LSTM(200, 200, num_layers=2)\n",
      "  (decoder): Linear(in_features=200, out_features=21, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYXHWd7/H3p6qXLN3ZKwGyEEjSgSAIGCOIpLksisjAuI3g6OCMDuOVGdfHZRx17lWvozM+OuNyVRQdVES8LqOyqOBAAsoWImtCFkJIwpJ09nSSXut7/6iTTqfJ0unk9Knq+rye5zxddc6vz/lWP0l96vzOr35HEYGZmRlALusCzMysfDgUzMysh0PBzMx6OBTMzKyHQ8HMzHo4FMzMrIdDwSqKpLykVknTjmZbMytxKFiqkjflPUtR0u5ez//ycPcXEd0R0RARa45m28Ml6bOS/vNo77efx5akD0h6QtJOSesk/UTSS7Kox4aWmqwLsKEtIhr2PJa0GnhXRNxxoPaSaiKiazBqq2BfBy4C/hb4I6X/x28ELgEeP5wd+e9tfflMwTKVfOK+SdKNknYAb5N0tqT7JG2V9Lykr0iqTdrXSApJ05PnP0y23yZph6R7JZ1wuG2T7a+VtFzSNklflfQHSe8YwGs6RdKCpP7HJL2u17ZLJS1Njr9O0geS9RMl3Zr8zmZJCw+w75OBvwPeEhF3RURHROyKiB9ExL8mbe7pXbekd0m6q8/f5D2SVgJPSvq2pM/3Oc4tkt6bPJ4i6ReSWiQ9Lemaw/2bWOVwKFg5eD3wI2A0cBPQBbwPmACcA1xM6Y3wQN4KfBIYB6wBPnO4bSVNBH4CfDg57tPAvMN9IZLqgJuBW4AC8AHgJkkzkybfA94ZEY3AacCCZP2HgVXJ7xwDfOIAh7gAWB0Riw+3tj4uA14OnArcCFwhSclrGA+cn9SdS17Pg8BkSmcoH5Z0wREe38qUQ8HKwT0R8euIKEbE7oh4MCLuj4iuiFgFXAs0H+T3fxoRiyKiE7gBOH0AbS8FHo6IXybbvgxsHMBrOQeoA/4tIjqTrrLbgCuS7Z3AHEmNEbG515t7J3AcMC359L/fMwVgPPD8AOrq63MRsSUidgN3AbXA2cm2vwDujoj1ybpREfG5pK6VwHW9Xo8NMQ4FKwdrez+RdFLSffGCpO3Apyl9ej+QF3o93gU0HKjhQdoe17uOKM0Uua4ftfd1HLAm9p1p8hlKn7KhdFZ0GbBG0l2SXpGs/3zS7veSnpL04QPsfxNw7ADq6qv3ay1SOkO7Mln1VkqBCXA8MC3p1toqaSvwEUpnMzYEORSsHPSdqvdblC6YzoyIUcCnAKVcw/PAlD1Pkq6UyQdufkDPAVP3dMUkpgHPAiRnQJcBEyl1y/w4Wb89Ij4QEdOBPwc+Kml/Z0e/B6ZLOuMgNewERvR6vr838L5/8xuBNyfXWM4Efp6sXwusiIgxvZbGiPizgxzfKphDwcpRI7AN2NnrwmrabgbOlPRnkmooXdMoHOJ38pKG9VrqKY0G6gI+JKlW0vmURgXdJGm4pLdKGpV0Ue0AigDJcWckYbIN6N6zrbeIWEqpO+0mSc2S6nrtd8/ZxcPAG5P1TcDfHOrFR8SDwPZk37dGxI5k071Ah6QPJa8xL+lUSS871D6tMjkUrBx9CLiK0pvmtyh1baQq6T9/C/AlSl00M4A/Ae0H+bW3Abt7Lcsioh34M+ByStckvgK8NSJWJL9zFfBM0i32zmQfALOB/wZagT8A/xERdx/guNcA30iWLcAKSl1StyTbv0jpTGAD8F3gh/36I5TOFi6kdNEfgGS46iWULrqvTl7Tt4BR/dynVRj5JjtmLyYpT6kr6E0HeXM2G3J8pmCWkHSxpDFJN9AnKY0IeiDjsswGlUPBbK9XUfquQAvwGuD1SXeQWdVw95GZmfXwmYKZmfWouAnxJkyYENOnT8+6DDOzivLQQw9tjIhDDbOuvFCYPn06ixYtyroMM7OKIumZ/rRz95GZmfVwKJiZWQ+HgpmZ9XAomJlZD4eCmZn1cCiYmVmP1EJB0lRJd0paIukJSe/bT5vzkvvhPpwsn0qrHjMzO7Q0v6fQBXwoIhZLagQeknR7RCzp0+7uiLg0xToAWL5+Bzc9uJYPv2Y2w2rzaR/OzKwipXamEBHP77n/bHLDjqUM7E5WR8W6Lbu47p6nWbR6S1YlmJmVvUG5piBpOnAGcP9+Np8t6RFJt0k6Ja0azjpxPHX5HAuWb0jrEGZmFS/1UJDUAPwMeH9EbO+zeTFwfES8FPgq8F8H2MfVkhZJWtTS0jKgOkbU1TDvhHEsWD6w3zczqwaphoKkWkqBcENE/Lzv9uRm5a3J41uBWkkT9tPu2oiYGxFzC4VDzud0QM1NBZavb+W5rbsHvA8zs6EszdFHAq4DlkbElw7Q5pikHZLmJfVsSqum5tmlQFnoswUzs/1Kc/TROcDbgcckPZys+zgwDSAivgm8Cfifkroo3fj8ikjxrj+zJjZwzKhhLFzRwhXzpqV1GDOzipVaKETEPYAO0eZrwNfSqqEvSTQ3Fbj18efp6i5Sk/d398zMequ6d8Xm2QV2tHXx8NqtWZdiZlZ2qi4Uzpk5gXxOHoVkZrYfVRcKo4fXcsbUMQ4FM7P9qLpQgNLQ1Mee3cam1vasSzEzKytVGQrzmwpEwD0rN2ZdiplZWanKUDh18mjGjaxjwTJ3IZmZ9VaVoZDLiXNnTWDhihaKxdS+FmFmVnGqMhSgdF1hY2sHS57vOx2TmVn1qtpQOHdWacoLj0IyM9urakOh0FjPSyaP8nUFM7NeqjYUAObPKrB4zRa2t3VmXYqZWVmo6lBobirQVQz+uDK1iVnNzCpKVYfCmcePpaG+xtcVzMwSVR0Ktfkc58wcz8LlLaQ4Y7eZWcWo6lAAaG6ayLNbd/NUS2vWpZiZZa7qQ2F+U+nun3d5FJKZmUNhytgRzCiMZOEKz4NkZlb1oQClLqT7V22irbM761LMzDLlUKB0N7b2riL3rfLQVDOrbg4F4BUnjKO+JuehqWZW9RwKwLDaPGedON6hYGZVz6GQaG4qsKplJ2s378q6FDOzzDgUEvObSrOmLlzhswUzq14OhcSMwkgmjxnuWVPNrKo5FBKSaJ5d4I9PbaKjq5h1OWZmmXAo9NLcVKC1vYvFa7ZkXYqZWSYcCr28csZ4anLyKCQzq1oOhV4ah9XysuPH+rqCmVUth0If85sKLHl+Oxt2tGVdipnZoHMo9NGcDE29e7knyDOz6uNQ6GPOsaOY0FDv6wpmVpUcCn3kcmJ+0wTuXtFCd9F3YzOz6pJaKEiaKulOSUskPSHpfftpI0lfkbRS0qOSzkyrnsPR3FRgy65OHnt2W9almJkNqjTPFLqAD0XEHOAs4BpJc/q0eS0wK1muBr6RYj39du6sAhIehWRmVSe1UIiI5yNicfJ4B7AUmNyn2eXA96PkPmCMpGPTqqm/xo2s47TJoz0PkplVnUG5piBpOnAGcH+fTZOBtb2er+PFwYGkqyUtkrSopWVw3qibmwr8ac0Wtu3qHJTjmZmVg9RDQVID8DPg/RGxfSD7iIhrI2JuRMwtFApHt8ADaJ5doBhwz0oPTTWz6pFqKEiqpRQIN0TEz/fT5Flgaq/nU5J1mXvplDGMGlbDguUbsi7FzGzQpDn6SMB1wNKI+NIBmv0K+KtkFNJZwLaIeD6tmg5HTT7HubMKLFjeQoSHpppZdUjzTOEc4O3A+ZIeTpZLJL1b0ruTNrcCq4CVwLeB96RYz2Frbiqwfns7y9bvyLoUM7NBUZPWjiPiHkCHaBPANWnVcKR67sa2vIWTjhmVcTVmZunzN5oP4pjRw5g9qdFTXphZ1XAoHELz7AIPPr2Fne1dWZdiZpY6h8IhNDcV6Oguct+qTVmXYmaWOofCIcydPpbhtXl3IZlZVXAoHEJ9TZ5XzhjvUDCzquBQ6Ifm2QWe2bSL1Rt3Zl2KmVmqHAr9MH9WMjTVE+SZ2RDnUOiH6RNGcvz4EZ5K28yGPIdCPzU3FfjjU5to7+rOuhQzs9Q4FPqpuanA7s5uFq3eknUpZmapcSj001knjqcun/MoJDMb0hwK/TSyvoaXnzCWhQ4FMxvCHAqHYf6sAk++sIMXtrVlXYqZWSocCoehefbeWVPNzIYih8JhmD2pkUmj6n1dwcyGLIfCYZBEc1OBu1e00NVdzLocM7OjzqFwmJqbJrK9rYtH1m3NuhQzs6POoXCYXjVzAjnBguUbsy7FzOyocygcptEjajl96hhfVzCzIcmhMADNTRN5dN1WNu/syLoUM7OjyqEwAM2zC0TA3Z411cyGGIfCAJw6eTRjR9S6C8nMhhyHwgDkc+LcWQUWLt9IsRhZl2NmdtQ4FAaouanAxtZ2lr6wPetSzMyOGofCAJ3bNAHAXUhmNqQ4FAZoYuMw5hw7yndjM7MhxaFwBJpnF3jomS3saOvMuhQzs6PCoXAEmpsKdBWDPz61KetSzMyOCofCEThz2lga6mt8XcHMhgyHwhGoq8nxyhnjWbi8hQgPTTWzyudQOELzmwqs27KbVRt3Zl2KmdkRcygcoeam0t3YPArJzIaC1EJB0nclbZD0+AG2nydpm6SHk+VTadWSpqnjRnBiYaSvK5jZkJDmmcJ/Ahcfos3dEXF6snw6xVpS1dxU4L5Vm2jr7M66FDOzI5JaKETEQmBzWvsvJ81NBdq7itz/dFW8XDMbwrK+pnC2pEck3SbplAM1knS1pEWSFrW0lF83zVknjqe+JsdCdyGZWYXLMhQWA8dHxEuBrwL/daCGEXFtRMyNiLmFQmHQCuyvYbV55p0wztcVzKziZRYKEbE9IlqTx7cCtZImZFXPkWpuKrByQyvrtuzKuhQzswHLLBQkHSNJyeN5SS0VO1/EebNLZzALl2/MuBIzs4FLc0jqjcC9wGxJ6yS9U9K7Jb07afIm4HFJjwBfAa6ICv5a8IxCA5PHDGfB8g1Zl2JmNmA1ae04Iq48xPavAV9L6/iDTRLzmwr8+pHn6OwuUpvP+hq+mdnh8zvXUdTcVKC1vYs/rdmadSlmZgPiUDiKXjlzPPmc3IVkZhXLoXAUjRpWy8umjfXQVDOrWA6Fo6x5doHHn91Oy472rEsxMzts/QoFSe+TNEol10laLOnVaRdXifbMmnr3Cp8tmFnl6e+Zwt9ExHbg1cBY4O3A51OrqoLNOXYUExrq3IVkZhWpv6Gg5OclwA8i4ole66yXXE7Mn1Xg7hUbKRYr9msXZlal+hsKD0n6HaVQ+K2kRqCYXlmVbX5Tgc07O3j8uW1Zl2Jmdlj6GwrvBD4GvDwidgG1wF+nVlWFO3fWBCTfjc3MKk9/Q+FsYFlEbJX0NuATgD8GH8D4hnpOnTza1xXMrOL0NxS+AeyS9FLgQ8BTwPdTq2oIaG4qsHjNFrbt6sy6FDOzfutvKHQlk9VdDnwtIr4ONKZXVuVrbipQDPjDU5411cwqR39DYYekf6Q0FPUWSTlK1xXsAE6fOobGYTW+G5uZVZT+hsJbgHZK31d4AZgC/FtqVQ0BNfkcr5o5gQXLW6jgGcHNrMr0KxSSILgBGC3pUqAtInxN4RCamwo8v62NFRtasy7FzKxf+jvNxV8ADwBvBv4CuF/Sm9IsbCiYn0x54aGpZlYp+tt99E+UvqNwVUT8FTAP+GR6ZQ0Nx40ZTtOkBg9NNbOK0d9QyEVE75sEbDqM361qzU0FHnh6M7s6urIuxczskPr7xv4bSb+V9A5J7wBuAW5Nr6yho7lpIh3dRe5ftTnrUszMDqm/F5o/DFwLnJYs10bER9MsbKiYO30sw2pz7kIys4pQ09+GEfEz4Gcp1jIkDavNc/aJ4x0KZlYRDnqmIGmHpO37WXZI2j5YRVa65qYCT2/cyTObdmZdipnZQR00FCKiMSJG7WdpjIhRg1VkpWuePRHA3242s7LnEUSDYPr4EUwbN8JdSGZW9hwKg0ASzU0F/vjUJjq6fG8iMytfDoVBMr+pwK6ObhY946GpZla+HAqD5OwZ46nNy11IZlbWHAqDpKG+hrnHj/M8SGZW1hwKg6h5doEnX9jB+u1tWZdiZrZfDoVB1Lxn1lR3IZlZmXIoDKKTjmlkYmO9v69gZmXLoTCIJDG/qcDC5S20tnvWVDMrP6mFgqTvStog6fEDbJekr0haKelRSWemVUs5+ctXTGN7WxffvOuprEsxM3uRNM8U/hO4+CDbXwvMSpargW+kWEvZOGPaWC4//Ti+ffcq1m3ZlXU5Zmb7SC0UImIhcLBval0OfD9K7gPGSDo2rXrKyUcvPgkJvvCbZVmXYma2jyyvKUwG1vZ6vi5Z9yKSrpa0SNKilpbKv0h73JjhXD1/Br9+5Dke8jeczayMVMSF5oi4NiLmRsTcQqGQdTlHxbubT2TSqHo+ffNSisXIuhwzMyDbUHgWmNrr+ZRkXVUYUVfDR15zEo+s3covH6mal21mZS7LUPgV8FfJKKSzgG0R8XyG9Qy6158xmdOmjOYLty1jV4eHqJpZ9tIcknojcC8wW9I6Se+U9G5J706a3AqsAlYC3wbek1Yt5SqXE5+8dA4vbG/j2oWrsi7HzKz/92g+XBFx5SG2B3BNWsevFC+fPo7XnXYs31zwFG95+VSOHT0865LMrIpVxIXmoe5jF59EMeBfPUTVzDLmUCgDU8eN4F2vOoFf/OlZHl67NetyzKyKORTKxHv+x0wmNNTz6V8/Qalnzcxs8DkUykRDfQ0fec1sFq/Zyq8frapBWGZWRhwKZeSNL5vCnGNH8YXbnqStszvrcsysCjkUykg+GaL67NbdfOduD1E1s8HnUCgzZ88Yz8WnHMP/vesp37bTzAadQ6EM/eMlJ9HVHXzxtx6iamaDy6FQho4fP5K/Pmc6P128jsfWbcu6HDOrIg6FMnXN+TMZN6KOz9y8xENUzWzQOBTK1KhhtXzw1U08sHozv3n8hazLMbMq4VAoY2+ZO5WTjmnkc7ct9RBVMxsUDoUyVpPP8clL57B2826+94fVWZdjZlXAoVDmzpk5gQtPnsjX71xJy472rMsxsyHOoVABPn7JybR1dvOl2z1E1czS5VCoACcWGrjqldP58YNrWfLc9qzLMbMhzKFQId57/izGDK/1EFUzS5VDoUKMHlHLBy5q4t5Vm7h9yfqsyzGzIcqhUEHeOm8asyY28Llbl9LRVcy6HDMbghwKFaQmn+OfXncyqzft4vv3rs66HDMbghwKFea82RM5b3aB//j9Cja1eoiqmR1dDoUK9InXncyujm6+fMfyrEsxsyHGoVCBZk5s5G2vmMaP7l/Dshd2ZF2OmQ0hDoUK9f4Lm2ior+Gzt3iIqpkdPQ6FCjV2ZB3vv7CJu1ds5M5lG7Iux8yGCIdCBXv72cdz4oSRfPaWpXR2e4iqmR05h0IFq02GqK5q2ckP73sm63LMbAhwKFS480+ayLmzJvDvd6xg666OrMsxswrnUKhwkvjE6+awo62Tf79jRdblmFmFcygMAbOPaeTKedP4wX3PsHKDh6ia2cA5FIaID17UxIjaPP/nlqVZl2JmFcyhMESMb6jnHy6YyZ3LWliwvCXrcsysQqUaCpIulrRM0kpJH9vP9ndIapH0cLK8K816hrqrXjmd48eP4LM3L6HLQ1TNbABSCwVJeeDrwGuBOcCVkubsp+lNEXF6snwnrXqqQX1Nno9fcjIrNrRy4wNrsi7HzCpQmmcK84CVEbEqIjqAHwOXp3g8A149ZxJnnTiOL92+nG27O7Mux8wqTJqhMBlY2+v5umRdX2+U9Kikn0qaur8dSbpa0iJJi1pa3F9+MJL45KVz2Lq7k6/+3kNUzezwZH2h+dfA9Ig4DbgduH5/jSLi2oiYGxFzC4XCoBZYiU45bjRvmTuV6+9dzdMbd2ZdjplVkDRD4Vmg9yf/Kcm6HhGxKSL23CnmO8DLUqynqnzw1U3U5XN87lYPUTWz/kszFB4EZkk6QVIdcAXwq94NJB3b6+llgN/BjpKJjcO45vyZ3L5kPX9YuTHrcsysQqQWChHRBfw98FtKb/Y/iYgnJH1a0mVJs/dKekLSI8B7gXekVU81+ptzTmDK2OF85uYldBd9zwUzOzRV2g1a5s6dG4sWLcq6jIpxy6PPc82PFvMvbziVK+dNy7ocM8uIpIciYu6h2mV9odlSdsmpx/Dy6WP54m+Xsb3NQ1TN7OAcCkOcJD516Sls3tXB1+9cmXU5ZlbmHApV4NQpo3nDGVP43j2rWbNpV9blmFkZcyhUiY9cPJt8TvzLbR7gZWYH5lCoEpNGDeM9583gtsdf4L5Vm7Iux8zKlEOhivzt/BM5bvQwD1E1swNyKFSRYbV5Pvrak3jiue38bPG6rMsxszLkUKgyl730OM6YNoZ/++0yWtu7si7HzMqMQ6HKlIaozqFlRzuf+uXjnjDPzPZRk3UBNvjOmDaWq84+nuvvfYafL36WGYWRXDhnEhedPIkzpo0ln1PWJZpZRjzNRRVbu3kXv1+6njuWbuC+VZvoKgbjRtZx/kkTufDkSZw7awIj6/25wWwo6O80Fw4FA2B7WycLlrVwx9L13PnkBra3dVFXk+OcGeO5cM4kLjx5EpNGDcu6TDMbIIeCDVhnd5EHV2/mjiUbuH3pC6zdvBuA06aM5sKTSwFx8rGNSO5mMqsUDgU7KiKCFRtauX3Jeu5Yup6H124lAiaPGc5FyRnEvBPGUVfjMQtm5cyhYKnYsKONO5/cwO1LNnDPyhbaOos01tfQPLvARXMmcV7TREaPqM26TDPrw6Fgqdvd0c0fVm7kjuRi9cbWdvI5MW/6uJ7RTNPGj8i6TDPDoWCDrFgMHlm3tRQQSzawbP0OAJomNZSuQ8yZxOlTxpDzcFezTDgULFNrNu1KziDWc//Tm+kuBhMa6rngpIlcOGcSr5o5geF1+azLNKsaDgUrG9t2dXLX8g3cvmQ9C5a1sKO9i/qaHOfOmsCFJ0/i1CmjKTTWM35kvb84Z5aS/oaCv5lkqRs9opbLT5/M5adPpqOryANPb+aOpeuTEU0betrlBONG1jOxsZ5C76Whz/PGehrrazwk1iwFPlOwzEQEy9e38vTGVlp2tLNhRzste5bWvY+79jPN97Da3IsDo2HYi8Kj0FDv4bJm+EzBKoAkZh/TyOxjGg/YplgMtu3u3CckSgHS1hMeT2/cyQNPb2bLrs797mPMiNo+4fHiM49CQz2jhtdSm3eAWHVzKFhZy+XE2JF1jB1ZR9OkA4cHQEdXkU079w2PPcGxYXvp55/WbGXDjjbaOov73UddTY7G+hpGJktDfT75WVr2rN/bJr/Ptt4/h9Xm3MVlFcehYENGXU2OY0cP59jRww/aLiLY2dHdJzza2NHWRWt7adnZ3kVrezet7Z1sau1gzaZdPet3dnT3q558Toysy+8NimFJaNTtDZyGYb3CJFlfX5ujPp+jvjZHXT5PXU2Oupoc9cnPupocdfnSc4eOHW0OBas6kno+3Z8wYeRh/36xGOzs6GJne3efENn7sydA2rvZ0bYnTErr129vozUJoJ0d3Ud0a9S6fO7FoZHvGyL5UogkYfPi9vkXhU59TY6aXI58TtTmRU0+R01OpSWfozavZNue9Tlq8iotyePaPetycnhVEIeC2WHK5UTjsFoahx35dB4RQXtXsSc4Wtu76Ogu0t5ZpKO7SEdXsnR377OuPVkOtL2j1/ZtuzuT59292u89xmDcrzu/J1D6hEpNLrdv6OwJleRxbT5HTqXfy/daanIil9uzPrfP9n23ibxEPr+3bV6QT46XV/I7ee1znL3Pc72OC7mk/Z6fvR/vOW5eIpejZ9+5XsfZc4xy/hKnQ8EsQ5IYVptnWG2eQmN9JjV0F2Of0Gjv2hsWnd1FurqDruKen6V1pW2l9T2Pu4t0FoPu7mLSLuguFnvadRWjtI+edkFnst+eYxUjaVda39rVRbEYdEf0tOuO0s8XPy9SDHpq6i4Gg5B3A5bvEyC5XiHWO0j2hg9cOW8a7zr3xFTrciiYVbl8Tgyvyw/Jb5gXe4VGdxI43cXez4sUi3uDpKu4b9tilMKqWITuiNL+kn323ncxCa1iBN192hajz+8UobtYTH6Xvdt7td27bk/b0muZ0JD+BweHgpkNWbmcyCFqh17epcaDss3MrIdDwczMejgUzMysR6qhIOliScskrZT0sf1sr5d0U7L9fknT06zHzMwOLrVQkJQHvg68FpgDXClpTp9m7wS2RMRM4MvAF9Kqx8zMDi3NM4V5wMqIWBURHcCPgcv7tLkcuD55/FPgAvmrj2ZmmUkzFCYDa3s9X5es22+biOgCtgHj++5I0tWSFkla1NLSklK5ZmZWEReaI+LaiJgbEXMLhULW5ZiZDVlpfnntWWBqr+dTknX7a7NOUg0wGth0sJ0+9NBDGyU9M8CaJgAbB/i7R5Pr2Jfr2Fc51FEONYDr6OtI6ji+P43SDIUHgVmSTqD05n8F8NY+bX4FXAXcC7wJ+O84xK3gImLApwqSFvXnzkNpcx2uo9zrKIcaXEc2daQWChHRJenvgd8CeeC7EfGEpE8DiyLiV8B1wA8krQQ2UwoOMzPLSKpzH0XErcCtfdZ9qtfjNuDNadZgZmb9VxEXmo+ia7MuIOE69uU69lUOdZRDDeA6+kq9Dh2iC9/MzKpItZ0pmJnZQTgUzMysR9WEwqEm5xukGr4raYOkx7M4fq86pkq6U9ISSU9Iel8GNQyT9ICkR5Ia/vdg19CnnrykP0m6OcMaVkt6TNLDkhZlWMcYST+V9KSkpZLOzqCG2cnfYc+yXdL7M6jjA8m/z8cl3Shp2GDXkNTxvqSGJ1L/O0TEkF8oDYl9CjgRqAMeAeZkUMd84Ezg8Yz/HscCZyaPG4Hlg/33AAQ0JI9rgfuBszL8m3wQ+BFwc4Y1rAYmZPlvI6njeuBdyeM6YEzG9eSBF4DjB/m4k4GngeHJ858A78jg9b8EeBwYQWnE6B3AzLSOVy1nCv2ZnC91EbGQ0vcxMhURz0fE4uTxDmApL56XKu0aIiJak6e1yZLJqAdJU4DXAd/J4vjlRNJoSh9ergOIiI6I2JpmKsHiAAAEY0lEQVRtVVwAPBURA53J4EjUAMOTGRdGAM9lUMPJwP0RsStKc8QtAN6Q1sGqJRT6MzlfVUruYXEGpU/qg33svKSHgQ3A7REx6DUk/h34CFDM6Ph7BPA7SQ9JujqjGk4AWoDvJd1p35E0MqNa9rgCuHGwDxoRzwJfBNYAzwPbIuJ3g10HpbOEcyWNlzQCuIR9pxA6qqolFGw/JDUAPwPeHxHbB/v4EdEdEadTmhdrnqSXDHYNki4FNkTEQ4N97P14VUScSekeJNdImp9BDTWUuji/ERFnADuBTK7BAUiqAy4D/l8Gxx5LqUfhBOA4YKSktw12HRGxlNK9Zn4H/AZ4GOhO63jVEgr9mZyvqkiqpRQIN0TEz7OsJemeuBO4OIPDnwNcJmk1pW7F8yX9MIM69nwyJSI2AL+g1O052NYB63qdtf2UUkhk5bXA4ohYn8GxLwSejoiWiOgEfg68MoM6iIjrIuJlETEf2ELpOmAqqiUUeibnSz55XEFpMr6qlNzI6DpgaUR8KaMaCpLGJI+HAxcBTw52HRHxjxExJSKmU/p38d8RMeifBiWNlNS45zHwakrdBoMqIl4A1kqanay6AFgy2HX0ciUZdB0l1gBnSRqR/J+5gNL1t0EnaWLycxql6wk/SutYqc59VC7iAJPzDXYdkm4EzgMmSFoH/HNEXDfYdVD6dPx24LGkTx/g41Gaq2qwHAtcn9y2NQf8JCIyGw5aBiYBv0huPFgD/CgifpNRLf8A3JB8gFoF/HUWRSTheBHwd1kcPyLul/RTYDHQBfyJ7Ka7+Jmk8UAncE2aF/89zYWZmfWolu4jMzPrB4eCmZn1cCiYmVkPh4KZmfVwKJiZWQ+HglnKJJ2X5eyrZofDoWBmZj0cCmYJSW9L7vHwsKRvJRP2tUr6cjKP/e8lFZK2p0u6T9Kjkn6RzJODpJmS7kjuE7FY0oxk9w297lFwQ/INWSR9PrmvxaOSvpjRSzfr4VAwAySdDLwFOCeZpK8b+EtgJLAoIk6hNGXxPye/8n3goxFxGvBYr/U3AF+PiJdSmifn+WT9GcD7gTmU7utxTvIN1dcDpyT7+Wy6r9Ls0BwKZiUXAC8DHkym/riA0pt3EbgpafND4FXJPQfGRMSCZP31wPxk7qLJEfELgIhoi4hdSZsHImJdRBQpzXI5HdgGtAHXSXoDsKetWWYcCmYlAq6PiNOTZXZE/K/9tBvovDDtvR53AzXJDVPmUZqJ9FJK0yKbZcqhYFbye+BNvWajHCfpeEr/R96UtHkrcE9EbAO2SDo3Wf92YEFyF7t1kv482Ud9clOU/UruZzE6mYjwA8BL03hhZoejKmZJNTuUiFgi6ROU7nyWI5mNktJNZuYl2zZQuu4AcBXwzeRNv/dMom8HviXp08k+3nyQwzYCv0xuBi9K94k2y5RnSTU7CEmtEdGQdR1mg8XdR2Zm1sNnCmZm1sNnCmZm1sOhYGZmPRwKZmbWw6FgZmY9HApmZtbj/wO5HXyDzrJUoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 0.2. generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK* with 0 mismatches from the wild type.\n",
      "temperature: 0.8. generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDDHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK* with 1 mismatches from the wild type.\n",
      "temperature: 1.0. generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVPTLVSTLYGVQCFSRYPDHMKQHDFSKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDSKEDGNILGHKLEYNYNSCNVYIMADKQKNGIKVNFKIRHNIVDGNVQLGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPAPWPTLVTTLSYGVQCFSRYPDH with 172 mismatches from the wild type.\n",
      "temperature: 1.2. generated sequence: SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFCRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKREYNYNSHNVYIMADKRKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSQSALSVQPNDGKPLVNHRFYTAADMQRNGIKADYKLP with 39 mismatches from the wild type.\n",
      "temperature: 1.8. generated sequence: SKGEGDTLVNTGVLFEGSTALSKPEDGNRVLFETGDALVNRIFEDGPVQLPDNHMVLLA*TSGKAPELGNYTLRDNHIFKEDEGILRHIKEDGSVPIRPDHMVLLGFVNAITGDHGSVQLQDNYHYQNTPIGDGPVLLP*NNYTLSSKTPVSREVDGTTLLKGSVPILVGDSVQHYFESAMDHKREFITAH*GDPILHQQSYNSHI*DGAACQQDNSMREESFGVEDGVPILVEGDAL with 220 mismatches from the wild type.\n"
     ]
    }
   ],
   "source": [
    "rnn = GenerativeRNN(args)\n",
    "logger = open(\"./logs/{0}.txt\".format(args[\"name\"]), \"w\")\n",
    "rnn.fit(dataloader=dataloader, logger=logger)\n",
    "rnn.show_model()\n",
    "rnn.plot_history(\"./logs/{0}_training_history\".format(args[\"name\"]))\n",
    "rnn.plot_model(\"./logs/{0}_model_architecture\".format(args[\"name\"]))\n",
    "temperature_lst = [0.2, 0.8, 1.0, 1.2, 1.8]\n",
    "for temperature in temperature_lst: \n",
    "    generated_sequence = rnn.sample(predict_len = len(wild_type) - 1, prime_str = \"S\", temperature = temperature)\n",
    "    mismatches = count_substring_mismatch(wild_type, generated_sequence)\n",
    "    print(\"temperature: {0}. generated sequence: {1} with {2} mismatches from the wild type.\".format(temperature, generated_sequence, mismatches), file=logger) \n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all_sequences(model, string, base = \"S\", depth = 3): \n",
    "    if depth == 0: \n",
    "        return np.e ** model.predict_log_prob(string, base)\n",
    "    total = 0\n",
    "    for c in get_all_amino_acids(): \n",
    "        total += enumerate_all_sequences(model, string + c, base, depth - 1)\n",
    "    return total\n",
    "\n",
    "for depth in range(1, 4):\n",
    "    for base in \"QRST\":\n",
    "        np.testing.assert_almost_equal(1, enumerate_all_sequences(rnn, \"\", base, depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.00000e-02 *\n",
      "       7.6142), tensor(1.00000e-02 *\n",
      "       9.9237), tensor(0.1153), tensor(0.1120), tensor(0.1042), tensor(1.00000e-02 *\n",
      "       7.5500), tensor(0.1046), tensor(1.00000e-02 *\n",
      "       9.2714), tensor(1.00000e-02 *\n",
      "       8.2159), tensor(0.1154)]\n",
      "[tensor(1.00000e-02 *\n",
      "       9.7746), tensor(0.1194), tensor(0.1002), tensor(1.00000e-02 *\n",
      "       9.2724), tensor(0.1102), tensor(0.1109), tensor(0.1092), tensor(0.1286), tensor(0.1177), tensor(1.00000e-02 *\n",
      "       7.7318)]\n"
     ]
    }
   ],
   "source": [
    "epoch = 8\n",
    "load_rnn = GenerativeRNN(args)\n",
    "load_rnn.load_model(\"./checkpoint_{0}.pt\".format(epoch))\n",
    "total_loss = []\n",
    "for i, (input, target) in enumerate(dataloader):\n",
    "    batch_size, seq_length = input.shape[0], input.shape[1]\n",
    "    hidden = load_rnn.model.init_hidden(batch_size)\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        output, hidden = load_rnn.model(input[:, c], hidden)\n",
    "        loss += load_rnn.criterion(output.view(batch_size, -1), target[:, c])\n",
    "    total_loss.append(loss.item() / seq_length) \n",
    "print(total_loss)\n",
    "print(torch.load(\"./models/rnn_test_sample/checkpoint_{0}.pt\".format(epoch))[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
